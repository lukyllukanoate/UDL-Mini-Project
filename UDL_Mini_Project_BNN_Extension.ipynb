{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21153,
     "status": "ok",
     "timestamp": 1767447235952,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "o883yfJrKAzJ",
    "outputId": "da41e997-74de-4e5f-db21-8193b0d0421e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/Colab Notebooks/UDL Mini Project\n"
     ]
    }
   ],
   "source": [
    "# Mount on drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/UDL Mini Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10054,
     "status": "ok",
     "timestamp": 1767447246008,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "gZcItpDJKY2Y",
    "outputId": "db5a3f11-4286-41b0-9cdc-d0448225cca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "import heapq\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvcLJGz1L-np"
   },
   "source": [
    "# 1. Input Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLnVuAgnKl2v"
   },
   "source": [
    "## 1.1 Load all the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqIuPfaTKj2P"
   },
   "outputs": [],
   "source": [
    "def get_mnist_data(batch_train=64, batch_eval=256, root='./data'):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    train = datasets.MNIST(root=root, train=True, download=True, transform=transform)\n",
    "    test  = datasets.MNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader_full = DataLoader(train, batch_size=batch_train, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_eval, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train, train_loader_full, test, test_loader\n",
    "\n",
    "train_dataset, train_loader_full, test_dataset, test_loader = get_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUq-ghjqMtee"
   },
   "source": [
    "## 1.2 Take out subsets of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A850N6c9kW63"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYPpOfPuktCF"
   },
   "outputs": [],
   "source": [
    "def sample_balanced_seed(full_dataset: Dataset, n_per_class=2, num_classes=10, seed=0):\n",
    "  \n",
    "    set_seed(seed)\n",
    "    indices_by_class = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(full_dataset):\n",
    "        indices_by_class[int(label)].append(idx)\n",
    "    seed_indices = []\n",
    "    for c in range(num_classes):\n",
    "        choices = random.sample(indices_by_class[c], k=n_per_class)\n",
    "        seed_indices.extend(choices)\n",
    "    random.shuffle(seed_indices)\n",
    "    return seed_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13816,
     "status": "ok",
     "timestamp": 1767447262259,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "x_I7_oXV-CDQ",
    "outputId": "c45cc0fb-ec4e-4c1e-a908-ea6e400763d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# Take out 20 images, 2 per class\n",
    "seed_idx = sample_balanced_seed(train_dataset, n_per_class=2, seed=seed)\n",
    "train_dataset_small = Subset(train_dataset, seed_idx)\n",
    "train_loader_small = DataLoader(train_dataset_small, batch_size=64, shuffle=True)\n",
    "print(len(train_dataset_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyPDYU7x0lhu"
   },
   "source": [
    "## 1.3 Create Dataset for Rotation Prediction SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AkIPcIw0kC8"
   },
   "outputs": [],
   "source": [
    "class RotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Given an underlying dataset that returns (x, y) (y ignored),\n",
    "    produce 4 rotated versions per image with rotation label 0..3.\n",
    "    x expected as tensor [1,H,W] already normalized.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset, transform=None):\n",
    "        self.base = base_dataset\n",
    "        # rotation transforms: 0,90,180,270\n",
    "        self.rots = [lambda x: x,\n",
    "                     lambda x: torch.rot90(x, 1, dims=[-2,-1]),\n",
    "                     lambda x: torch.rot90(x, 2, dims=[-2,-1]),\n",
    "                     lambda x: torch.rot90(x, 3, dims=[-2,-1])]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base) * 4\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_idx = idx // 4\n",
    "        rot_idx = idx % 4\n",
    "        x, _ = self.base[base_idx]\n",
    "        x_rot = self.rots[rot_idx](x)\n",
    "        if self.transform:\n",
    "            x_rot = self.transform(x_rot)\n",
    "        return x_rot, rot_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdHHs_3YTLIG"
   },
   "source": [
    "# 2. Model for BNN Analytical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBC2xaSJ1Au_"
   },
   "source": [
    "## 2.1 BNN Model Architecture (Extended with Non-Zero mean Prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rzlDTn8BFE_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def stable_inv(mat, jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Numerically stable inverse: try Cholesky, fall back to adding jitter.\n",
    "    mat: symmetric (d x d) torch tensor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        L = torch.linalg.cholesky(mat, upper=False)\n",
    "        invL = torch.inverse(L)\n",
    "        inv = invL.t() @ invL\n",
    "        return inv\n",
    "    except Exception:\n",
    "        d = mat.shape[0]\n",
    "        mat_j = mat + jitter * torch.eye(d, device=mat.device, dtype=mat.dtype)\n",
    "        return torch.inverse(mat_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrRwMiWsTh9O"
   },
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=28*28, hidden_sizes=[512,256], output_dim=10, dropout=0.5, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            if dropout and dropout > 0:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "            in_dim = h\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(in_dim, output_dim)\n",
    "\n",
    "        # Bayes posterior storage (populated by fit_last_layer_posterior)\n",
    "        self.posterior = None  # dict with keys 'U_post', 'M', 'Sigma', 's'\n",
    "        self._init_weights()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # small Gaussian init (close to older frameworks), reasonable for regression\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x, return_features=False, use_bayesian=False, n_samples=0):\n",
    "       \n",
    "        if x.dim() == 4:\n",
    "            x_flat = x.view(x.size(0), -1)\n",
    "        else:\n",
    "            x_flat = x\n",
    "\n",
    "        features = self.feature_extractor(x_flat)  # [B, K]\n",
    "\n",
    "        if use_bayesian:\n",
    "            if self.posterior is None:\n",
    "                raise RuntimeError(\"Posterior not set. Call model.fit_last_layer_posterior(Phi, Y, ...) first.\")\n",
    "\n",
    "            # Obtain analytic predictive mean mu, and covariance (1+q)Sigma as a tuple (mu, q, Sigma)\n",
    "            preds_tuple = self.predict_last_layer_bayes_from_features(features)\n",
    "\n",
    "            if n_samples is None or n_samples == 0:\n",
    "                if return_features:\n",
    "                    return preds_tuple, features\n",
    "                return preds_tuple\n",
    "            else:\n",
    "                raise RuntimeError(\"Not considering sampling posterior yet...\")\n",
    "         \n",
    "\n",
    "        # default deterministic forward (head weights used directly)\n",
    "        preds = self.head(features)\n",
    "        if return_features:\n",
    "            return preds, features\n",
    "        return preds\n",
    "\n",
    "    def get_features_from_loader(self, loader):\n",
    "        \"\"\"\n",
    "        Helper: pass a DataLoader returning (x,y) and get stacked features and labels.\n",
    "        Returns:\n",
    "          feats (N, K) torch tensor on cpu\n",
    "          Y_onehot (N, C) torch tensor on cpu\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        feats_list = []\n",
    "        y_list = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x = x.to(self.device)\n",
    "                logits, feats = self.forward(x, return_features=True, use_bayesian=False)\n",
    "                feats_list.append(feats.cpu())\n",
    "                y_list.append(F.one_hot(y, num_classes=logits.size(1)).float())\n",
    "        feats = torch.cat(feats_list, dim=0)\n",
    "        Y = torch.cat(y_list, dim=0)\n",
    "        return feats, Y\n",
    "\n",
    "    def fit_last_layer_posterior(self, Phi, Y, s=1.0, Sigma=None, M0=None, jitter=1e-6):\n",
    "        \n",
    "        device = self.device\n",
    "        Phi = Phi.to(device)\n",
    "        Y = Y.to(device)\n",
    "        N, K = Phi.shape\n",
    "        _, C = Y.shape\n",
    "\n",
    "        if Sigma is None:\n",
    "            # MAP ridge to estimate residuals\n",
    "            A_map = Phi.t() @ Phi + s * torch.eye(K, device=device)\n",
    "            Ainv_map = stable_inv(A_map)\n",
    "            W_map = Ainv_map @ (Phi.t() @ Y)\n",
    "            Resid = Y - Phi @ W_map\n",
    "            Sigma_emp = (Resid.t() @ Resid) / max(N - 1, 1)\n",
    "            Sigma = Sigma_emp + 1e-6 * torch.eye(C, device=device)\n",
    "        else:\n",
    "            Sigma = Sigma.to(device)\n",
    "\n",
    "        S_mat = s * torch.eye(K, device=device)\n",
    "        A = S_mat + Phi.t() @ Phi  # (K,K)\n",
    "        U_post = stable_inv(A)     # (K,K)\n",
    "\n",
    "        if M0 is None:\n",
    "            M = U_post @ (Phi.t() @ Y) # (K,C)\n",
    "        else:\n",
    "            print(\"Using Pretrained Prior Weight M0!\")\n",
    "            M0 = M0.to(device)\n",
    "            assert M0.shape == (K, C)\n",
    "            M = U_post @ (s * M0 + Phi.t() @ Y)\n",
    "\n",
    "        self.posterior = {\n",
    "            'U_post': U_post,\n",
    "            'M': M,\n",
    "            'Sigma': Sigma,\n",
    "            's': s,\n",
    "        }\n",
    "        return self.posterior\n",
    "\n",
    "\n",
    "    def predict_last_layer_bayes_from_features(self, feats):\n",
    "       \n",
    "        if self.posterior is None:\n",
    "            raise RuntimeError(\"Posterior not fit. Call fit_last_layer_posterior first.\")\n",
    "        feats = feats.to(self.device)\n",
    "        U_post = self.posterior['U_post'].to(self.device)\n",
    "        M = self.posterior['M'].to(self.device)\n",
    "        Sigma = self.posterior['Sigma'].to(self.device)\n",
    "\n",
    "        means = feats @ M                             # (B, C)\n",
    "        temp = (U_post @ feats.t()).t()               # (B, K)\n",
    "        q = (feats * temp).sum(dim=1)                 # (B,)\n",
    "        return means, q, Sigma\n",
    "\n",
    "    def sample_W_from_posterior(self, n_samples=1, jitter=1e-8):\n",
    "       \n",
    "        if self.posterior is None:\n",
    "            raise RuntimeError(\"Posterior not fit. Call fit_last_layer_posterior first.\")\n",
    "        M = self.posterior['M'].to(self.device)       # (K, C)\n",
    "        U_post = self.posterior['U_post'].to(self.device)\n",
    "        Sigma = self.posterior['Sigma'].to(self.device)\n",
    "        K, C = M.shape\n",
    "\n",
    "        # Cholesky factors\n",
    "        try:\n",
    "            A = torch.cholesky(U_post, upper=False)\n",
    "        except Exception:\n",
    "            A = torch.cholesky(U_post + jitter * torch.eye(K, device=self.device), upper=False)\n",
    "        try:\n",
    "            B = torch.cholesky(Sigma, upper=False)\n",
    "        except Exception:\n",
    "            B = torch.cholesky(Sigma + jitter * torch.eye(C, device=self.device), upper=False)\n",
    "\n",
    "        samples = []\n",
    "        for _ in range(n_samples):\n",
    "            Z = torch.randn((K, C), device=self.device)\n",
    "            W_s = M + A @ Z @ B.t()   # (K, C)\n",
    "            samples.append(W_s.unsqueeze(0))\n",
    "        W_samples = torch.cat(samples, dim=0)\n",
    "        return W_samples  # (n_samples, K, C)\n",
    "\n",
    "    def freeze_features(self):\n",
    "        for p in self.feature_extractor.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def unfreeze_features(self):\n",
    "        for p in self.feature_extractor.parameters():\n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35Pa4-2J1GcW"
   },
   "source": [
    "## 2.2 Model SSL Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDwRgGMO1MCS"
   },
   "outputs": [],
   "source": [
    "#@title Rotation Prediction Pretraining\n",
    "def ssl_rotation_pretrain(model: MLPRegressor,\n",
    "                          base_dataset,\n",
    "                          device='cpu',\n",
    "                          batch_size=128,\n",
    "                          epochs=20,\n",
    "                          lr=1e-3,\n",
    "                          weight_decay=1e-4):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    # Wrap base dataset into rotated dataset\n",
    "    rot_ds = RotDataset(base_dataset)\n",
    "    loader = DataLoader(rot_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # create temporary rotation head\n",
    "    # find feature dim K via a dummy forward\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        x0, _ = base_dataset[0]\n",
    "        x0 = x0.unsqueeze(0)\n",
    "        _, feats = model.forward(x0.to(device), return_features=True, use_bayesian=False)\n",
    "        K = feats.size(1)\n",
    "    rot_head = nn.Linear(K, 4).to(device)\n",
    "    opt = torch.optim.Adam(list(model.feature_extractor.parameters()) + list(rot_head.parameters()),\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        rot_head.train()\n",
    "        running = 0.0\n",
    "        for x, rot_label in loader:\n",
    "            x = x.to(device)\n",
    "            rot_label = rot_label.to(device)\n",
    "            opt.zero_grad()\n",
    "            _, feats = model.forward(x, return_features=True, use_bayesian=False)\n",
    "            logits = rot_head(feats)\n",
    "            loss = loss_fn(logits, rot_label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running += loss.item() * x.size(0)\n",
    "        print(f\"[SSL epoch {epoch+1}/{epochs}] loss={(running/len(loader.dataset)):.4f}\")\n",
    "    # done: keep feature_extractor weights (head dropped)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "0W9vMYEX2nQx"
   },
   "outputs": [],
   "source": [
    "#@title Compute W_SSL for Final Layer Weights via Ridge Linear Regression\n",
    "def compute_W_ssl_from_labeled(model: MLPRegressor, labeled_loader: DataLoader, alpha=1e-3, device='cpu'):\n",
    "  \n",
    "    model.eval()\n",
    "    Phi, Y = model.get_features_from_loader(labeled_loader)   # returns on CPU\n",
    "    Phi = Phi.to(device)   # (N, K)\n",
    "    Y = Y.to(device)       # (N, C)\n",
    "    N, K = Phi.shape\n",
    "    _, C = Y.shape\n",
    "    # Ridge: compute (K,K)\n",
    "    A = Phi.t() @ Phi + alpha * torch.eye(K, device=device)\n",
    "    Ainv = torch.inverse(A)\n",
    "    W_ssl = Ainv @ (Phi.t() @ Y)   # (K, C)\n",
    "    return W_ssl.cpu()  # return on CPU for storage; you can move to device later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKztnAHR_LMa"
   },
   "source": [
    "# 3. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmQY0EhBTJ5d"
   },
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes=10, device='cpu', dtype=torch.float32):\n",
    "    return F.one_hot(labels.long(), num_classes=num_classes).to(dtype=dtype).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipv8n5U__XN0"
   },
   "source": [
    "## 3.1 Training for one Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9BMINoITyk1"
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Training loop (MSE / regression to one-hot)\n",
    "# -------------------------\n",
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_onehot = one_hot(y, num_classes=10, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)  # shape [B,10]\n",
    "        loss = F.mse_loss(outputs, y_onehot, reduction='mean')  # mean over batch and outputs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_size = x.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "    return running_loss / total_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmQEXitp_mu1"
   },
   "source": [
    "## 3.2 Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gCsZElD_l7S"
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# infer model last layer posterior for Bayesian evaluation\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def infer_model_posterior(model, labeled_loader, s=1.0, Sigma=None, M0=None, device='cpu'):\n",
    "    model.freeze_features()\n",
    "\n",
    "    Phi, Y = model.get_features_from_loader(labeled_loader)  # returns on CPU; move to device if needed\n",
    "    Phi = Phi.to(model.device)\n",
    "    Y = Y.to(model.device)\n",
    "\n",
    "    posterior = model.fit_last_layer_posterior(Phi, Y, s=s, Sigma=Sigma, M0=M0)\n",
    "    #print(\"Posterior:\", posterior)\n",
    "    print(\"M_post shape\", posterior[\"M\"].shape)\n",
    "    print(\"U_post shape\", posterior[\"U_post\"].shape)\n",
    "    print(\"Sigma shape\", posterior[\"Sigma\"].shape)\n",
    "    return posterior\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_rmse(model, dataloader, use_bayesian=False, device='cpu'):\n",
    "    \"\"\"\n",
    "    Compute RMSE between model outputs (R^10) and one-hot targets.\n",
    "    if use_bayesian:\n",
    "        call model forward with use_bayesian=True to obtain preds_tuple\n",
    "        then use pred_mean to compute RMSE\n",
    "    else:\n",
    "        directly obtain point estimate output vector to compute RMSE\n",
    "    RMSE is sqrt(mean((y_pred - y_onehot)^2)) averaged over all samples and output dimensions.\n",
    "    Returns scalar RMSE.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sqerr_sum = 0.0\n",
    "    total = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_onehot = one_hot(y, num_classes=10, device=device)\n",
    "\n",
    "        if use_bayesian:\n",
    "            preds_tuple = model.forward(x, use_bayesian=True, n_samples=0)\n",
    "            outputs = preds_tuple[0] \n",
    "        else:\n",
    "            outputs = model.forward(x, use_bayesian=False)  # [B,10]\n",
    "\n",
    "        sqerr = (outputs - y_onehot).pow(2).sum().item() \n",
    "        sqerr_sum += sqerr\n",
    "        total += x.size(0) * 10 \n",
    "    mse = sqerr_sum / total\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKUkow4-_rof"
   },
   "source": [
    "## 3.3 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14134,
     "status": "ok",
     "timestamp": 1767447276949,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "NFISO5KfwOvQ",
    "outputId": "1920663d-b53e-4179-be62-77956fc4f7e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled set size: 1000\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_loader, test_dataset, test_loader = get_mnist_data(batch_train=128, batch_eval=256)\n",
    "# Subsample labelled data\n",
    "seed_idx = sample_balanced_seed(train_dataset, n_per_class=100, seed=seed)\n",
    "labeled_dataset = Subset(train_dataset, seed_idx)\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n",
    "print(\"Labeled set size:\", len(labeled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7f0fcVwT7hL"
   },
   "outputs": [],
   "source": [
    "\n",
    "def pretrain_model(seed, hidden_sizes):\n",
    "    set_seed(seed)\n",
    "    model = MLPRegressor(input_dim=28*28, hidden_sizes=hidden_sizes, output_dim=10, dropout=0.5, device=device)\n",
    "\n",
    "    # SSL pretrain on full unlabeled dataset (use train_dataset as unlabeled for SSL)\n",
    "    print(\"Starting SSL pretraining (rotation)...\")\n",
    "    model = ssl_rotation_pretrain(model, train_dataset, device=device, batch_size=256, epochs=5, lr=1e-3)\n",
    "\n",
    "    # Compute W_SSL via ridge on labeled set\n",
    "    print(\"Computing W_SSL (linear probe ridge)...\")\n",
    "    W_ssl = compute_W_ssl_from_labeled(model, labeled_loader, alpha=1e-3, device=device)\n",
    "    # W_ssl is on CPU. Move to model.device when calling fit.\n",
    "    print(\"W_ssl shape:\", W_ssl.shape)\n",
    "    return model, W_ssl\n",
    "\n",
    "\n",
    "def train_mlp_with_ssl(pretrained_model, W_ssl,\n",
    "                       seed=0,\n",
    "                       epochs=20,\n",
    "                       lr=1e-3,\n",
    "                       weight_decay=0.0,\n",
    "                       hidden_sizes=[512,256],\n",
    "                       use_bayesian=False,\n",
    "                       freeze_features=False,\n",
    "                       batch_train=128,\n",
    "                       batch_eval=256):\n",
    "\n",
    "    #model = copy.deepcopy(pretrained_model)\n",
    "    model = MLPRegressor(input_dim=28*28, hidden_sizes=hidden_sizes, output_dim=10, dropout=0.5, device=device)\n",
    "    if freeze_features:\n",
    "        model.freeze_features()\n",
    "    if use_bayesian:\n",
    "        # replacing model.head.parameters with W_ssl\n",
    "        model.head.weight.data.copy_(W_ssl.t().to(model.device))\n",
    "        model.head.bias.data.zero_()\n",
    "\n",
    "    # Finetuning model on labelled set\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss = train_one_epoch(model, labeled_loader, optimizer, device)\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            rmse = evaluate_rmse(model, test_loader, use_bayesian=False, device=model.device)\n",
    "            print(f\"[Epoch {epoch:02d}] train MSE loss={loss:.6f} | test RMSE = {rmse:.6f}\")\n",
    "\n",
    "    # Infer the model posterior, with W_SSL as prior mean\n",
    "    if use_bayesian:\n",
    "        print(\"Inferring model posterior...\")\n",
    "        posterior = infer_model_posterior(model, labeled_loader, device=model.device, M0=W_ssl.to(device), s=1e-3)\n",
    "\n",
    "    # Infer model predictive and compute rmse\n",
    "    final_rmse = evaluate_rmse(model, test_loader, use_bayesian=use_bayesian, device=model.device)\n",
    "    print(\"Final test RMSE:\", final_rmse)\n",
    "    return model, final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370217,
     "status": "ok",
     "timestamp": 1767447647171,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "1mN7m-Uf9XWz",
    "outputId": "b7b57ce0-3d78-4eff-bf14-556f6a6e811c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SSL pretraining (rotation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SSL epoch 1/5] loss=0.0959\n",
      "[SSL epoch 2/5] loss=0.0477\n",
      "[SSL epoch 3/5] loss=0.0414\n",
      "[SSL epoch 4/5] loss=0.0395\n",
      "[SSL epoch 5/5] loss=0.0377\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "#@title Obtain Pretrained Model\n",
    "hidden_sizes = [512,256]\n",
    "seed=1\n",
    "pretrained_model, W_ssl = pretrain_model(seed, hidden_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 52557,
     "status": "ok",
     "timestamp": 1767447699730,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "5YIXxHX08pCG",
    "outputId": "f4614332-12fd-4690-8200-1640f19a0fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] train MSE loss=0.205050 | test RMSE = 0.301377\n",
      "[Epoch 05] train MSE loss=0.074493 | test RMSE = 0.251299\n",
      "[Epoch 10] train MSE loss=0.051469 | test RMSE = 0.199631\n",
      "[Epoch 15] train MSE loss=0.041713 | test RMSE = 0.171530\n",
      "[Epoch 20] train MSE loss=0.034460 | test RMSE = 0.164065\n",
      "[Epoch 25] train MSE loss=0.029482 | test RMSE = 0.148512\n",
      "[Epoch 30] train MSE loss=0.026850 | test RMSE = 0.144281\n",
      "[Epoch 35] train MSE loss=0.023599 | test RMSE = 0.144576\n",
      "[Epoch 40] train MSE loss=0.022822 | test RMSE = 0.146414\n",
      "[Epoch 45] train MSE loss=0.021101 | test RMSE = 0.137179\n",
      "[Epoch 50] train MSE loss=0.019833 | test RMSE = 0.143110\n",
      "Inferring model posterior...\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13139089721912786\n"
     ]
    }
   ],
   "source": [
    "#@title Finetune Pretrained Model\n",
    "model, rmse = train_mlp_with_ssl(pretrained_model, W_ssl, seed=1, epochs=50, lr=1e-3, weight_decay=0.0, hidden_sizes=hidden_sizes,\n",
    "                                 use_bayesian=True, freeze_features=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyBnpvgsBFFA"
   },
   "source": [
    "### check accuracy of NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6fab433"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy_from_probs(probs, labels):\n",
    "    preds = probs.argmax(dim=1)   # take the maximum in predicted prob\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_accuracy(model, dataloader, use_bayesian=False, device='cpu'):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if use_bayesian:\n",
    "            preds_tuple = model.forward(x, use_bayesian=True, n_samples=0)\n",
    "            outputs = preds_tuple[0]  # Take out pred_mean\n",
    "        else:\n",
    "            outputs = model.forward(x, use_bayesian=False)  # [B,10]\n",
    "\n",
    "        total_correct += (outputs.argmax(dim=1) == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    return total_correct / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1766,
     "status": "ok",
     "timestamp": 1767447701777,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "7464a133",
    "outputId": "41a37241-95ee-4c2f-931f-aef00555d192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9047\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_accuracy(model, test_loader, use_bayesian=True, device=model.device)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFM-TVUEBFFB"
   },
   "source": [
    "# 4. Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6BzMA5qBFFB"
   },
   "source": [
    "## 4.1 Acquisition Function: Predictive Covariance Factor\n",
    "\n",
    "Predictive Covariance is given by $(1+q)\\Sigma$. We can use either $q$, $\\log (1+q)$, or $(1+q)\\det(\\Sigma)$ as acquisition function. The ranking produced is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPWsMHVZBFFB"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predictive_covar_acquisition(model: nn.Module, pool_dataset: Dataset, pool_indices: list,\n",
    "                                 use_bayesian = True, batch_size=256, device='cpu', score_type='q'):\n",
    "   \n",
    "    model.eval()\n",
    "    # Create loader for the pool subset (preserve order by shuffle=False)\n",
    "    pool_subset = Subset(pool_dataset, pool_indices)\n",
    "    pool_loader = DataLoader(pool_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    qs = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in pool_loader:\n",
    "            x = x.to(device)\n",
    "            if use_bayesian:\n",
    "                preds_tuple = model.forward(x, use_bayesian=True, n_samples=0)\n",
    "                q_batch = preds_tuple[1]  # Take out covariance factor q\n",
    "            else:\n",
    "                print(\"Warning: setting use_bayesian to False results in random acq scores, equivalent to random sampling\")\n",
    "                outputs = model.forward(x, use_bayesian=False)\n",
    "                q_batch = torch.rand(outputs.shape[0], device=device)\n",
    "\n",
    "            qs.append(q_batch.cpu())\n",
    "    qs = torch.cat(qs, dim=0).numpy()  # shape (len(pool_indices),)\n",
    "\n",
    "    if score_type == 'q':\n",
    "        scores = qs\n",
    "    elif score_type == 'log1p':\n",
    "        scores = np.log1p(qs)\n",
    "    elif score_type == 'trace':\n",
    "        assert use_bayesian == True, \"Cannot use trace for acq for deterministic model.\"\n",
    "        # predictive covariance scalar measure: (1+q)*trace(Sigma)\n",
    "        Sigma = model.posterior['Sigma'].to(device)      # (C,C)\n",
    "        tr_Sigma = torch.trace(Sigma).item()\n",
    "        scores = (1.0 + qs) * tr_Sigma\n",
    "    else:\n",
    "        raise ValueError(\"Unknown score_type\")\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weWkBMDKBFFB"
   },
   "source": [
    "## 4.2 Main AL Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ToVkljFqO7Vz"
   },
   "outputs": [],
   "source": [
    "# @title Main AL Loop\n",
    "\n",
    "def active_learning_loop(pretrained_model,    \n",
    "                         model_ctor,          \n",
    "                         train_dataset,       \n",
    "                         test_dataset,         \n",
    "                         initial_labeled_idxs, \n",
    "                         val_indices=None,   \n",
    "                         pool_subset=None,     \n",
    "                         candidate_pool_size=None,\n",
    "                         n_acq_per_iter=10,\n",
    "                         n_iterations=10,     \n",
    "                         epochs_per_round=50,\n",
    "                         lr=1e-3,\n",
    "                         weight_decay=1e-4,\n",
    "                         T_acq=20,          \n",
    "                         batch_train=64,\n",
    "                         batch_pool=256,\n",
    "                         prior_s=1.0,\n",
    "                         reset_model=True,\n",
    "                         device='cpu',\n",
    "                         seed=0,\n",
    "                         is_bayesian=True,\n",
    "                         acquisition_fn=predictive_covar_acquisition,\n",
    "                         acquisition_kwargs=None):\n",
    "   \n",
    "    print(\"Training dataset size:\", len(train_dataset))\n",
    "    print(\"Test dataset size:\", len(test_dataset))\n",
    "    print(\"Initial Labelled set size:\", len(initial_labeled_idxs))\n",
    "\n",
    "    set_seed(seed)\n",
    "    acquisition_kwargs = acquisition_kwargs or {}\n",
    "\n",
    "    # L: labelled set (list of indices)\n",
    "    L = list(initial_labeled_idxs[:])\n",
    "    # U: pool indices\n",
    "    all_indices = list(range(len(train_dataset)))\n",
    "    U = [i for i in all_indices if i not in set(L)]\n",
    "    if pool_subset is not None:\n",
    "        # restrict pool to provided subset\n",
    "        U = [i for i in U if i in set(pool_subset)]\n",
    "\n",
    "    model = model_ctor().to(device)\n",
    "    init_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    history = {\n",
    "        'labelled_set_sizes': [len(L)],\n",
    "        'selected_indices_each_iter': [],\n",
    "        'test_rmse': [],\n",
    "        'is_bayesian': is_bayesian,\n",
    "    }\n",
    "\n",
    "    # main loop\n",
    "    for it in range(n_iterations + 1):\n",
    "        print(f\"\\n=== Acquisition iteration {it} | labelled size = {len(L)} | pool size = {len(U)} ===\")\n",
    "\n",
    "        # 1) Prepare labelled DataLoader\n",
    "        labeled_subset = Subset(train_dataset, L)\n",
    "        labeled_loader = DataLoader(labeled_subset, batch_size=batch_train, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # 2) Initialize / reset model\n",
    "        model = model_ctor().to(device)\n",
    "        if reset_model:\n",
    "            model.load_state_dict(init_state)  # ensures same init every round\n",
    "\n",
    "        # 2.5) Obtain pretrained W_ssl via ridge and insert into model last layer\n",
    "        if is_bayesian:\n",
    "            print(\"Computing W_SSL (linear probe ridge)...\")\n",
    "            W_ssl = compute_W_ssl_from_labeled(pretrained_model, labeled_loader, alpha=1e-3, device=device)\n",
    "            model.head.weight.data.copy_(W_ssl.t().to(model.device))\n",
    "            model.head.bias.data.zero_()\n",
    "            print(\"W_ssl shape:\", W_ssl.shape)\n",
    "\n",
    "        # 3) Train the model on current labelled set\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        for epoch in range(epochs_per_round):\n",
    "            loss = train_one_epoch(model, labeled_loader, optimizer, device)\n",
    "\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "                rmse = evaluate_rmse(model, test_loader, use_bayesian=False, device=model.device)\n",
    "                print(f\"[Train epoch {epoch+1}/{epochs_per_round}] loss={loss:.6f}, train_rmse={rmse:.6f}\")\n",
    "\n",
    "\n",
    "        # 4) Evaluate on test set using appropriate method\n",
    "        if is_bayesian:\n",
    "            # Infer the model posterior\n",
    "            posterior = infer_model_posterior(model, labeled_loader, device=model.device, M0=W_ssl.to(device), s=prior_s)\n",
    "\n",
    "        final_rmse = evaluate_rmse(model, test_loader, use_bayesian=is_bayesian, device=model.device)\n",
    "        print(\"Final test RMSE:\", final_rmse)\n",
    "\n",
    "        history['test_rmse'].append(final_rmse)\n",
    "\n",
    "        if it == n_iterations:\n",
    "            break\n",
    "\n",
    "        # 5) Compute acquisition scores on pool U using passed-in acquisition function\n",
    "        print(f\"Computing acquisition scores on pool (subsample size: {candidate_pool_size})\")\n",
    "\n",
    "        # choose candidate subset size (new parameter: candidate_pool_size)\n",
    "        # if candidate_pool_size is None or >= len(U) we score full pool\n",
    "        if candidate_pool_size is None or candidate_pool_size >= len(U):\n",
    "            candidate_indices = list(U)   # score full pool (fallback)\n",
    "        else:\n",
    "            # sample uniformly from U (reproducible controlled by set_seed(seed) earlier)\n",
    "            candidate_indices = random.sample(U, k=min(candidate_pool_size, len(U)))\n",
    "\n",
    "        # call acquisition on the candidate subset only (indices refer to full dataset)\n",
    "        scores_on_candidates = acquisition_fn(model, train_dataset, pool_indices=candidate_indices,\n",
    "                                              use_bayesian=is_bayesian, score_type='log1p', **acquisition_kwargs)\n",
    "        scores_on_candidates = np.asarray(scores_on_candidates)\n",
    "        # Now pick top-k from candidates\n",
    "        k = min(n_acq_per_iter, len(candidate_indices))\n",
    "        topk_idx_in_candidates = np.argpartition(-scores_on_candidates, k-1)[:k]\n",
    "        topk_sorted = topk_idx_in_candidates[np.argsort(-scores_on_candidates[topk_idx_in_candidates])]\n",
    "        selected_indices = [candidate_indices[i] for i in topk_sorted.tolist()]\n",
    "\n",
    "        # 6) Update sets: move selected from U -> L\n",
    "        for s in selected_indices:\n",
    "            L.append(s)\n",
    "            U.remove(s)\n",
    "\n",
    "        history['labelled_set_sizes'].append(len(L))\n",
    "        history['selected_indices_each_iter'].append(selected_indices)\n",
    "\n",
    "        with open('outputs/history_BNN_intermediate.json', 'w') as f:\n",
    "            json.dump(history, f)\n",
    "\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tX4kIDdkBFFB"
   },
   "outputs": [],
   "source": [
    "#@title Config for Extension on BNN\n",
    "def make_model():\n",
    "    return MLPRegressor(input_dim=28*28, hidden_sizes=[512, 256], output_dim=10, dropout=0.5, device=device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "acq_functions = [predictive_covar_acquisition]\n",
    "acq_names = [\"PredCovariance\"]\n",
    "model_names = [\"BNN_Analytical\"]\n",
    "output_dir = \"outputs/bnn_ssl/\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset, train_loader_full, test_dataset, test_loader = get_mnist_data()\n",
    "#train_dataset_small = Subset(train_dataset, range(1000))\n",
    "#test_dataset_small = Subset(test_dataset, range(1000))\n",
    "train_dataset_to_use = train_dataset\n",
    "test_dataset_to_use = test_dataset\n",
    "\n",
    "# Training Hyperparameters\n",
    "n_iterations = 100  # Number of AL runs\n",
    "T_acq = 20   # Number of MC samples for function evaluation and acquisition calculation\n",
    "epochs_per_round = 50\n",
    "candidate_pool_size = 2000  # Number of subsample for acquisition\n",
    "prior_s = 1e-3\n",
    "seeds = [3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 15827919,
     "status": "ok",
     "timestamp": 1767464426358,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "-w6Om2mxBFFB",
    "outputId": "8032e77d-40ed-449c-a0cf-3fddef08ded4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========== Running PredCovariance Seed 3 ==========\n",
      "Starting SSL pretraining (rotation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "[Train epoch 5/50] loss=0.072808, train_rmse=0.255097\n",
      "[Train epoch 10/50] loss=0.055817, train_rmse=0.219798\n",
      "[Train epoch 15/50] loss=0.046754, train_rmse=0.200753\n",
      "[Train epoch 20/50] loss=0.038585, train_rmse=0.190789\n",
      "[Train epoch 25/50] loss=0.030793, train_rmse=0.180791\n",
      "[Train epoch 30/50] loss=0.028487, train_rmse=0.178817\n",
      "[Train epoch 35/50] loss=0.026773, train_rmse=0.176213\n",
      "[Train epoch 40/50] loss=0.022905, train_rmse=0.171824\n",
      "[Train epoch 45/50] loss=0.021332, train_rmse=0.167718\n",
      "[Train epoch 50/50] loss=0.020515, train_rmse=0.166709\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15291925815375143\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 67 | labelled size = 690 | pool size = 59310 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.166239, train_rmse=0.296770\n",
      "[Train epoch 5/50] loss=0.071337, train_rmse=0.255438\n",
      "[Train epoch 10/50] loss=0.055222, train_rmse=0.217054\n",
      "[Train epoch 15/50] loss=0.045238, train_rmse=0.198463\n",
      "[Train epoch 20/50] loss=0.035878, train_rmse=0.184576\n",
      "[Train epoch 25/50] loss=0.030999, train_rmse=0.178599\n",
      "[Train epoch 30/50] loss=0.026799, train_rmse=0.179099\n",
      "[Train epoch 35/50] loss=0.025458, train_rmse=0.179017\n",
      "[Train epoch 40/50] loss=0.022651, train_rmse=0.166931\n",
      "[Train epoch 45/50] loss=0.021780, train_rmse=0.165071\n",
      "[Train epoch 50/50] loss=0.020032, train_rmse=0.168543\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1503021580078622\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 68 | labelled size = 700 | pool size = 59300 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.171661, train_rmse=0.298245\n",
      "[Train epoch 5/50] loss=0.071848, train_rmse=0.253105\n",
      "[Train epoch 10/50] loss=0.052470, train_rmse=0.217036\n",
      "[Train epoch 15/50] loss=0.041248, train_rmse=0.198087\n",
      "[Train epoch 20/50] loss=0.034954, train_rmse=0.185455\n",
      "[Train epoch 25/50] loss=0.029384, train_rmse=0.183615\n",
      "[Train epoch 30/50] loss=0.027403, train_rmse=0.177584\n",
      "[Train epoch 35/50] loss=0.025667, train_rmse=0.172119\n",
      "[Train epoch 40/50] loss=0.021286, train_rmse=0.166298\n",
      "[Train epoch 45/50] loss=0.021182, train_rmse=0.159522\n",
      "[Train epoch 50/50] loss=0.018928, train_rmse=0.158450\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14988242398694598\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 69 | labelled size = 710 | pool size = 59290 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.181970, train_rmse=0.300426\n",
      "[Train epoch 5/50] loss=0.076977, train_rmse=0.262895\n",
      "[Train epoch 10/50] loss=0.059749, train_rmse=0.230686\n",
      "[Train epoch 15/50] loss=0.048894, train_rmse=0.206865\n",
      "[Train epoch 20/50] loss=0.040174, train_rmse=0.192555\n",
      "[Train epoch 25/50] loss=0.037597, train_rmse=0.182724\n",
      "[Train epoch 30/50] loss=0.033176, train_rmse=0.189018\n",
      "[Train epoch 35/50] loss=0.028885, train_rmse=0.176973\n",
      "[Train epoch 40/50] loss=0.029785, train_rmse=0.179564\n",
      "[Train epoch 45/50] loss=0.023038, train_rmse=0.163532\n",
      "[Train epoch 50/50] loss=0.023782, train_rmse=0.165975\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1485850007603156\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 70 | labelled size = 720 | pool size = 59280 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.194129, train_rmse=0.304782\n",
      "[Train epoch 5/50] loss=0.077519, train_rmse=0.263894\n",
      "[Train epoch 10/50] loss=0.060411, train_rmse=0.231339\n",
      "[Train epoch 15/50] loss=0.048519, train_rmse=0.203107\n",
      "[Train epoch 20/50] loss=0.037548, train_rmse=0.186227\n",
      "[Train epoch 25/50] loss=0.032727, train_rmse=0.180538\n",
      "[Train epoch 30/50] loss=0.028751, train_rmse=0.173133\n",
      "[Train epoch 35/50] loss=0.025140, train_rmse=0.168474\n",
      "[Train epoch 40/50] loss=0.023075, train_rmse=0.163012\n",
      "[Train epoch 45/50] loss=0.021577, train_rmse=0.170614\n",
      "[Train epoch 50/50] loss=0.021900, train_rmse=0.169367\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1499837012336922\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 71 | labelled size = 730 | pool size = 59270 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.190807, train_rmse=0.302809\n",
      "[Train epoch 5/50] loss=0.079271, train_rmse=0.265789\n",
      "[Train epoch 10/50] loss=0.064011, train_rmse=0.237892\n",
      "[Train epoch 15/50] loss=0.052476, train_rmse=0.214448\n",
      "[Train epoch 20/50] loss=0.044018, train_rmse=0.200333\n",
      "[Train epoch 25/50] loss=0.036083, train_rmse=0.188534\n",
      "[Train epoch 30/50] loss=0.033356, train_rmse=0.182895\n",
      "[Train epoch 35/50] loss=0.031154, train_rmse=0.172950\n",
      "[Train epoch 40/50] loss=0.028040, train_rmse=0.167971\n",
      "[Train epoch 45/50] loss=0.025504, train_rmse=0.165294\n",
      "[Train epoch 50/50] loss=0.023860, train_rmse=0.162042\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14560000711044097\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 72 | labelled size = 740 | pool size = 59260 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.167713, train_rmse=0.299655\n",
      "[Train epoch 5/50] loss=0.073319, train_rmse=0.254995\n",
      "[Train epoch 10/50] loss=0.056149, train_rmse=0.216200\n",
      "[Train epoch 15/50] loss=0.043769, train_rmse=0.195781\n",
      "[Train epoch 20/50] loss=0.036605, train_rmse=0.183238\n",
      "[Train epoch 25/50] loss=0.030425, train_rmse=0.179031\n",
      "[Train epoch 30/50] loss=0.029355, train_rmse=0.175852\n",
      "[Train epoch 35/50] loss=0.025447, train_rmse=0.169058\n",
      "[Train epoch 40/50] loss=0.024347, train_rmse=0.162850\n",
      "[Train epoch 45/50] loss=0.021940, train_rmse=0.162407\n",
      "[Train epoch 50/50] loss=0.020688, train_rmse=0.164775\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14526585019211016\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 73 | labelled size = 750 | pool size = 59250 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.179956, train_rmse=0.304200\n",
      "[Train epoch 5/50] loss=0.076229, train_rmse=0.264997\n",
      "[Train epoch 10/50] loss=0.060093, train_rmse=0.229982\n",
      "[Train epoch 15/50] loss=0.047880, train_rmse=0.204428\n",
      "[Train epoch 20/50] loss=0.040362, train_rmse=0.193854\n",
      "[Train epoch 25/50] loss=0.033055, train_rmse=0.182230\n",
      "[Train epoch 30/50] loss=0.031385, train_rmse=0.176956\n",
      "[Train epoch 35/50] loss=0.027668, train_rmse=0.174662\n",
      "[Train epoch 40/50] loss=0.023496, train_rmse=0.163807\n",
      "[Train epoch 45/50] loss=0.023412, train_rmse=0.159524\n",
      "[Train epoch 50/50] loss=0.022801, train_rmse=0.161584\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14300548054123133\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 74 | labelled size = 760 | pool size = 59240 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.159346, train_rmse=0.296403\n",
      "[Train epoch 5/50] loss=0.069333, train_rmse=0.243247\n",
      "[Train epoch 10/50] loss=0.052158, train_rmse=0.209494\n",
      "[Train epoch 15/50] loss=0.040494, train_rmse=0.190608\n",
      "[Train epoch 20/50] loss=0.033831, train_rmse=0.175147\n",
      "[Train epoch 25/50] loss=0.029196, train_rmse=0.172239\n",
      "[Train epoch 30/50] loss=0.024731, train_rmse=0.162397\n",
      "[Train epoch 35/50] loss=0.022609, train_rmse=0.155677\n",
      "[Train epoch 40/50] loss=0.022583, train_rmse=0.162379\n",
      "[Train epoch 45/50] loss=0.019936, train_rmse=0.152885\n",
      "[Train epoch 50/50] loss=0.018502, train_rmse=0.154992\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1447105851016969\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 75 | labelled size = 770 | pool size = 59230 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.149006, train_rmse=0.296475\n",
      "[Train epoch 5/50] loss=0.074069, train_rmse=0.253352\n",
      "[Train epoch 10/50] loss=0.057623, train_rmse=0.216747\n",
      "[Train epoch 15/50] loss=0.046222, train_rmse=0.198258\n",
      "[Train epoch 20/50] loss=0.040946, train_rmse=0.186007\n",
      "[Train epoch 25/50] loss=0.037107, train_rmse=0.185513\n",
      "[Train epoch 30/50] loss=0.034723, train_rmse=0.176055\n",
      "[Train epoch 35/50] loss=0.034781, train_rmse=0.178843\n",
      "[Train epoch 40/50] loss=0.031046, train_rmse=0.171312\n",
      "[Train epoch 45/50] loss=0.030792, train_rmse=0.176651\n",
      "[Train epoch 50/50] loss=0.029110, train_rmse=0.170966\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14942810893335617\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 76 | labelled size = 780 | pool size = 59220 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.149669, train_rmse=0.292117\n",
      "[Train epoch 5/50] loss=0.067769, train_rmse=0.242658\n",
      "[Train epoch 10/50] loss=0.050686, train_rmse=0.205090\n",
      "[Train epoch 15/50] loss=0.038365, train_rmse=0.186200\n",
      "[Train epoch 20/50] loss=0.032599, train_rmse=0.182809\n",
      "[Train epoch 25/50] loss=0.028957, train_rmse=0.167777\n",
      "[Train epoch 30/50] loss=0.025573, train_rmse=0.167064\n",
      "[Train epoch 35/50] loss=0.025766, train_rmse=0.161337\n",
      "[Train epoch 40/50] loss=0.022234, train_rmse=0.156729\n",
      "[Train epoch 45/50] loss=0.021037, train_rmse=0.164161\n",
      "[Train epoch 50/50] loss=0.018977, train_rmse=0.156331\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14451562182087935\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 77 | labelled size = 790 | pool size = 59210 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.176891, train_rmse=0.301206\n",
      "[Train epoch 5/50] loss=0.075025, train_rmse=0.256533\n",
      "[Train epoch 10/50] loss=0.056733, train_rmse=0.220399\n",
      "[Train epoch 15/50] loss=0.043791, train_rmse=0.196925\n",
      "[Train epoch 20/50] loss=0.038323, train_rmse=0.185035\n",
      "[Train epoch 25/50] loss=0.034290, train_rmse=0.180217\n",
      "[Train epoch 30/50] loss=0.029774, train_rmse=0.165773\n",
      "[Train epoch 35/50] loss=0.025507, train_rmse=0.157543\n",
      "[Train epoch 40/50] loss=0.024135, train_rmse=0.159832\n",
      "[Train epoch 45/50] loss=0.021230, train_rmse=0.154242\n",
      "[Train epoch 50/50] loss=0.021872, train_rmse=0.157329\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14036404870473457\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 78 | labelled size = 800 | pool size = 59200 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.139486, train_rmse=0.288790\n",
      "[Train epoch 5/50] loss=0.065873, train_rmse=0.237618\n",
      "[Train epoch 10/50] loss=0.048838, train_rmse=0.203000\n",
      "[Train epoch 15/50] loss=0.036179, train_rmse=0.183364\n",
      "[Train epoch 20/50] loss=0.029926, train_rmse=0.167304\n",
      "[Train epoch 25/50] loss=0.025072, train_rmse=0.155170\n",
      "[Train epoch 30/50] loss=0.021714, train_rmse=0.156238\n",
      "[Train epoch 35/50] loss=0.022390, train_rmse=0.160026\n",
      "[Train epoch 40/50] loss=0.018690, train_rmse=0.156003\n",
      "[Train epoch 45/50] loss=0.016908, train_rmse=0.159983\n",
      "[Train epoch 50/50] loss=0.017254, train_rmse=0.154305\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1424279941953877\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 79 | labelled size = 810 | pool size = 59190 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.149145, train_rmse=0.291658\n",
      "[Train epoch 5/50] loss=0.067620, train_rmse=0.240657\n",
      "[Train epoch 10/50] loss=0.048263, train_rmse=0.197747\n",
      "[Train epoch 15/50] loss=0.037113, train_rmse=0.178414\n",
      "[Train epoch 20/50] loss=0.031461, train_rmse=0.168161\n",
      "[Train epoch 25/50] loss=0.026086, train_rmse=0.158270\n",
      "[Train epoch 30/50] loss=0.025033, train_rmse=0.162550\n",
      "[Train epoch 35/50] loss=0.020133, train_rmse=0.151227\n",
      "[Train epoch 40/50] loss=0.021160, train_rmse=0.151486\n",
      "[Train epoch 45/50] loss=0.019311, train_rmse=0.149553\n",
      "[Train epoch 50/50] loss=0.016924, train_rmse=0.150668\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1400441774761584\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 80 | labelled size = 820 | pool size = 59180 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.171517, train_rmse=0.304706\n",
      "[Train epoch 5/50] loss=0.073923, train_rmse=0.254042\n",
      "[Train epoch 10/50] loss=0.057262, train_rmse=0.223083\n",
      "[Train epoch 15/50] loss=0.047191, train_rmse=0.195517\n",
      "[Train epoch 20/50] loss=0.038969, train_rmse=0.179617\n",
      "[Train epoch 25/50] loss=0.033925, train_rmse=0.171699\n",
      "[Train epoch 30/50] loss=0.028036, train_rmse=0.163953\n",
      "[Train epoch 35/50] loss=0.025941, train_rmse=0.151113\n",
      "[Train epoch 40/50] loss=0.022490, train_rmse=0.154119\n",
      "[Train epoch 45/50] loss=0.020866, train_rmse=0.159197\n",
      "[Train epoch 50/50] loss=0.019497, train_rmse=0.148995\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13729792752073594\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 81 | labelled size = 830 | pool size = 59170 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.138862, train_rmse=0.289423\n",
      "[Train epoch 5/50] loss=0.066745, train_rmse=0.237216\n",
      "[Train epoch 10/50] loss=0.050309, train_rmse=0.202491\n",
      "[Train epoch 15/50] loss=0.040643, train_rmse=0.187577\n",
      "[Train epoch 20/50] loss=0.032834, train_rmse=0.167746\n",
      "[Train epoch 25/50] loss=0.028819, train_rmse=0.157699\n",
      "[Train epoch 30/50] loss=0.025672, train_rmse=0.156974\n",
      "[Train epoch 35/50] loss=0.023343, train_rmse=0.152315\n",
      "[Train epoch 40/50] loss=0.020858, train_rmse=0.156788\n",
      "[Train epoch 45/50] loss=0.020081, train_rmse=0.152833\n",
      "[Train epoch 50/50] loss=0.018983, train_rmse=0.150435\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13814923654635947\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 82 | labelled size = 840 | pool size = 59160 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.176591, train_rmse=0.301626\n",
      "[Train epoch 5/50] loss=0.074895, train_rmse=0.259329\n",
      "[Train epoch 10/50] loss=0.059690, train_rmse=0.225321\n",
      "[Train epoch 15/50] loss=0.049576, train_rmse=0.210404\n",
      "[Train epoch 20/50] loss=0.040428, train_rmse=0.184844\n",
      "[Train epoch 25/50] loss=0.032976, train_rmse=0.164788\n",
      "[Train epoch 30/50] loss=0.030944, train_rmse=0.168041\n",
      "[Train epoch 35/50] loss=0.026887, train_rmse=0.158891\n",
      "[Train epoch 40/50] loss=0.025492, train_rmse=0.159137\n",
      "[Train epoch 45/50] loss=0.023400, train_rmse=0.155028\n",
      "[Train epoch 50/50] loss=0.022276, train_rmse=0.153383\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13888847323143538\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 83 | labelled size = 850 | pool size = 59150 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.143522, train_rmse=0.291891\n",
      "[Train epoch 5/50] loss=0.065200, train_rmse=0.233635\n",
      "[Train epoch 10/50] loss=0.047714, train_rmse=0.199172\n",
      "[Train epoch 15/50] loss=0.037195, train_rmse=0.181887\n",
      "[Train epoch 20/50] loss=0.031700, train_rmse=0.171111\n",
      "[Train epoch 25/50] loss=0.030118, train_rmse=0.160126\n",
      "[Train epoch 30/50] loss=0.024319, train_rmse=0.149182\n",
      "[Train epoch 35/50] loss=0.022567, train_rmse=0.156633\n",
      "[Train epoch 40/50] loss=0.022831, train_rmse=0.152619\n",
      "[Train epoch 45/50] loss=0.019506, train_rmse=0.156072\n",
      "[Train epoch 50/50] loss=0.017789, train_rmse=0.147102\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1369840072221367\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 84 | labelled size = 860 | pool size = 59140 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.145961, train_rmse=0.295875\n",
      "[Train epoch 5/50] loss=0.072204, train_rmse=0.253994\n",
      "[Train epoch 10/50] loss=0.053891, train_rmse=0.209937\n",
      "[Train epoch 15/50] loss=0.041823, train_rmse=0.186392\n",
      "[Train epoch 20/50] loss=0.035237, train_rmse=0.180120\n",
      "[Train epoch 25/50] loss=0.031426, train_rmse=0.167389\n",
      "[Train epoch 30/50] loss=0.027115, train_rmse=0.159210\n",
      "[Train epoch 35/50] loss=0.024247, train_rmse=0.158300\n",
      "[Train epoch 40/50] loss=0.023010, train_rmse=0.155103\n",
      "[Train epoch 45/50] loss=0.021177, train_rmse=0.153754\n",
      "[Train epoch 50/50] loss=0.019275, train_rmse=0.145153\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13535781489211535\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 85 | labelled size = 870 | pool size = 59130 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.148269, train_rmse=0.293375\n",
      "[Train epoch 5/50] loss=0.067966, train_rmse=0.243883\n",
      "[Train epoch 10/50] loss=0.049994, train_rmse=0.203110\n",
      "[Train epoch 15/50] loss=0.039506, train_rmse=0.180890\n",
      "[Train epoch 20/50] loss=0.031231, train_rmse=0.165379\n",
      "[Train epoch 25/50] loss=0.028874, train_rmse=0.161021\n",
      "[Train epoch 30/50] loss=0.023756, train_rmse=0.154800\n",
      "[Train epoch 35/50] loss=0.020955, train_rmse=0.147650\n",
      "[Train epoch 40/50] loss=0.020798, train_rmse=0.150094\n",
      "[Train epoch 45/50] loss=0.019106, train_rmse=0.155893\n",
      "[Train epoch 50/50] loss=0.019449, train_rmse=0.159389\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13963718186481308\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 86 | labelled size = 880 | pool size = 59120 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.158447, train_rmse=0.301889\n",
      "[Train epoch 5/50] loss=0.074600, train_rmse=0.255320\n",
      "[Train epoch 10/50] loss=0.055616, train_rmse=0.215866\n",
      "[Train epoch 15/50] loss=0.046222, train_rmse=0.191941\n",
      "[Train epoch 20/50] loss=0.037437, train_rmse=0.175460\n",
      "[Train epoch 25/50] loss=0.031451, train_rmse=0.166898\n",
      "[Train epoch 30/50] loss=0.027322, train_rmse=0.158487\n",
      "[Train epoch 35/50] loss=0.024622, train_rmse=0.156428\n",
      "[Train epoch 40/50] loss=0.022508, train_rmse=0.151460\n",
      "[Train epoch 45/50] loss=0.020599, train_rmse=0.152008\n",
      "[Train epoch 50/50] loss=0.019526, train_rmse=0.153041\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13913899257415563\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 87 | labelled size = 890 | pool size = 59110 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.161173, train_rmse=0.298803\n",
      "[Train epoch 5/50] loss=0.073548, train_rmse=0.255400\n",
      "[Train epoch 10/50] loss=0.057789, train_rmse=0.219919\n",
      "[Train epoch 15/50] loss=0.045873, train_rmse=0.193244\n",
      "[Train epoch 20/50] loss=0.039292, train_rmse=0.178635\n",
      "[Train epoch 25/50] loss=0.032474, train_rmse=0.168020\n",
      "[Train epoch 30/50] loss=0.027975, train_rmse=0.160876\n",
      "[Train epoch 35/50] loss=0.025768, train_rmse=0.157264\n",
      "[Train epoch 40/50] loss=0.023012, train_rmse=0.155347\n",
      "[Train epoch 45/50] loss=0.020120, train_rmse=0.145679\n",
      "[Train epoch 50/50] loss=0.020438, train_rmse=0.150405\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13608665664616862\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 88 | labelled size = 900 | pool size = 59100 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.142300, train_rmse=0.292923\n",
      "[Train epoch 5/50] loss=0.067284, train_rmse=0.238243\n",
      "[Train epoch 10/50] loss=0.053375, train_rmse=0.204071\n",
      "[Train epoch 15/50] loss=0.042503, train_rmse=0.184541\n",
      "[Train epoch 20/50] loss=0.034453, train_rmse=0.168811\n",
      "[Train epoch 25/50] loss=0.032296, train_rmse=0.167219\n",
      "[Train epoch 30/50] loss=0.030557, train_rmse=0.166451\n",
      "[Train epoch 35/50] loss=0.026956, train_rmse=0.162905\n",
      "[Train epoch 40/50] loss=0.024029, train_rmse=0.152428\n",
      "[Train epoch 45/50] loss=0.024761, train_rmse=0.160211\n",
      "[Train epoch 50/50] loss=0.021370, train_rmse=0.153854\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1381655431381755\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 89 | labelled size = 910 | pool size = 59090 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.149830, train_rmse=0.297337\n",
      "[Train epoch 5/50] loss=0.069923, train_rmse=0.242133\n",
      "[Train epoch 10/50] loss=0.051901, train_rmse=0.207341\n",
      "[Train epoch 15/50] loss=0.040897, train_rmse=0.180317\n",
      "[Train epoch 20/50] loss=0.033606, train_rmse=0.166676\n",
      "[Train epoch 25/50] loss=0.029174, train_rmse=0.157984\n",
      "[Train epoch 30/50] loss=0.024652, train_rmse=0.152842\n",
      "[Train epoch 35/50] loss=0.022407, train_rmse=0.156032\n",
      "[Train epoch 40/50] loss=0.022411, train_rmse=0.150889\n",
      "[Train epoch 45/50] loss=0.020312, train_rmse=0.142221\n",
      "[Train epoch 50/50] loss=0.020622, train_rmse=0.151748\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13682950155470297\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 90 | labelled size = 920 | pool size = 59080 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.143300, train_rmse=0.294409\n",
      "[Train epoch 5/50] loss=0.069731, train_rmse=0.243262\n",
      "[Train epoch 10/50] loss=0.051166, train_rmse=0.198563\n",
      "[Train epoch 15/50] loss=0.037806, train_rmse=0.174960\n",
      "[Train epoch 20/50] loss=0.033386, train_rmse=0.162608\n",
      "[Train epoch 25/50] loss=0.027400, train_rmse=0.154325\n",
      "[Train epoch 30/50] loss=0.023591, train_rmse=0.146854\n",
      "[Train epoch 35/50] loss=0.022312, train_rmse=0.156023\n",
      "[Train epoch 40/50] loss=0.022499, train_rmse=0.157121\n",
      "[Train epoch 45/50] loss=0.020472, train_rmse=0.153240\n",
      "[Train epoch 50/50] loss=0.017804, train_rmse=0.143854\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13405565533360045\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 91 | labelled size = 930 | pool size = 59070 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.152438, train_rmse=0.302651\n",
      "[Train epoch 5/50] loss=0.073225, train_rmse=0.250384\n",
      "[Train epoch 10/50] loss=0.053969, train_rmse=0.209552\n",
      "[Train epoch 15/50] loss=0.040875, train_rmse=0.183667\n",
      "[Train epoch 20/50] loss=0.034240, train_rmse=0.171457\n",
      "[Train epoch 25/50] loss=0.030035, train_rmse=0.163102\n",
      "[Train epoch 30/50] loss=0.028154, train_rmse=0.159914\n",
      "[Train epoch 35/50] loss=0.022854, train_rmse=0.154337\n",
      "[Train epoch 40/50] loss=0.022529, train_rmse=0.156051\n",
      "[Train epoch 45/50] loss=0.021122, train_rmse=0.156983\n",
      "[Train epoch 50/50] loss=0.018827, train_rmse=0.144275\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1321352335089453\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 92 | labelled size = 940 | pool size = 59060 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.133892, train_rmse=0.288992\n",
      "[Train epoch 5/50] loss=0.066586, train_rmse=0.232862\n",
      "[Train epoch 10/50] loss=0.047066, train_rmse=0.193140\n",
      "[Train epoch 15/50] loss=0.036167, train_rmse=0.173379\n",
      "[Train epoch 20/50] loss=0.029766, train_rmse=0.158765\n",
      "[Train epoch 25/50] loss=0.024411, train_rmse=0.156812\n",
      "[Train epoch 30/50] loss=0.022228, train_rmse=0.158176\n",
      "[Train epoch 35/50] loss=0.021557, train_rmse=0.151794\n",
      "[Train epoch 40/50] loss=0.020221, train_rmse=0.144127\n",
      "[Train epoch 45/50] loss=0.018143, train_rmse=0.143426\n",
      "[Train epoch 50/50] loss=0.017786, train_rmse=0.147711\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13366733467065142\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 93 | labelled size = 950 | pool size = 59050 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.167066, train_rmse=0.297435\n",
      "[Train epoch 5/50] loss=0.073062, train_rmse=0.250814\n",
      "[Train epoch 10/50] loss=0.057573, train_rmse=0.219796\n",
      "[Train epoch 15/50] loss=0.044358, train_rmse=0.190897\n",
      "[Train epoch 20/50] loss=0.036814, train_rmse=0.172367\n",
      "[Train epoch 25/50] loss=0.030667, train_rmse=0.159089\n",
      "[Train epoch 30/50] loss=0.027539, train_rmse=0.158114\n",
      "[Train epoch 35/50] loss=0.023257, train_rmse=0.161048\n",
      "[Train epoch 40/50] loss=0.021769, train_rmse=0.150320\n",
      "[Train epoch 45/50] loss=0.020768, train_rmse=0.155052\n",
      "[Train epoch 50/50] loss=0.020704, train_rmse=0.154743\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13688582336186933\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 94 | labelled size = 960 | pool size = 59040 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.137324, train_rmse=0.292364\n",
      "[Train epoch 5/50] loss=0.067552, train_rmse=0.237376\n",
      "[Train epoch 10/50] loss=0.048431, train_rmse=0.195377\n",
      "[Train epoch 15/50] loss=0.036643, train_rmse=0.166926\n",
      "[Train epoch 20/50] loss=0.029258, train_rmse=0.156081\n",
      "[Train epoch 25/50] loss=0.024275, train_rmse=0.149544\n",
      "[Train epoch 30/50] loss=0.021871, train_rmse=0.146737\n",
      "[Train epoch 35/50] loss=0.020181, train_rmse=0.144666\n",
      "[Train epoch 40/50] loss=0.019040, train_rmse=0.146988\n",
      "[Train epoch 45/50] loss=0.018390, train_rmse=0.144467\n",
      "[Train epoch 50/50] loss=0.016994, train_rmse=0.139412\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1295362514455188\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 95 | labelled size = 970 | pool size = 59030 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.145361, train_rmse=0.291184\n",
      "[Train epoch 5/50] loss=0.071301, train_rmse=0.250130\n",
      "[Train epoch 10/50] loss=0.054844, train_rmse=0.209347\n",
      "[Train epoch 15/50] loss=0.044349, train_rmse=0.183937\n",
      "[Train epoch 20/50] loss=0.035966, train_rmse=0.174568\n",
      "[Train epoch 25/50] loss=0.031473, train_rmse=0.166554\n",
      "[Train epoch 30/50] loss=0.028575, train_rmse=0.157195\n",
      "[Train epoch 35/50] loss=0.025289, train_rmse=0.150319\n",
      "[Train epoch 40/50] loss=0.025498, train_rmse=0.152317\n",
      "[Train epoch 45/50] loss=0.023746, train_rmse=0.159491\n",
      "[Train epoch 50/50] loss=0.020559, train_rmse=0.152446\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13401241722150634\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 96 | labelled size = 980 | pool size = 59020 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.130203, train_rmse=0.289021\n",
      "[Train epoch 5/50] loss=0.062493, train_rmse=0.220659\n",
      "[Train epoch 10/50] loss=0.043405, train_rmse=0.182363\n",
      "[Train epoch 15/50] loss=0.032448, train_rmse=0.161100\n",
      "[Train epoch 20/50] loss=0.027757, train_rmse=0.150904\n",
      "[Train epoch 25/50] loss=0.024875, train_rmse=0.152977\n",
      "[Train epoch 30/50] loss=0.022894, train_rmse=0.153068\n",
      "[Train epoch 35/50] loss=0.021028, train_rmse=0.149203\n",
      "[Train epoch 40/50] loss=0.019420, train_rmse=0.146135\n",
      "[Train epoch 45/50] loss=0.018580, train_rmse=0.143774\n",
      "[Train epoch 50/50] loss=0.017565, train_rmse=0.149155\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13253031412669844\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 97 | labelled size = 990 | pool size = 59010 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.133497, train_rmse=0.292615\n",
      "[Train epoch 5/50] loss=0.066439, train_rmse=0.231944\n",
      "[Train epoch 10/50] loss=0.045852, train_rmse=0.188674\n",
      "[Train epoch 15/50] loss=0.035095, train_rmse=0.161787\n",
      "[Train epoch 20/50] loss=0.030029, train_rmse=0.152595\n",
      "[Train epoch 25/50] loss=0.024629, train_rmse=0.144667\n",
      "[Train epoch 30/50] loss=0.023579, train_rmse=0.148739\n",
      "[Train epoch 35/50] loss=0.021081, train_rmse=0.148004\n",
      "[Train epoch 40/50] loss=0.019696, train_rmse=0.152612\n",
      "[Train epoch 45/50] loss=0.017791, train_rmse=0.141087\n",
      "[Train epoch 50/50] loss=0.017611, train_rmse=0.147890\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1341087855841991\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 98 | labelled size = 1000 | pool size = 59000 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.146950, train_rmse=0.298687\n",
      "[Train epoch 5/50] loss=0.070153, train_rmse=0.239249\n",
      "[Train epoch 10/50] loss=0.052555, train_rmse=0.198292\n",
      "[Train epoch 15/50] loss=0.041362, train_rmse=0.176340\n",
      "[Train epoch 20/50] loss=0.032653, train_rmse=0.163733\n",
      "[Train epoch 25/50] loss=0.027854, train_rmse=0.156521\n",
      "[Train epoch 30/50] loss=0.023996, train_rmse=0.147332\n",
      "[Train epoch 35/50] loss=0.022256, train_rmse=0.143008\n",
      "[Train epoch 40/50] loss=0.021792, train_rmse=0.148666\n",
      "[Train epoch 45/50] loss=0.020255, train_rmse=0.146663\n",
      "[Train epoch 50/50] loss=0.018459, train_rmse=0.143626\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1303336731155451\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 99 | labelled size = 1010 | pool size = 58990 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.140962, train_rmse=0.298527\n",
      "[Train epoch 5/50] loss=0.073224, train_rmse=0.254634\n",
      "[Train epoch 10/50] loss=0.056389, train_rmse=0.207810\n",
      "[Train epoch 15/50] loss=0.043665, train_rmse=0.182245\n",
      "[Train epoch 20/50] loss=0.035345, train_rmse=0.163900\n",
      "[Train epoch 25/50] loss=0.031431, train_rmse=0.157763\n",
      "[Train epoch 30/50] loss=0.028621, train_rmse=0.158514\n",
      "[Train epoch 35/50] loss=0.026036, train_rmse=0.151029\n",
      "[Train epoch 40/50] loss=0.022878, train_rmse=0.150068\n",
      "[Train epoch 45/50] loss=0.022247, train_rmse=0.149600\n",
      "[Train epoch 50/50] loss=0.019458, train_rmse=0.147048\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1311129217712575\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 100 | labelled size = 1020 | pool size = 58980 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.134152, train_rmse=0.289819\n",
      "[Train epoch 5/50] loss=0.064492, train_rmse=0.228403\n",
      "[Train epoch 10/50] loss=0.046773, train_rmse=0.190292\n",
      "[Train epoch 15/50] loss=0.033617, train_rmse=0.162712\n",
      "[Train epoch 20/50] loss=0.029541, train_rmse=0.160145\n",
      "[Train epoch 25/50] loss=0.025128, train_rmse=0.144317\n",
      "[Train epoch 30/50] loss=0.022506, train_rmse=0.147725\n",
      "[Train epoch 35/50] loss=0.022562, train_rmse=0.149065\n",
      "[Train epoch 40/50] loss=0.019157, train_rmse=0.149769\n",
      "[Train epoch 45/50] loss=0.017908, train_rmse=0.144544\n",
      "[Train epoch 50/50] loss=0.017615, train_rmse=0.146171\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1329212117549088\n",
      "Results saved to outputs/bnn_ssl/history_BNN_Analytical_PredCovariance_Run3.json\n",
      "\n",
      "\n",
      "========== Running PredCovariance Seed 4 ==========\n",
      "Starting SSL pretraining (rotation)...\n",
      "[SSL epoch 1/5] loss=0.0970\n",
      "[SSL epoch 2/5] loss=0.0480\n",
      "[SSL epoch 3/5] loss=0.0428\n",
      "[SSL epoch 4/5] loss=0.0397\n",
      "[SSL epoch 5/5] loss=0.0361\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "Training dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "Initial Labelled set size: 20\n",
      "\n",
      "=== Acquisition iteration 0 | labelled size = 20 | pool size = 59980 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.102191, train_rmse=0.310331\n",
      "[Train epoch 5/50] loss=0.085199, train_rmse=0.291251\n",
      "[Train epoch 10/50] loss=0.062488, train_rmse=0.283453\n",
      "[Train epoch 15/50] loss=0.043239, train_rmse=0.273994\n",
      "[Train epoch 20/50] loss=0.032555, train_rmse=0.270984\n",
      "[Train epoch 25/50] loss=0.025301, train_rmse=0.269533\n",
      "[Train epoch 30/50] loss=0.021020, train_rmse=0.268876\n",
      "[Train epoch 35/50] loss=0.016895, train_rmse=0.269311\n",
      "[Train epoch 40/50] loss=0.019567, train_rmse=0.267752\n",
      "[Train epoch 45/50] loss=0.018108, train_rmse=0.267701\n",
      "[Train epoch 50/50] loss=0.017674, train_rmse=0.270476\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2667755284271712\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 1 | labelled size = 30 | pool size = 59970 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.105466, train_rmse=0.312079\n",
      "[Train epoch 5/50] loss=0.080232, train_rmse=0.300623\n",
      "[Train epoch 10/50] loss=0.064212, train_rmse=0.287936\n",
      "[Train epoch 15/50] loss=0.050305, train_rmse=0.279102\n",
      "[Train epoch 20/50] loss=0.041157, train_rmse=0.267489\n",
      "[Train epoch 25/50] loss=0.045615, train_rmse=0.263339\n",
      "[Train epoch 30/50] loss=0.032365, train_rmse=0.257645\n",
      "[Train epoch 35/50] loss=0.027740, train_rmse=0.253664\n",
      "[Train epoch 40/50] loss=0.024821, train_rmse=0.253209\n",
      "[Train epoch 45/50] loss=0.018881, train_rmse=0.252254\n",
      "[Train epoch 50/50] loss=0.017769, train_rmse=0.252328\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24592884489580574\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 2 | labelled size = 40 | pool size = 59960 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.130157, train_rmse=0.487532\n",
      "[Train epoch 5/50] loss=0.140040, train_rmse=0.310216\n",
      "[Train epoch 10/50] loss=0.088631, train_rmse=0.300074\n",
      "[Train epoch 15/50] loss=0.086658, train_rmse=0.302578\n",
      "[Train epoch 20/50] loss=0.073293, train_rmse=0.292553\n",
      "[Train epoch 25/50] loss=0.066742, train_rmse=0.288316\n",
      "[Train epoch 30/50] loss=0.063470, train_rmse=0.283914\n",
      "[Train epoch 35/50] loss=0.055035, train_rmse=0.277917\n",
      "[Train epoch 40/50] loss=0.058860, train_rmse=0.276334\n",
      "[Train epoch 45/50] loss=0.044184, train_rmse=0.273393\n",
      "[Train epoch 50/50] loss=0.040366, train_rmse=0.268384\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24491886074030464\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 3 | labelled size = 50 | pool size = 59950 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.412191, train_rmse=1.831627\n",
      "[Train epoch 5/50] loss=0.287917, train_rmse=0.321368\n",
      "[Train epoch 10/50] loss=0.131134, train_rmse=0.306908\n",
      "[Train epoch 15/50] loss=0.096604, train_rmse=0.306488\n",
      "[Train epoch 20/50] loss=0.091834, train_rmse=0.305829\n",
      "[Train epoch 25/50] loss=0.084755, train_rmse=0.302245\n",
      "[Train epoch 30/50] loss=0.089209, train_rmse=0.300394\n",
      "[Train epoch 35/50] loss=0.084970, train_rmse=0.298962\n",
      "[Train epoch 40/50] loss=0.083456, train_rmse=0.295654\n",
      "[Train epoch 45/50] loss=0.077736, train_rmse=0.292966\n",
      "[Train epoch 50/50] loss=0.072643, train_rmse=0.290491\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2715297917377248\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 4 | labelled size = 60 | pool size = 59940 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=6.617335, train_rmse=4.081849\n",
      "[Train epoch 5/50] loss=9.238000, train_rmse=2.289589\n",
      "[Train epoch 10/50] loss=3.374557, train_rmse=0.757641\n",
      "[Train epoch 15/50] loss=0.483707, train_rmse=0.316916\n",
      "[Train epoch 20/50] loss=0.288920, train_rmse=0.335107\n",
      "[Train epoch 25/50] loss=0.171245, train_rmse=0.317984\n",
      "[Train epoch 30/50] loss=0.137015, train_rmse=0.313113\n",
      "[Train epoch 35/50] loss=0.102625, train_rmse=0.311613\n",
      "[Train epoch 40/50] loss=0.097584, train_rmse=0.309740\n",
      "[Train epoch 45/50] loss=0.095988, train_rmse=0.307791\n",
      "[Train epoch 50/50] loss=0.097329, train_rmse=0.306226\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2946029600721146\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 5 | labelled size = 70 | pool size = 59930 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.964604, train_rmse=0.462489\n",
      "[Train epoch 5/50] loss=1.273388, train_rmse=0.339520\n",
      "[Train epoch 10/50] loss=0.199224, train_rmse=0.353443\n",
      "[Train epoch 15/50] loss=0.136384, train_rmse=0.305393\n",
      "[Train epoch 20/50] loss=0.094280, train_rmse=0.306703\n",
      "[Train epoch 25/50] loss=0.086116, train_rmse=0.301974\n",
      "[Train epoch 30/50] loss=0.104206, train_rmse=0.295206\n",
      "[Train epoch 35/50] loss=0.071521, train_rmse=0.293201\n",
      "[Train epoch 40/50] loss=0.066597, train_rmse=0.290373\n",
      "[Train epoch 45/50] loss=0.062969, train_rmse=0.286962\n",
      "[Train epoch 50/50] loss=0.059789, train_rmse=0.283659\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.3057538805424493\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 6 | labelled size = 80 | pool size = 59920 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=1.438065, train_rmse=1.146817\n",
      "[Train epoch 5/50] loss=0.524321, train_rmse=0.373261\n",
      "[Train epoch 10/50] loss=0.130050, train_rmse=0.316159\n",
      "[Train epoch 15/50] loss=0.094313, train_rmse=0.308746\n",
      "[Train epoch 20/50] loss=0.082579, train_rmse=0.300878\n",
      "[Train epoch 25/50] loss=0.071919, train_rmse=0.300064\n",
      "[Train epoch 30/50] loss=0.070111, train_rmse=0.297954\n",
      "[Train epoch 35/50] loss=0.066515, train_rmse=0.295319\n",
      "[Train epoch 40/50] loss=0.061830, train_rmse=0.292831\n",
      "[Train epoch 45/50] loss=0.062883, train_rmse=0.289087\n",
      "[Train epoch 50/50] loss=0.060490, train_rmse=0.287021\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2597412326643854\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 7 | labelled size = 90 | pool size = 59910 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=30.794659, train_rmse=3.874170\n",
      "[Train epoch 5/50] loss=2.544339, train_rmse=0.564337\n",
      "[Train epoch 10/50] loss=0.424026, train_rmse=0.318864\n",
      "[Train epoch 15/50] loss=0.201515, train_rmse=0.316142\n",
      "[Train epoch 20/50] loss=0.123043, train_rmse=0.315671\n",
      "[Train epoch 25/50] loss=0.119030, train_rmse=0.313784\n",
      "[Train epoch 30/50] loss=0.097579, train_rmse=0.308317\n",
      "[Train epoch 35/50] loss=0.102772, train_rmse=0.306249\n",
      "[Train epoch 40/50] loss=0.083561, train_rmse=0.306224\n",
      "[Train epoch 45/50] loss=0.081151, train_rmse=0.303538\n",
      "[Train epoch 50/50] loss=0.075076, train_rmse=0.300477\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2679949898820838\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 8 | labelled size = 100 | pool size = 59900 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=1.817679, train_rmse=1.296749\n",
      "[Train epoch 5/50] loss=0.307410, train_rmse=0.315056\n",
      "[Train epoch 10/50] loss=0.109911, train_rmse=0.306242\n",
      "[Train epoch 15/50] loss=0.075556, train_rmse=0.300166\n",
      "[Train epoch 20/50] loss=0.070974, train_rmse=0.293326\n",
      "[Train epoch 25/50] loss=0.064219, train_rmse=0.290408\n",
      "[Train epoch 30/50] loss=0.059512, train_rmse=0.285412\n",
      "[Train epoch 35/50] loss=0.055518, train_rmse=0.284320\n",
      "[Train epoch 40/50] loss=0.050769, train_rmse=0.281730\n",
      "[Train epoch 45/50] loss=0.048950, train_rmse=0.279195\n",
      "[Train epoch 50/50] loss=0.045892, train_rmse=0.276736\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24490552369068813\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 9 | labelled size = 110 | pool size = 59890 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=35.718978, train_rmse=1.632210\n",
      "[Train epoch 5/50] loss=0.850979, train_rmse=0.406495\n",
      "[Train epoch 10/50] loss=0.319240, train_rmse=0.321111\n",
      "[Train epoch 15/50] loss=0.118024, train_rmse=0.314638\n",
      "[Train epoch 20/50] loss=0.098938, train_rmse=0.311748\n",
      "[Train epoch 25/50] loss=0.092160, train_rmse=0.306161\n",
      "[Train epoch 30/50] loss=0.082620, train_rmse=0.303662\n",
      "[Train epoch 35/50] loss=0.079844, train_rmse=0.304369\n",
      "[Train epoch 40/50] loss=0.078876, train_rmse=0.301443\n",
      "[Train epoch 45/50] loss=0.074477, train_rmse=0.298006\n",
      "[Train epoch 50/50] loss=0.070658, train_rmse=0.295995\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2736624383979205\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 10 | labelled size = 120 | pool size = 59880 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=2.160227, train_rmse=0.381401\n",
      "[Train epoch 5/50] loss=0.136754, train_rmse=0.311724\n",
      "[Train epoch 10/50] loss=0.086997, train_rmse=0.305235\n",
      "[Train epoch 15/50] loss=0.074968, train_rmse=0.300282\n",
      "[Train epoch 20/50] loss=0.067679, train_rmse=0.296472\n",
      "[Train epoch 25/50] loss=0.059711, train_rmse=0.288705\n",
      "[Train epoch 30/50] loss=0.060782, train_rmse=0.286625\n",
      "[Train epoch 35/50] loss=0.056610, train_rmse=0.283998\n",
      "[Train epoch 40/50] loss=0.053566, train_rmse=0.280618\n",
      "[Train epoch 45/50] loss=0.049765, train_rmse=0.277669\n",
      "[Train epoch 50/50] loss=0.046078, train_rmse=0.275735\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24456452482473748\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 11 | labelled size = 130 | pool size = 59870 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=1.482255, train_rmse=0.439299\n",
      "[Train epoch 5/50] loss=0.108980, train_rmse=0.309085\n",
      "[Train epoch 10/50] loss=0.079504, train_rmse=0.299506\n",
      "[Train epoch 15/50] loss=0.078058, train_rmse=0.295165\n",
      "[Train epoch 20/50] loss=0.069063, train_rmse=0.290129\n",
      "[Train epoch 25/50] loss=0.068347, train_rmse=0.287749\n",
      "[Train epoch 30/50] loss=0.060428, train_rmse=0.288206\n",
      "[Train epoch 35/50] loss=0.060310, train_rmse=0.279789\n",
      "[Train epoch 40/50] loss=0.057289, train_rmse=0.279059\n",
      "[Train epoch 45/50] loss=0.056231, train_rmse=0.278259\n",
      "[Train epoch 50/50] loss=0.049875, train_rmse=0.278109\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24804392318771445\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 12 | labelled size = 140 | pool size = 59860 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.997229, train_rmse=0.442415\n",
      "[Train epoch 5/50] loss=0.103612, train_rmse=0.303743\n",
      "[Train epoch 10/50] loss=0.075331, train_rmse=0.293417\n",
      "[Train epoch 15/50] loss=0.063530, train_rmse=0.287552\n",
      "[Train epoch 20/50] loss=0.057918, train_rmse=0.275444\n",
      "[Train epoch 25/50] loss=0.051241, train_rmse=0.272566\n",
      "[Train epoch 30/50] loss=0.046535, train_rmse=0.268928\n",
      "[Train epoch 35/50] loss=0.045629, train_rmse=0.271270\n",
      "[Train epoch 40/50] loss=0.041522, train_rmse=0.263670\n",
      "[Train epoch 45/50] loss=0.039100, train_rmse=0.257761\n",
      "[Train epoch 50/50] loss=0.036308, train_rmse=0.257725\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.22761029093611695\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 13 | labelled size = 150 | pool size = 59850 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=3.322085, train_rmse=0.709084\n",
      "[Train epoch 5/50] loss=0.256207, train_rmse=0.323595\n",
      "[Train epoch 10/50] loss=0.097599, train_rmse=0.310033\n",
      "[Train epoch 15/50] loss=0.086185, train_rmse=0.298808\n",
      "[Train epoch 20/50] loss=0.077827, train_rmse=0.297636\n",
      "[Train epoch 25/50] loss=0.072111, train_rmse=0.293381\n",
      "[Train epoch 30/50] loss=0.068468, train_rmse=0.288382\n",
      "[Train epoch 35/50] loss=0.064727, train_rmse=0.283563\n",
      "[Train epoch 40/50] loss=0.060423, train_rmse=0.281572\n",
      "[Train epoch 45/50] loss=0.059572, train_rmse=0.276751\n",
      "[Train epoch 50/50] loss=0.054024, train_rmse=0.272799\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.23759410393219546\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 14 | labelled size = 160 | pool size = 59840 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.166928, train_rmse=0.298650\n",
      "[Train epoch 5/50] loss=0.066696, train_rmse=0.278014\n",
      "[Train epoch 10/50] loss=0.052156, train_rmse=0.271568\n",
      "[Train epoch 15/50] loss=0.041656, train_rmse=0.261368\n",
      "[Train epoch 20/50] loss=0.034470, train_rmse=0.258195\n",
      "[Train epoch 25/50] loss=0.031423, train_rmse=0.252925\n",
      "[Train epoch 30/50] loss=0.027840, train_rmse=0.249957\n",
      "[Train epoch 35/50] loss=0.029444, train_rmse=0.248996\n",
      "[Train epoch 40/50] loss=0.026679, train_rmse=0.246357\n",
      "[Train epoch 45/50] loss=0.025554, train_rmse=0.248246\n",
      "[Train epoch 50/50] loss=0.022802, train_rmse=0.248550\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.22236858124713835\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 15 | labelled size = 170 | pool size = 59830 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.576369, train_rmse=0.407859\n",
      "[Train epoch 5/50] loss=0.086814, train_rmse=0.300997\n",
      "[Train epoch 10/50] loss=0.068301, train_rmse=0.286521\n",
      "[Train epoch 15/50] loss=0.060525, train_rmse=0.275906\n",
      "[Train epoch 20/50] loss=0.051119, train_rmse=0.268424\n",
      "[Train epoch 25/50] loss=0.044833, train_rmse=0.261083\n",
      "[Train epoch 30/50] loss=0.040510, train_rmse=0.254732\n",
      "[Train epoch 35/50] loss=0.038472, train_rmse=0.250276\n",
      "[Train epoch 40/50] loss=0.035182, train_rmse=0.248892\n",
      "[Train epoch 45/50] loss=0.031930, train_rmse=0.249255\n",
      "[Train epoch 50/50] loss=0.028666, train_rmse=0.245273\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21416294991079649\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 16 | labelled size = 180 | pool size = 59820 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.596341, train_rmse=0.420370\n",
      "[Train epoch 5/50] loss=0.091531, train_rmse=0.305365\n",
      "[Train epoch 10/50] loss=0.074048, train_rmse=0.289211\n",
      "[Train epoch 15/50] loss=0.066557, train_rmse=0.279189\n",
      "[Train epoch 20/50] loss=0.063692, train_rmse=0.273731\n",
      "[Train epoch 25/50] loss=0.055544, train_rmse=0.265043\n",
      "[Train epoch 30/50] loss=0.049250, train_rmse=0.256999\n",
      "[Train epoch 35/50] loss=0.042824, train_rmse=0.254646\n",
      "[Train epoch 40/50] loss=0.041476, train_rmse=0.252198\n",
      "[Train epoch 45/50] loss=0.037599, train_rmse=0.250309\n",
      "[Train epoch 50/50] loss=0.035825, train_rmse=0.242983\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21275699944866613\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 17 | labelled size = 190 | pool size = 59810 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.539502, train_rmse=0.362903\n",
      "[Train epoch 5/50] loss=0.088974, train_rmse=0.304360\n",
      "[Train epoch 10/50] loss=0.071937, train_rmse=0.277782\n",
      "[Train epoch 15/50] loss=0.060806, train_rmse=0.268835\n",
      "[Train epoch 20/50] loss=0.055449, train_rmse=0.262608\n",
      "[Train epoch 25/50] loss=0.049487, train_rmse=0.257290\n",
      "[Train epoch 30/50] loss=0.042965, train_rmse=0.250189\n",
      "[Train epoch 35/50] loss=0.037846, train_rmse=0.242475\n",
      "[Train epoch 40/50] loss=0.036502, train_rmse=0.241085\n",
      "[Train epoch 45/50] loss=0.032364, train_rmse=0.239396\n",
      "[Train epoch 50/50] loss=0.031313, train_rmse=0.238796\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2133314902355129\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 18 | labelled size = 200 | pool size = 59800 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.752113, train_rmse=0.367999\n",
      "[Train epoch 5/50] loss=0.093284, train_rmse=0.306592\n",
      "[Train epoch 10/50] loss=0.076843, train_rmse=0.287692\n",
      "[Train epoch 15/50] loss=0.064875, train_rmse=0.275937\n",
      "[Train epoch 20/50] loss=0.057177, train_rmse=0.268333\n",
      "[Train epoch 25/50] loss=0.053641, train_rmse=0.263710\n",
      "[Train epoch 30/50] loss=0.048462, train_rmse=0.258311\n",
      "[Train epoch 35/50] loss=0.044555, train_rmse=0.251001\n",
      "[Train epoch 40/50] loss=0.039022, train_rmse=0.252305\n",
      "[Train epoch 45/50] loss=0.040743, train_rmse=0.246817\n",
      "[Train epoch 50/50] loss=0.036569, train_rmse=0.244454\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21023562304162824\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 19 | labelled size = 210 | pool size = 59790 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.388577, train_rmse=0.329744\n",
      "[Train epoch 5/50] loss=0.084937, train_rmse=0.293803\n",
      "[Train epoch 10/50] loss=0.069137, train_rmse=0.279362\n",
      "[Train epoch 15/50] loss=0.055643, train_rmse=0.265123\n",
      "[Train epoch 20/50] loss=0.046912, train_rmse=0.253766\n",
      "[Train epoch 25/50] loss=0.043360, train_rmse=0.250957\n",
      "[Train epoch 30/50] loss=0.039910, train_rmse=0.247410\n",
      "[Train epoch 35/50] loss=0.037096, train_rmse=0.243894\n",
      "[Train epoch 40/50] loss=0.034996, train_rmse=0.237529\n",
      "[Train epoch 45/50] loss=0.028567, train_rmse=0.236678\n",
      "[Train epoch 50/50] loss=0.027263, train_rmse=0.233489\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.210555873620518\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 20 | labelled size = 220 | pool size = 59780 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.393169, train_rmse=0.328504\n",
      "[Train epoch 5/50] loss=0.084723, train_rmse=0.292902\n",
      "[Train epoch 10/50] loss=0.068572, train_rmse=0.273564\n",
      "[Train epoch 15/50] loss=0.054293, train_rmse=0.259052\n",
      "[Train epoch 20/50] loss=0.046171, train_rmse=0.252434\n",
      "[Train epoch 25/50] loss=0.043217, train_rmse=0.246945\n",
      "[Train epoch 30/50] loss=0.036917, train_rmse=0.242642\n",
      "[Train epoch 35/50] loss=0.035227, train_rmse=0.238301\n",
      "[Train epoch 40/50] loss=0.033819, train_rmse=0.235860\n",
      "[Train epoch 45/50] loss=0.029374, train_rmse=0.236138\n",
      "[Train epoch 50/50] loss=0.029815, train_rmse=0.234448\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20280287294506616\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 21 | labelled size = 230 | pool size = 59770 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.406119, train_rmse=0.335472\n",
      "[Train epoch 5/50] loss=0.078950, train_rmse=0.285195\n",
      "[Train epoch 10/50] loss=0.066926, train_rmse=0.269915\n",
      "[Train epoch 15/50] loss=0.053944, train_rmse=0.259812\n",
      "[Train epoch 20/50] loss=0.046381, train_rmse=0.250523\n",
      "[Train epoch 25/50] loss=0.041209, train_rmse=0.245694\n",
      "[Train epoch 30/50] loss=0.033435, train_rmse=0.239051\n",
      "[Train epoch 35/50] loss=0.034139, train_rmse=0.234108\n",
      "[Train epoch 40/50] loss=0.029735, train_rmse=0.232965\n",
      "[Train epoch 45/50] loss=0.026437, train_rmse=0.230103\n",
      "[Train epoch 50/50] loss=0.024155, train_rmse=0.227872\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2096459345205263\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 22 | labelled size = 240 | pool size = 59760 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.339809, train_rmse=0.340660\n",
      "[Train epoch 5/50] loss=0.079948, train_rmse=0.282519\n",
      "[Train epoch 10/50] loss=0.060477, train_rmse=0.266935\n",
      "[Train epoch 15/50] loss=0.051214, train_rmse=0.255697\n",
      "[Train epoch 20/50] loss=0.041998, train_rmse=0.245641\n",
      "[Train epoch 25/50] loss=0.038571, train_rmse=0.235285\n",
      "[Train epoch 30/50] loss=0.033637, train_rmse=0.237367\n",
      "[Train epoch 35/50] loss=0.029170, train_rmse=0.233348\n",
      "[Train epoch 40/50] loss=0.028601, train_rmse=0.230534\n",
      "[Train epoch 45/50] loss=0.024525, train_rmse=0.226153\n",
      "[Train epoch 50/50] loss=0.024430, train_rmse=0.226464\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20126499717228893\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 23 | labelled size = 250 | pool size = 59750 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.550276, train_rmse=0.323110\n",
      "[Train epoch 5/50] loss=0.088474, train_rmse=0.295789\n",
      "[Train epoch 10/50] loss=0.071417, train_rmse=0.280237\n",
      "[Train epoch 15/50] loss=0.059795, train_rmse=0.263267\n",
      "[Train epoch 20/50] loss=0.053824, train_rmse=0.252539\n",
      "[Train epoch 25/50] loss=0.047926, train_rmse=0.248154\n",
      "[Train epoch 30/50] loss=0.041274, train_rmse=0.240795\n",
      "[Train epoch 35/50] loss=0.038102, train_rmse=0.236963\n",
      "[Train epoch 40/50] loss=0.034768, train_rmse=0.234553\n",
      "[Train epoch 45/50] loss=0.034064, train_rmse=0.233801\n",
      "[Train epoch 50/50] loss=0.030307, train_rmse=0.229876\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20961370743899624\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 24 | labelled size = 260 | pool size = 59740 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.346941, train_rmse=0.328148\n",
      "[Train epoch 5/50] loss=0.084247, train_rmse=0.288352\n",
      "[Train epoch 10/50] loss=0.068505, train_rmse=0.269501\n",
      "[Train epoch 15/50] loss=0.060004, train_rmse=0.257440\n",
      "[Train epoch 20/50] loss=0.054241, train_rmse=0.250421\n",
      "[Train epoch 25/50] loss=0.047508, train_rmse=0.246148\n",
      "[Train epoch 30/50] loss=0.046330, train_rmse=0.246910\n",
      "[Train epoch 35/50] loss=0.038802, train_rmse=0.237638\n",
      "[Train epoch 40/50] loss=0.034241, train_rmse=0.232672\n",
      "[Train epoch 45/50] loss=0.037072, train_rmse=0.235086\n",
      "[Train epoch 50/50] loss=0.031439, train_rmse=0.233042\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20830438722045805\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 25 | labelled size = 270 | pool size = 59730 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.352360, train_rmse=0.322009\n",
      "[Train epoch 5/50] loss=0.078633, train_rmse=0.283944\n",
      "[Train epoch 10/50] loss=0.063021, train_rmse=0.264966\n",
      "[Train epoch 15/50] loss=0.053647, train_rmse=0.252774\n",
      "[Train epoch 20/50] loss=0.045103, train_rmse=0.243676\n",
      "[Train epoch 25/50] loss=0.039753, train_rmse=0.243830\n",
      "[Train epoch 30/50] loss=0.034998, train_rmse=0.234492\n",
      "[Train epoch 35/50] loss=0.033005, train_rmse=0.232163\n",
      "[Train epoch 40/50] loss=0.030481, train_rmse=0.228723\n",
      "[Train epoch 45/50] loss=0.027072, train_rmse=0.231846\n",
      "[Train epoch 50/50] loss=0.026316, train_rmse=0.223956\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19754961894642337\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 26 | labelled size = 280 | pool size = 59720 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.331127, train_rmse=0.319804\n",
      "[Train epoch 5/50] loss=0.080127, train_rmse=0.283873\n",
      "[Train epoch 10/50] loss=0.062958, train_rmse=0.265191\n",
      "[Train epoch 15/50] loss=0.051495, train_rmse=0.247541\n",
      "[Train epoch 20/50] loss=0.043631, train_rmse=0.239852\n",
      "[Train epoch 25/50] loss=0.038347, train_rmse=0.230497\n",
      "[Train epoch 30/50] loss=0.034232, train_rmse=0.227312\n",
      "[Train epoch 35/50] loss=0.030559, train_rmse=0.228333\n",
      "[Train epoch 40/50] loss=0.026276, train_rmse=0.224711\n",
      "[Train epoch 45/50] loss=0.026347, train_rmse=0.223788\n",
      "[Train epoch 50/50] loss=0.026050, train_rmse=0.222167\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19408434488445928\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 27 | labelled size = 290 | pool size = 59710 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.399104, train_rmse=0.325638\n",
      "[Train epoch 5/50] loss=0.080723, train_rmse=0.283184\n",
      "[Train epoch 10/50] loss=0.063342, train_rmse=0.259607\n",
      "[Train epoch 15/50] loss=0.050351, train_rmse=0.247101\n",
      "[Train epoch 20/50] loss=0.044567, train_rmse=0.237610\n",
      "[Train epoch 25/50] loss=0.037866, train_rmse=0.232112\n",
      "[Train epoch 30/50] loss=0.034578, train_rmse=0.225205\n",
      "[Train epoch 35/50] loss=0.029638, train_rmse=0.222607\n",
      "[Train epoch 40/50] loss=0.027357, train_rmse=0.223346\n",
      "[Train epoch 45/50] loss=0.024416, train_rmse=0.221569\n",
      "[Train epoch 50/50] loss=0.024075, train_rmse=0.215111\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19514361907668212\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 28 | labelled size = 300 | pool size = 59700 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.485521, train_rmse=0.323551\n",
      "[Train epoch 5/50] loss=0.084179, train_rmse=0.290137\n",
      "[Train epoch 10/50] loss=0.071877, train_rmse=0.274818\n",
      "[Train epoch 15/50] loss=0.061820, train_rmse=0.257527\n",
      "[Train epoch 20/50] loss=0.051534, train_rmse=0.248371\n",
      "[Train epoch 25/50] loss=0.045871, train_rmse=0.240496\n",
      "[Train epoch 30/50] loss=0.039676, train_rmse=0.233409\n",
      "[Train epoch 35/50] loss=0.036158, train_rmse=0.232301\n",
      "[Train epoch 40/50] loss=0.030603, train_rmse=0.224787\n",
      "[Train epoch 45/50] loss=0.028928, train_rmse=0.223588\n",
      "[Train epoch 50/50] loss=0.026001, train_rmse=0.222239\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20071458682084686\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 29 | labelled size = 310 | pool size = 59690 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.499664, train_rmse=0.328484\n",
      "[Train epoch 5/50] loss=0.083067, train_rmse=0.289356\n",
      "[Train epoch 10/50] loss=0.068234, train_rmse=0.267536\n",
      "[Train epoch 15/50] loss=0.056120, train_rmse=0.251611\n",
      "[Train epoch 20/50] loss=0.049411, train_rmse=0.240710\n",
      "[Train epoch 25/50] loss=0.041751, train_rmse=0.234066\n",
      "[Train epoch 30/50] loss=0.036288, train_rmse=0.227551\n",
      "[Train epoch 35/50] loss=0.032340, train_rmse=0.227406\n",
      "[Train epoch 40/50] loss=0.029573, train_rmse=0.226515\n",
      "[Train epoch 45/50] loss=0.027299, train_rmse=0.222380\n",
      "[Train epoch 50/50] loss=0.024554, train_rmse=0.221957\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19761775528659753\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 30 | labelled size = 320 | pool size = 59680 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.317952, train_rmse=0.313046\n",
      "[Train epoch 5/50] loss=0.079779, train_rmse=0.285882\n",
      "[Train epoch 10/50] loss=0.065922, train_rmse=0.266028\n",
      "[Train epoch 15/50] loss=0.054156, train_rmse=0.246903\n",
      "[Train epoch 20/50] loss=0.043475, train_rmse=0.236468\n",
      "[Train epoch 25/50] loss=0.037639, train_rmse=0.228221\n",
      "[Train epoch 30/50] loss=0.033979, train_rmse=0.226603\n",
      "[Train epoch 35/50] loss=0.028413, train_rmse=0.219910\n",
      "[Train epoch 40/50] loss=0.025829, train_rmse=0.221217\n",
      "[Train epoch 45/50] loss=0.021569, train_rmse=0.218958\n",
      "[Train epoch 50/50] loss=0.022527, train_rmse=0.215961\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1931427157402831\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 31 | labelled size = 330 | pool size = 59670 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.415646, train_rmse=0.319369\n",
      "[Train epoch 5/50] loss=0.082159, train_rmse=0.288652\n",
      "[Train epoch 10/50] loss=0.063196, train_rmse=0.259783\n",
      "[Train epoch 15/50] loss=0.055547, train_rmse=0.247386\n",
      "[Train epoch 20/50] loss=0.046493, train_rmse=0.237109\n",
      "[Train epoch 25/50] loss=0.038977, train_rmse=0.230180\n",
      "[Train epoch 30/50] loss=0.035961, train_rmse=0.226732\n",
      "[Train epoch 35/50] loss=0.032778, train_rmse=0.225324\n",
      "[Train epoch 40/50] loss=0.032008, train_rmse=0.224801\n",
      "[Train epoch 45/50] loss=0.028063, train_rmse=0.225045\n",
      "[Train epoch 50/50] loss=0.025861, train_rmse=0.219767\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19086565307335174\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 32 | labelled size = 340 | pool size = 59660 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.382868, train_rmse=0.319733\n",
      "[Train epoch 5/50] loss=0.080045, train_rmse=0.281561\n",
      "[Train epoch 10/50] loss=0.064457, train_rmse=0.261717\n",
      "[Train epoch 15/50] loss=0.053380, train_rmse=0.243390\n",
      "[Train epoch 20/50] loss=0.047134, train_rmse=0.237644\n",
      "[Train epoch 25/50] loss=0.041499, train_rmse=0.231601\n",
      "[Train epoch 30/50] loss=0.036494, train_rmse=0.221820\n",
      "[Train epoch 35/50] loss=0.032077, train_rmse=0.219758\n",
      "[Train epoch 40/50] loss=0.029010, train_rmse=0.220733\n",
      "[Train epoch 45/50] loss=0.027311, train_rmse=0.216186\n",
      "[Train epoch 50/50] loss=0.025185, train_rmse=0.213329\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19199097384654235\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 33 | labelled size = 350 | pool size = 59650 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.348082, train_rmse=0.310141\n",
      "[Train epoch 5/50] loss=0.085138, train_rmse=0.288147\n",
      "[Train epoch 10/50] loss=0.066801, train_rmse=0.262193\n",
      "[Train epoch 15/50] loss=0.054152, train_rmse=0.245297\n",
      "[Train epoch 20/50] loss=0.047316, train_rmse=0.236264\n",
      "[Train epoch 25/50] loss=0.039265, train_rmse=0.228403\n",
      "[Train epoch 30/50] loss=0.034664, train_rmse=0.221783\n",
      "[Train epoch 35/50] loss=0.031411, train_rmse=0.221275\n",
      "[Train epoch 40/50] loss=0.028199, train_rmse=0.214994\n",
      "[Train epoch 45/50] loss=0.028914, train_rmse=0.214997\n",
      "[Train epoch 50/50] loss=0.023179, train_rmse=0.213278\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1917243015321849\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 34 | labelled size = 360 | pool size = 59640 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.271099, train_rmse=0.312901\n",
      "[Train epoch 5/50] loss=0.077832, train_rmse=0.282246\n",
      "[Train epoch 10/50] loss=0.063893, train_rmse=0.254669\n",
      "[Train epoch 15/50] loss=0.052956, train_rmse=0.239992\n",
      "[Train epoch 20/50] loss=0.044688, train_rmse=0.227874\n",
      "[Train epoch 25/50] loss=0.035355, train_rmse=0.222213\n",
      "[Train epoch 30/50] loss=0.032256, train_rmse=0.215833\n",
      "[Train epoch 35/50] loss=0.028749, train_rmse=0.211668\n",
      "[Train epoch 40/50] loss=0.027284, train_rmse=0.209621\n",
      "[Train epoch 45/50] loss=0.023730, train_rmse=0.205472\n",
      "[Train epoch 50/50] loss=0.021382, train_rmse=0.203868\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1869146479008515\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 35 | labelled size = 370 | pool size = 59630 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.289865, train_rmse=0.307185\n",
      "[Train epoch 5/50] loss=0.074325, train_rmse=0.270910\n",
      "[Train epoch 10/50] loss=0.057763, train_rmse=0.246781\n",
      "[Train epoch 15/50] loss=0.043053, train_rmse=0.228092\n",
      "[Train epoch 20/50] loss=0.036418, train_rmse=0.220450\n",
      "[Train epoch 25/50] loss=0.032674, train_rmse=0.213328\n",
      "[Train epoch 30/50] loss=0.028841, train_rmse=0.214230\n",
      "[Train epoch 35/50] loss=0.025312, train_rmse=0.205265\n",
      "[Train epoch 40/50] loss=0.023806, train_rmse=0.206072\n",
      "[Train epoch 45/50] loss=0.020426, train_rmse=0.202692\n",
      "[Train epoch 50/50] loss=0.021397, train_rmse=0.202418\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18942373132209095\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 36 | labelled size = 380 | pool size = 59620 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.360345, train_rmse=0.313429\n",
      "[Train epoch 5/50] loss=0.077480, train_rmse=0.284127\n",
      "[Train epoch 10/50] loss=0.062480, train_rmse=0.257074\n",
      "[Train epoch 15/50] loss=0.051402, train_rmse=0.236758\n",
      "[Train epoch 20/50] loss=0.043798, train_rmse=0.226090\n",
      "[Train epoch 25/50] loss=0.036183, train_rmse=0.219095\n",
      "[Train epoch 30/50] loss=0.033504, train_rmse=0.214389\n",
      "[Train epoch 35/50] loss=0.029035, train_rmse=0.207862\n",
      "[Train epoch 40/50] loss=0.024902, train_rmse=0.204334\n",
      "[Train epoch 45/50] loss=0.024174, train_rmse=0.202653\n",
      "[Train epoch 50/50] loss=0.022315, train_rmse=0.200122\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18452236519144263\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 37 | labelled size = 390 | pool size = 59610 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.463508, train_rmse=0.313772\n",
      "[Train epoch 5/50] loss=0.088114, train_rmse=0.291857\n",
      "[Train epoch 10/50] loss=0.073150, train_rmse=0.271238\n",
      "[Train epoch 15/50] loss=0.064295, train_rmse=0.259909\n",
      "[Train epoch 20/50] loss=0.057197, train_rmse=0.244942\n",
      "[Train epoch 25/50] loss=0.049476, train_rmse=0.236404\n",
      "[Train epoch 30/50] loss=0.046975, train_rmse=0.225215\n",
      "[Train epoch 35/50] loss=0.038031, train_rmse=0.220365\n",
      "[Train epoch 40/50] loss=0.037813, train_rmse=0.221528\n",
      "[Train epoch 45/50] loss=0.032137, train_rmse=0.216838\n",
      "[Train epoch 50/50] loss=0.031270, train_rmse=0.209459\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18631205637359782\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 38 | labelled size = 400 | pool size = 59600 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.349452, train_rmse=0.312103\n",
      "[Train epoch 5/50] loss=0.081325, train_rmse=0.284089\n",
      "[Train epoch 10/50] loss=0.065274, train_rmse=0.255080\n",
      "[Train epoch 15/50] loss=0.052971, train_rmse=0.240968\n",
      "[Train epoch 20/50] loss=0.046038, train_rmse=0.229108\n",
      "[Train epoch 25/50] loss=0.040417, train_rmse=0.219439\n",
      "[Train epoch 30/50] loss=0.037707, train_rmse=0.217642\n",
      "[Train epoch 35/50] loss=0.032583, train_rmse=0.211143\n",
      "[Train epoch 40/50] loss=0.029151, train_rmse=0.208356\n",
      "[Train epoch 45/50] loss=0.026134, train_rmse=0.203167\n",
      "[Train epoch 50/50] loss=0.023486, train_rmse=0.201714\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18435071712868628\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 39 | labelled size = 410 | pool size = 59590 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.395492, train_rmse=0.309209\n",
      "[Train epoch 5/50] loss=0.083606, train_rmse=0.286933\n",
      "[Train epoch 10/50] loss=0.067722, train_rmse=0.261585\n",
      "[Train epoch 15/50] loss=0.054490, train_rmse=0.241552\n",
      "[Train epoch 20/50] loss=0.045233, train_rmse=0.229378\n",
      "[Train epoch 25/50] loss=0.039714, train_rmse=0.220338\n",
      "[Train epoch 30/50] loss=0.034468, train_rmse=0.211887\n",
      "[Train epoch 35/50] loss=0.032820, train_rmse=0.211299\n",
      "[Train epoch 40/50] loss=0.028431, train_rmse=0.211084\n",
      "[Train epoch 45/50] loss=0.027608, train_rmse=0.207663\n",
      "[Train epoch 50/50] loss=0.026269, train_rmse=0.201837\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1821506637970575\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 40 | labelled size = 420 | pool size = 59580 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.318605, train_rmse=0.307642\n",
      "[Train epoch 5/50] loss=0.082808, train_rmse=0.285819\n",
      "[Train epoch 10/50] loss=0.064071, train_rmse=0.247734\n",
      "[Train epoch 15/50] loss=0.052000, train_rmse=0.233790\n",
      "[Train epoch 20/50] loss=0.044535, train_rmse=0.226920\n",
      "[Train epoch 25/50] loss=0.037003, train_rmse=0.214889\n",
      "[Train epoch 30/50] loss=0.032058, train_rmse=0.209769\n",
      "[Train epoch 35/50] loss=0.028259, train_rmse=0.205490\n",
      "[Train epoch 40/50] loss=0.025030, train_rmse=0.201923\n",
      "[Train epoch 45/50] loss=0.023353, train_rmse=0.198962\n",
      "[Train epoch 50/50] loss=0.022361, train_rmse=0.196594\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1795463330977162\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 41 | labelled size = 430 | pool size = 59570 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.374319, train_rmse=0.311354\n",
      "[Train epoch 5/50] loss=0.081172, train_rmse=0.283849\n",
      "[Train epoch 10/50] loss=0.065725, train_rmse=0.254698\n",
      "[Train epoch 15/50] loss=0.053787, train_rmse=0.235977\n",
      "[Train epoch 20/50] loss=0.046960, train_rmse=0.226119\n",
      "[Train epoch 25/50] loss=0.038104, train_rmse=0.217914\n",
      "[Train epoch 30/50] loss=0.032491, train_rmse=0.208107\n",
      "[Train epoch 35/50] loss=0.028606, train_rmse=0.205202\n",
      "[Train epoch 40/50] loss=0.024668, train_rmse=0.202571\n",
      "[Train epoch 45/50] loss=0.024217, train_rmse=0.199050\n",
      "[Train epoch 50/50] loss=0.021286, train_rmse=0.194358\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17779891997707678\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 42 | labelled size = 440 | pool size = 59560 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.404667, train_rmse=0.310691\n",
      "[Train epoch 5/50] loss=0.082281, train_rmse=0.282832\n",
      "[Train epoch 10/50] loss=0.066458, train_rmse=0.252599\n",
      "[Train epoch 15/50] loss=0.056870, train_rmse=0.240398\n",
      "[Train epoch 20/50] loss=0.047779, train_rmse=0.227346\n",
      "[Train epoch 25/50] loss=0.042237, train_rmse=0.220301\n",
      "[Train epoch 30/50] loss=0.035141, train_rmse=0.210012\n",
      "[Train epoch 35/50] loss=0.032462, train_rmse=0.207252\n",
      "[Train epoch 40/50] loss=0.027722, train_rmse=0.204625\n",
      "[Train epoch 45/50] loss=0.024346, train_rmse=0.194785\n",
      "[Train epoch 50/50] loss=0.022403, train_rmse=0.198660\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.181107006229631\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 43 | labelled size = 450 | pool size = 59550 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.311521, train_rmse=0.311422\n",
      "[Train epoch 5/50] loss=0.081014, train_rmse=0.281292\n",
      "[Train epoch 10/50] loss=0.065656, train_rmse=0.259822\n",
      "[Train epoch 15/50] loss=0.059297, train_rmse=0.236498\n",
      "[Train epoch 20/50] loss=0.049957, train_rmse=0.231565\n",
      "[Train epoch 25/50] loss=0.046612, train_rmse=0.224781\n",
      "[Train epoch 30/50] loss=0.041668, train_rmse=0.217534\n",
      "[Train epoch 35/50] loss=0.036802, train_rmse=0.207769\n",
      "[Train epoch 40/50] loss=0.033011, train_rmse=0.204192\n",
      "[Train epoch 45/50] loss=0.030039, train_rmse=0.204298\n",
      "[Train epoch 50/50] loss=0.029543, train_rmse=0.200085\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17943295841721174\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 44 | labelled size = 460 | pool size = 59540 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.293824, train_rmse=0.311528\n",
      "[Train epoch 5/50] loss=0.081248, train_rmse=0.280310\n",
      "[Train epoch 10/50] loss=0.066285, train_rmse=0.250553\n",
      "[Train epoch 15/50] loss=0.055066, train_rmse=0.232481\n",
      "[Train epoch 20/50] loss=0.045240, train_rmse=0.219895\n",
      "[Train epoch 25/50] loss=0.039360, train_rmse=0.213954\n",
      "[Train epoch 30/50] loss=0.034895, train_rmse=0.205554\n",
      "[Train epoch 35/50] loss=0.029511, train_rmse=0.201577\n",
      "[Train epoch 40/50] loss=0.027354, train_rmse=0.195305\n",
      "[Train epoch 45/50] loss=0.026569, train_rmse=0.197299\n",
      "[Train epoch 50/50] loss=0.024340, train_rmse=0.198368\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17740459752753723\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 45 | labelled size = 470 | pool size = 59530 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.535616, train_rmse=0.319319\n",
      "[Train epoch 5/50] loss=0.086238, train_rmse=0.288579\n",
      "[Train epoch 10/50] loss=0.072352, train_rmse=0.264567\n",
      "[Train epoch 15/50] loss=0.060969, train_rmse=0.243198\n",
      "[Train epoch 20/50] loss=0.049716, train_rmse=0.229130\n",
      "[Train epoch 25/50] loss=0.045758, train_rmse=0.219361\n",
      "[Train epoch 30/50] loss=0.039220, train_rmse=0.216193\n",
      "[Train epoch 35/50] loss=0.034108, train_rmse=0.200904\n",
      "[Train epoch 40/50] loss=0.030583, train_rmse=0.201768\n",
      "[Train epoch 45/50] loss=0.024906, train_rmse=0.191636\n",
      "[Train epoch 50/50] loss=0.027524, train_rmse=0.197040\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17428215989286935\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 46 | labelled size = 480 | pool size = 59520 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.499337, train_rmse=0.309929\n",
      "[Train epoch 5/50] loss=0.081779, train_rmse=0.281870\n",
      "[Train epoch 10/50] loss=0.069146, train_rmse=0.257767\n",
      "[Train epoch 15/50] loss=0.058300, train_rmse=0.237966\n",
      "[Train epoch 20/50] loss=0.048982, train_rmse=0.229397\n",
      "[Train epoch 25/50] loss=0.040417, train_rmse=0.213813\n",
      "[Train epoch 30/50] loss=0.036902, train_rmse=0.205296\n",
      "[Train epoch 35/50] loss=0.031572, train_rmse=0.202679\n",
      "[Train epoch 40/50] loss=0.027738, train_rmse=0.197455\n",
      "[Train epoch 45/50] loss=0.026788, train_rmse=0.189083\n",
      "[Train epoch 50/50] loss=0.023429, train_rmse=0.192963\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17146562988434752\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 47 | labelled size = 490 | pool size = 59510 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.485254, train_rmse=0.312601\n",
      "[Train epoch 5/50] loss=0.085065, train_rmse=0.286468\n",
      "[Train epoch 10/50] loss=0.070659, train_rmse=0.262447\n",
      "[Train epoch 15/50] loss=0.057297, train_rmse=0.238106\n",
      "[Train epoch 20/50] loss=0.050046, train_rmse=0.228320\n",
      "[Train epoch 25/50] loss=0.045498, train_rmse=0.219261\n",
      "[Train epoch 30/50] loss=0.037240, train_rmse=0.210992\n",
      "[Train epoch 35/50] loss=0.036945, train_rmse=0.212148\n",
      "[Train epoch 40/50] loss=0.030218, train_rmse=0.203852\n",
      "[Train epoch 45/50] loss=0.028187, train_rmse=0.196110\n",
      "[Train epoch 50/50] loss=0.024574, train_rmse=0.190578\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17484506225093496\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 48 | labelled size = 500 | pool size = 59500 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.440596, train_rmse=0.312436\n",
      "[Train epoch 5/50] loss=0.082084, train_rmse=0.283580\n",
      "[Train epoch 10/50] loss=0.069575, train_rmse=0.258116\n",
      "[Train epoch 15/50] loss=0.058331, train_rmse=0.238763\n",
      "[Train epoch 20/50] loss=0.049579, train_rmse=0.227394\n",
      "[Train epoch 25/50] loss=0.043708, train_rmse=0.216484\n",
      "[Train epoch 30/50] loss=0.039768, train_rmse=0.212192\n",
      "[Train epoch 35/50] loss=0.031978, train_rmse=0.203574\n",
      "[Train epoch 40/50] loss=0.029937, train_rmse=0.200208\n",
      "[Train epoch 45/50] loss=0.027335, train_rmse=0.198021\n",
      "[Train epoch 50/50] loss=0.024399, train_rmse=0.195280\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17801094078209884\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 49 | labelled size = 510 | pool size = 59490 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.329514, train_rmse=0.310737\n",
      "[Train epoch 5/50] loss=0.080493, train_rmse=0.278263\n",
      "[Train epoch 10/50] loss=0.066176, train_rmse=0.255922\n",
      "[Train epoch 15/50] loss=0.055497, train_rmse=0.236428\n",
      "[Train epoch 20/50] loss=0.046233, train_rmse=0.219002\n",
      "[Train epoch 25/50] loss=0.039660, train_rmse=0.209114\n",
      "[Train epoch 30/50] loss=0.032729, train_rmse=0.201681\n",
      "[Train epoch 35/50] loss=0.031352, train_rmse=0.199330\n",
      "[Train epoch 40/50] loss=0.027790, train_rmse=0.195656\n",
      "[Train epoch 45/50] loss=0.025576, train_rmse=0.191533\n",
      "[Train epoch 50/50] loss=0.024848, train_rmse=0.192138\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17613947633957383\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 50 | labelled size = 520 | pool size = 59480 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.270658, train_rmse=0.307604\n",
      "[Train epoch 5/50] loss=0.080287, train_rmse=0.279878\n",
      "[Train epoch 10/50] loss=0.063874, train_rmse=0.250479\n",
      "[Train epoch 15/50] loss=0.052339, train_rmse=0.230562\n",
      "[Train epoch 20/50] loss=0.044319, train_rmse=0.224542\n",
      "[Train epoch 25/50] loss=0.038606, train_rmse=0.210863\n",
      "[Train epoch 30/50] loss=0.033650, train_rmse=0.206524\n",
      "[Train epoch 35/50] loss=0.030966, train_rmse=0.200340\n",
      "[Train epoch 40/50] loss=0.029846, train_rmse=0.193825\n",
      "[Train epoch 45/50] loss=0.026231, train_rmse=0.192173\n",
      "[Train epoch 50/50] loss=0.024016, train_rmse=0.195421\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17428156881181828\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 51 | labelled size = 530 | pool size = 59470 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.281007, train_rmse=0.309301\n",
      "[Train epoch 5/50] loss=0.081616, train_rmse=0.278696\n",
      "[Train epoch 10/50] loss=0.062740, train_rmse=0.246361\n",
      "[Train epoch 15/50] loss=0.051361, train_rmse=0.226331\n",
      "[Train epoch 20/50] loss=0.045138, train_rmse=0.217628\n",
      "[Train epoch 25/50] loss=0.039198, train_rmse=0.206082\n",
      "[Train epoch 30/50] loss=0.034083, train_rmse=0.207599\n",
      "[Train epoch 35/50] loss=0.030824, train_rmse=0.197464\n",
      "[Train epoch 40/50] loss=0.028449, train_rmse=0.191271\n",
      "[Train epoch 45/50] loss=0.024551, train_rmse=0.193840\n",
      "[Train epoch 50/50] loss=0.024052, train_rmse=0.190546\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.16857011775426173\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 52 | labelled size = 540 | pool size = 59460 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.228031, train_rmse=0.302922\n",
      "[Train epoch 5/50] loss=0.076292, train_rmse=0.267284\n",
      "[Train epoch 10/50] loss=0.058120, train_rmse=0.232646\n",
      "[Train epoch 15/50] loss=0.044791, train_rmse=0.217868\n",
      "[Train epoch 20/50] loss=0.036438, train_rmse=0.202069\n",
      "[Train epoch 25/50] loss=0.031884, train_rmse=0.193003\n",
      "[Train epoch 30/50] loss=0.027193, train_rmse=0.185666\n",
      "[Train epoch 35/50] loss=0.023369, train_rmse=0.180661\n",
      "[Train epoch 40/50] loss=0.022494, train_rmse=0.181358\n",
      "[Train epoch 45/50] loss=0.021291, train_rmse=0.179500\n",
      "[Train epoch 50/50] loss=0.021143, train_rmse=0.180318\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.16043563753718085\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 53 | labelled size = 550 | pool size = 59450 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.295645, train_rmse=0.306373\n",
      "[Train epoch 5/50] loss=0.078858, train_rmse=0.273084\n",
      "[Train epoch 10/50] loss=0.061883, train_rmse=0.240893\n",
      "[Train epoch 15/50] loss=0.048937, train_rmse=0.220774\n",
      "[Train epoch 20/50] loss=0.040295, train_rmse=0.206753\n",
      "[Train epoch 25/50] loss=0.036644, train_rmse=0.194226\n",
      "[Train epoch 30/50] loss=0.029785, train_rmse=0.189405\n",
      "[Train epoch 35/50] loss=0.026276, train_rmse=0.180352\n",
      "[Train epoch 40/50] loss=0.024740, train_rmse=0.180870\n",
      "[Train epoch 45/50] loss=0.020798, train_rmse=0.177647\n",
      "[Train epoch 50/50] loss=0.020688, train_rmse=0.175329\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1584573242455624\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 54 | labelled size = 560 | pool size = 59440 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.310120, train_rmse=0.305026\n",
      "[Train epoch 5/50] loss=0.080601, train_rmse=0.276345\n",
      "[Train epoch 10/50] loss=0.066154, train_rmse=0.249038\n",
      "[Train epoch 15/50] loss=0.056001, train_rmse=0.228282\n",
      "[Train epoch 20/50] loss=0.047787, train_rmse=0.221521\n",
      "[Train epoch 25/50] loss=0.041267, train_rmse=0.208535\n",
      "[Train epoch 30/50] loss=0.035583, train_rmse=0.200915\n",
      "[Train epoch 35/50] loss=0.032754, train_rmse=0.191530\n",
      "[Train epoch 40/50] loss=0.028666, train_rmse=0.196641\n",
      "[Train epoch 45/50] loss=0.026477, train_rmse=0.190869\n",
      "[Train epoch 50/50] loss=0.024865, train_rmse=0.186793\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1662803722402156\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 55 | labelled size = 570 | pool size = 59430 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.334258, train_rmse=0.309687\n",
      "[Train epoch 5/50] loss=0.082569, train_rmse=0.281647\n",
      "[Train epoch 10/50] loss=0.068976, train_rmse=0.255662\n",
      "[Train epoch 15/50] loss=0.058042, train_rmse=0.234749\n",
      "[Train epoch 20/50] loss=0.048780, train_rmse=0.222254\n",
      "[Train epoch 25/50] loss=0.040784, train_rmse=0.209453\n",
      "[Train epoch 30/50] loss=0.035726, train_rmse=0.200398\n",
      "[Train epoch 35/50] loss=0.030059, train_rmse=0.190140\n",
      "[Train epoch 40/50] loss=0.027474, train_rmse=0.181629\n",
      "[Train epoch 45/50] loss=0.025445, train_rmse=0.180217\n",
      "[Train epoch 50/50] loss=0.024381, train_rmse=0.183572\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1617137697641638\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 56 | labelled size = 580 | pool size = 59420 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.270087, train_rmse=0.304863\n",
      "[Train epoch 5/50] loss=0.082009, train_rmse=0.281106\n",
      "[Train epoch 10/50] loss=0.067486, train_rmse=0.256705\n",
      "[Train epoch 15/50] loss=0.058394, train_rmse=0.235633\n",
      "[Train epoch 20/50] loss=0.050129, train_rmse=0.222438\n",
      "[Train epoch 25/50] loss=0.044012, train_rmse=0.213841\n",
      "[Train epoch 30/50] loss=0.038394, train_rmse=0.203514\n",
      "[Train epoch 35/50] loss=0.034156, train_rmse=0.193158\n",
      "[Train epoch 40/50] loss=0.032917, train_rmse=0.191580\n",
      "[Train epoch 45/50] loss=0.030994, train_rmse=0.184382\n",
      "[Train epoch 50/50] loss=0.028865, train_rmse=0.186374\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.16456370860408262\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 57 | labelled size = 590 | pool size = 59410 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.286340, train_rmse=0.304614\n",
      "[Train epoch 5/50] loss=0.078879, train_rmse=0.277834\n",
      "[Train epoch 10/50] loss=0.064359, train_rmse=0.246457\n",
      "[Train epoch 15/50] loss=0.053686, train_rmse=0.226845\n",
      "[Train epoch 20/50] loss=0.044219, train_rmse=0.213312\n",
      "[Train epoch 25/50] loss=0.036289, train_rmse=0.198879\n",
      "[Train epoch 30/50] loss=0.030835, train_rmse=0.189678\n",
      "[Train epoch 35/50] loss=0.027578, train_rmse=0.185454\n",
      "[Train epoch 40/50] loss=0.025767, train_rmse=0.186054\n",
      "[Train epoch 45/50] loss=0.023297, train_rmse=0.178516\n",
      "[Train epoch 50/50] loss=0.024040, train_rmse=0.182244\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.16383281560976426\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 58 | labelled size = 600 | pool size = 59400 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.224420, train_rmse=0.299311\n",
      "[Train epoch 5/50] loss=0.076024, train_rmse=0.266665\n",
      "[Train epoch 10/50] loss=0.060640, train_rmse=0.237900\n",
      "[Train epoch 15/50] loss=0.048402, train_rmse=0.215946\n",
      "[Train epoch 20/50] loss=0.037800, train_rmse=0.199839\n",
      "[Train epoch 25/50] loss=0.032049, train_rmse=0.188154\n",
      "[Train epoch 30/50] loss=0.028261, train_rmse=0.187572\n",
      "[Train epoch 35/50] loss=0.025835, train_rmse=0.185545\n",
      "[Train epoch 40/50] loss=0.024272, train_rmse=0.181192\n",
      "[Train epoch 45/50] loss=0.021780, train_rmse=0.179976\n",
      "[Train epoch 50/50] loss=0.020169, train_rmse=0.167186\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15682743479861963\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 59 | labelled size = 610 | pool size = 59390 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.193088, train_rmse=0.302787\n",
      "[Train epoch 5/50] loss=0.072918, train_rmse=0.260624\n",
      "[Train epoch 10/50] loss=0.055497, train_rmse=0.226730\n",
      "[Train epoch 15/50] loss=0.045112, train_rmse=0.205414\n",
      "[Train epoch 20/50] loss=0.034826, train_rmse=0.193690\n",
      "[Train epoch 25/50] loss=0.031079, train_rmse=0.184330\n",
      "[Train epoch 30/50] loss=0.027424, train_rmse=0.179588\n",
      "[Train epoch 35/50] loss=0.025337, train_rmse=0.179837\n",
      "[Train epoch 40/50] loss=0.021687, train_rmse=0.171896\n",
      "[Train epoch 45/50] loss=0.019522, train_rmse=0.167989\n",
      "[Train epoch 50/50] loss=0.019919, train_rmse=0.167998\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1536254320580884\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 60 | labelled size = 620 | pool size = 59380 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.229964, train_rmse=0.308811\n",
      "[Train epoch 5/50] loss=0.076489, train_rmse=0.269272\n",
      "[Train epoch 10/50] loss=0.059782, train_rmse=0.237188\n",
      "[Train epoch 15/50] loss=0.046155, train_rmse=0.209427\n",
      "[Train epoch 20/50] loss=0.037972, train_rmse=0.195332\n",
      "[Train epoch 25/50] loss=0.032645, train_rmse=0.189156\n",
      "[Train epoch 30/50] loss=0.027459, train_rmse=0.180356\n",
      "[Train epoch 35/50] loss=0.025243, train_rmse=0.178778\n",
      "[Train epoch 40/50] loss=0.023550, train_rmse=0.175373\n",
      "[Train epoch 45/50] loss=0.020100, train_rmse=0.163070\n",
      "[Train epoch 50/50] loss=0.019393, train_rmse=0.166397\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15186576295556703\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 61 | labelled size = 630 | pool size = 59370 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.197669, train_rmse=0.302608\n",
      "[Train epoch 5/50] loss=0.076888, train_rmse=0.268679\n",
      "[Train epoch 10/50] loss=0.059668, train_rmse=0.234715\n",
      "[Train epoch 15/50] loss=0.048023, train_rmse=0.216135\n",
      "[Train epoch 20/50] loss=0.040055, train_rmse=0.200689\n",
      "[Train epoch 25/50] loss=0.033409, train_rmse=0.189762\n",
      "[Train epoch 30/50] loss=0.029995, train_rmse=0.182461\n",
      "[Train epoch 35/50] loss=0.026956, train_rmse=0.181792\n",
      "[Train epoch 40/50] loss=0.024688, train_rmse=0.181051\n",
      "[Train epoch 45/50] loss=0.022991, train_rmse=0.173991\n",
      "[Train epoch 50/50] loss=0.021679, train_rmse=0.184047\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15792134173710748\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 62 | labelled size = 640 | pool size = 59360 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.231602, train_rmse=0.305561\n",
      "[Train epoch 5/50] loss=0.077716, train_rmse=0.268415\n",
      "[Train epoch 10/50] loss=0.060599, train_rmse=0.238378\n",
      "[Train epoch 15/50] loss=0.050798, train_rmse=0.219661\n",
      "[Train epoch 20/50] loss=0.041420, train_rmse=0.204370\n",
      "[Train epoch 25/50] loss=0.036987, train_rmse=0.194473\n",
      "[Train epoch 30/50] loss=0.032075, train_rmse=0.187778\n",
      "[Train epoch 35/50] loss=0.028800, train_rmse=0.176591\n",
      "[Train epoch 40/50] loss=0.024590, train_rmse=0.170533\n",
      "[Train epoch 45/50] loss=0.022325, train_rmse=0.171528\n",
      "[Train epoch 50/50] loss=0.020153, train_rmse=0.166045\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14972021273457983\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 63 | labelled size = 650 | pool size = 59350 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.208133, train_rmse=0.303078\n",
      "[Train epoch 5/50] loss=0.074124, train_rmse=0.260026\n",
      "[Train epoch 10/50] loss=0.056426, train_rmse=0.223774\n",
      "[Train epoch 15/50] loss=0.044680, train_rmse=0.206343\n",
      "[Train epoch 20/50] loss=0.037409, train_rmse=0.194165\n",
      "[Train epoch 25/50] loss=0.032624, train_rmse=0.190527\n",
      "[Train epoch 30/50] loss=0.030968, train_rmse=0.183577\n",
      "[Train epoch 35/50] loss=0.028610, train_rmse=0.178501\n",
      "[Train epoch 40/50] loss=0.025158, train_rmse=0.175273\n",
      "[Train epoch 45/50] loss=0.023538, train_rmse=0.177405\n",
      "[Train epoch 50/50] loss=0.021716, train_rmse=0.169798\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1510895619329729\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 64 | labelled size = 660 | pool size = 59340 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.186264, train_rmse=0.299936\n",
      "[Train epoch 5/50] loss=0.067677, train_rmse=0.251997\n",
      "[Train epoch 10/50] loss=0.052294, train_rmse=0.217286\n",
      "[Train epoch 15/50] loss=0.040996, train_rmse=0.202495\n",
      "[Train epoch 20/50] loss=0.031783, train_rmse=0.187699\n",
      "[Train epoch 25/50] loss=0.028843, train_rmse=0.181564\n",
      "[Train epoch 30/50] loss=0.024684, train_rmse=0.174891\n",
      "[Train epoch 35/50] loss=0.021341, train_rmse=0.167565\n",
      "[Train epoch 40/50] loss=0.021207, train_rmse=0.161841\n",
      "[Train epoch 45/50] loss=0.020363, train_rmse=0.165785\n",
      "[Train epoch 50/50] loss=0.019951, train_rmse=0.161224\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1491525200505912\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 65 | labelled size = 670 | pool size = 59330 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.205600, train_rmse=0.303558\n",
      "[Train epoch 5/50] loss=0.074543, train_rmse=0.260000\n",
      "[Train epoch 10/50] loss=0.055866, train_rmse=0.225922\n",
      "[Train epoch 15/50] loss=0.044260, train_rmse=0.201015\n",
      "[Train epoch 20/50] loss=0.033962, train_rmse=0.187414\n",
      "[Train epoch 25/50] loss=0.029670, train_rmse=0.177054\n",
      "[Train epoch 30/50] loss=0.025875, train_rmse=0.172964\n",
      "[Train epoch 35/50] loss=0.021011, train_rmse=0.163773\n",
      "[Train epoch 40/50] loss=0.021800, train_rmse=0.165649\n",
      "[Train epoch 45/50] loss=0.018756, train_rmse=0.167770\n",
      "[Train epoch 50/50] loss=0.018166, train_rmse=0.170171\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1514672436286091\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 66 | labelled size = 680 | pool size = 59320 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.156231, train_rmse=0.291342\n",
      "[Train epoch 5/50] loss=0.068235, train_rmse=0.246961\n",
      "[Train epoch 10/50] loss=0.050813, train_rmse=0.217677\n",
      "[Train epoch 15/50] loss=0.039609, train_rmse=0.195952\n",
      "[Train epoch 20/50] loss=0.032198, train_rmse=0.182092\n",
      "[Train epoch 25/50] loss=0.027476, train_rmse=0.169061\n",
      "[Train epoch 30/50] loss=0.023335, train_rmse=0.172077\n",
      "[Train epoch 35/50] loss=0.021905, train_rmse=0.164640\n",
      "[Train epoch 40/50] loss=0.018290, train_rmse=0.165348\n",
      "[Train epoch 45/50] loss=0.017136, train_rmse=0.164757\n",
      "[Train epoch 50/50] loss=0.018353, train_rmse=0.168468\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15251022748577373\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 67 | labelled size = 690 | pool size = 59310 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.151775, train_rmse=0.294167\n",
      "[Train epoch 5/50] loss=0.068091, train_rmse=0.248229\n",
      "[Train epoch 10/50] loss=0.049917, train_rmse=0.211723\n",
      "[Train epoch 15/50] loss=0.038344, train_rmse=0.190548\n",
      "[Train epoch 20/50] loss=0.030672, train_rmse=0.176407\n",
      "[Train epoch 25/50] loss=0.027379, train_rmse=0.175952\n",
      "[Train epoch 30/50] loss=0.023319, train_rmse=0.167278\n",
      "[Train epoch 35/50] loss=0.019630, train_rmse=0.167388\n",
      "[Train epoch 40/50] loss=0.021560, train_rmse=0.173761\n",
      "[Train epoch 45/50] loss=0.018254, train_rmse=0.165025\n",
      "[Train epoch 50/50] loss=0.018046, train_rmse=0.157437\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14658510854440224\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 68 | labelled size = 700 | pool size = 59300 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.193478, train_rmse=0.299368\n",
      "[Train epoch 5/50] loss=0.073905, train_rmse=0.261546\n",
      "[Train epoch 10/50] loss=0.055373, train_rmse=0.222821\n",
      "[Train epoch 15/50] loss=0.044062, train_rmse=0.195553\n",
      "[Train epoch 20/50] loss=0.035062, train_rmse=0.182717\n",
      "[Train epoch 25/50] loss=0.029233, train_rmse=0.173809\n",
      "[Train epoch 30/50] loss=0.024907, train_rmse=0.174427\n",
      "[Train epoch 35/50] loss=0.022289, train_rmse=0.165653\n",
      "[Train epoch 40/50] loss=0.020137, train_rmse=0.166510\n",
      "[Train epoch 45/50] loss=0.019760, train_rmse=0.162610\n",
      "[Train epoch 50/50] loss=0.020789, train_rmse=0.166045\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14881527094562275\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 69 | labelled size = 710 | pool size = 59290 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.148162, train_rmse=0.291501\n",
      "[Train epoch 5/50] loss=0.066013, train_rmse=0.241256\n",
      "[Train epoch 10/50] loss=0.049841, train_rmse=0.207011\n",
      "[Train epoch 15/50] loss=0.039466, train_rmse=0.193941\n",
      "[Train epoch 20/50] loss=0.032851, train_rmse=0.176732\n",
      "[Train epoch 25/50] loss=0.029442, train_rmse=0.178995\n",
      "[Train epoch 30/50] loss=0.025612, train_rmse=0.166955\n",
      "[Train epoch 35/50] loss=0.023318, train_rmse=0.167598\n",
      "[Train epoch 40/50] loss=0.023573, train_rmse=0.169295\n",
      "[Train epoch 45/50] loss=0.026291, train_rmse=0.160154\n",
      "[Train epoch 50/50] loss=0.026056, train_rmse=0.169666\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1496982126802634\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 70 | labelled size = 720 | pool size = 59280 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.154351, train_rmse=0.297042\n",
      "[Train epoch 5/50] loss=0.069239, train_rmse=0.247783\n",
      "[Train epoch 10/50] loss=0.049036, train_rmse=0.208351\n",
      "[Train epoch 15/50] loss=0.039405, train_rmse=0.188231\n",
      "[Train epoch 20/50] loss=0.032800, train_rmse=0.172855\n",
      "[Train epoch 25/50] loss=0.026822, train_rmse=0.174234\n",
      "[Train epoch 30/50] loss=0.024364, train_rmse=0.166700\n",
      "[Train epoch 35/50] loss=0.021762, train_rmse=0.165678\n",
      "[Train epoch 40/50] loss=0.021894, train_rmse=0.170203\n",
      "[Train epoch 45/50] loss=0.020237, train_rmse=0.156365\n",
      "[Train epoch 50/50] loss=0.018367, train_rmse=0.157732\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14424735153285806\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 71 | labelled size = 730 | pool size = 59270 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.147229, train_rmse=0.292645\n",
      "[Train epoch 5/50] loss=0.067192, train_rmse=0.244923\n",
      "[Train epoch 10/50] loss=0.049181, train_rmse=0.209626\n",
      "[Train epoch 15/50] loss=0.037291, train_rmse=0.190029\n",
      "[Train epoch 20/50] loss=0.030286, train_rmse=0.175776\n",
      "[Train epoch 25/50] loss=0.027510, train_rmse=0.171596\n",
      "[Train epoch 30/50] loss=0.023451, train_rmse=0.164493\n",
      "[Train epoch 35/50] loss=0.020756, train_rmse=0.158648\n",
      "[Train epoch 40/50] loss=0.021455, train_rmse=0.158066\n",
      "[Train epoch 45/50] loss=0.019488, train_rmse=0.161291\n",
      "[Train epoch 50/50] loss=0.019317, train_rmse=0.168830\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14716697295420922\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 72 | labelled size = 740 | pool size = 59260 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.139003, train_rmse=0.290268\n",
      "[Train epoch 5/50] loss=0.068076, train_rmse=0.243904\n",
      "[Train epoch 10/50] loss=0.049282, train_rmse=0.206684\n",
      "[Train epoch 15/50] loss=0.036927, train_rmse=0.179424\n",
      "[Train epoch 20/50] loss=0.028715, train_rmse=0.172729\n",
      "[Train epoch 25/50] loss=0.026037, train_rmse=0.165761\n",
      "[Train epoch 30/50] loss=0.022559, train_rmse=0.166834\n",
      "[Train epoch 35/50] loss=0.020565, train_rmse=0.155759\n",
      "[Train epoch 40/50] loss=0.019228, train_rmse=0.160053\n",
      "[Train epoch 45/50] loss=0.018715, train_rmse=0.158878\n",
      "[Train epoch 50/50] loss=0.017587, train_rmse=0.162083\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14841073132526708\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 73 | labelled size = 750 | pool size = 59250 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.144046, train_rmse=0.295427\n",
      "[Train epoch 5/50] loss=0.064934, train_rmse=0.240147\n",
      "[Train epoch 10/50] loss=0.045500, train_rmse=0.201053\n",
      "[Train epoch 15/50] loss=0.035959, train_rmse=0.179920\n",
      "[Train epoch 20/50] loss=0.028563, train_rmse=0.168404\n",
      "[Train epoch 25/50] loss=0.024220, train_rmse=0.160768\n",
      "[Train epoch 30/50] loss=0.022444, train_rmse=0.160576\n",
      "[Train epoch 35/50] loss=0.022212, train_rmse=0.163044\n",
      "[Train epoch 40/50] loss=0.018810, train_rmse=0.163819\n",
      "[Train epoch 45/50] loss=0.018888, train_rmse=0.161422\n",
      "[Train epoch 50/50] loss=0.016514, train_rmse=0.156353\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14156786496267768\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 74 | labelled size = 760 | pool size = 59240 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.128574, train_rmse=0.291039\n",
      "[Train epoch 5/50] loss=0.065106, train_rmse=0.234030\n",
      "[Train epoch 10/50] loss=0.047506, train_rmse=0.203094\n",
      "[Train epoch 15/50] loss=0.035510, train_rmse=0.178231\n",
      "[Train epoch 20/50] loss=0.030591, train_rmse=0.173669\n",
      "[Train epoch 25/50] loss=0.025353, train_rmse=0.167774\n",
      "[Train epoch 30/50] loss=0.021553, train_rmse=0.158167\n",
      "[Train epoch 35/50] loss=0.021435, train_rmse=0.151214\n",
      "[Train epoch 40/50] loss=0.018615, train_rmse=0.155598\n",
      "[Train epoch 45/50] loss=0.016742, train_rmse=0.155517\n",
      "[Train epoch 50/50] loss=0.017309, train_rmse=0.152885\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1408506206515027\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 75 | labelled size = 770 | pool size = 59230 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.164258, train_rmse=0.295848\n",
      "[Train epoch 5/50] loss=0.077279, train_rmse=0.266207\n",
      "[Train epoch 10/50] loss=0.060639, train_rmse=0.232378\n",
      "[Train epoch 15/50] loss=0.051274, train_rmse=0.216270\n",
      "[Train epoch 20/50] loss=0.044127, train_rmse=0.193052\n",
      "[Train epoch 25/50] loss=0.038123, train_rmse=0.183707\n",
      "[Train epoch 30/50] loss=0.035782, train_rmse=0.177512\n",
      "[Train epoch 35/50] loss=0.032827, train_rmse=0.175180\n",
      "[Train epoch 40/50] loss=0.030657, train_rmse=0.172455\n",
      "[Train epoch 45/50] loss=0.027378, train_rmse=0.161431\n",
      "[Train epoch 50/50] loss=0.025146, train_rmse=0.166543\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14279202896746016\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 76 | labelled size = 780 | pool size = 59220 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.142262, train_rmse=0.294134\n",
      "[Train epoch 5/50] loss=0.075245, train_rmse=0.261207\n",
      "[Train epoch 10/50] loss=0.057980, train_rmse=0.223823\n",
      "[Train epoch 15/50] loss=0.046378, train_rmse=0.193953\n",
      "[Train epoch 20/50] loss=0.038108, train_rmse=0.179802\n",
      "[Train epoch 25/50] loss=0.030058, train_rmse=0.167644\n",
      "[Train epoch 30/50] loss=0.025939, train_rmse=0.159755\n",
      "[Train epoch 35/50] loss=0.025561, train_rmse=0.163192\n",
      "[Train epoch 40/50] loss=0.022190, train_rmse=0.153561\n",
      "[Train epoch 45/50] loss=0.022791, train_rmse=0.158387\n",
      "[Train epoch 50/50] loss=0.019027, train_rmse=0.152726\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14049019346257668\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 77 | labelled size = 790 | pool size = 59210 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.159037, train_rmse=0.295366\n",
      "[Train epoch 5/50] loss=0.072546, train_rmse=0.253606\n",
      "[Train epoch 10/50] loss=0.054379, train_rmse=0.215755\n",
      "[Train epoch 15/50] loss=0.042251, train_rmse=0.195170\n",
      "[Train epoch 20/50] loss=0.035458, train_rmse=0.178095\n",
      "[Train epoch 25/50] loss=0.029948, train_rmse=0.162671\n",
      "[Train epoch 30/50] loss=0.027308, train_rmse=0.160559\n",
      "[Train epoch 35/50] loss=0.024059, train_rmse=0.156901\n",
      "[Train epoch 40/50] loss=0.023353, train_rmse=0.159365\n",
      "[Train epoch 45/50] loss=0.020918, train_rmse=0.152545\n",
      "[Train epoch 50/50] loss=0.019785, train_rmse=0.155872\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13829862594487355\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 78 | labelled size = 800 | pool size = 59200 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.147436, train_rmse=0.295896\n",
      "[Train epoch 5/50] loss=0.071880, train_rmse=0.254514\n",
      "[Train epoch 10/50] loss=0.054446, train_rmse=0.219182\n",
      "[Train epoch 15/50] loss=0.042296, train_rmse=0.191643\n",
      "[Train epoch 20/50] loss=0.034139, train_rmse=0.175645\n",
      "[Train epoch 25/50] loss=0.028853, train_rmse=0.158791\n",
      "[Train epoch 30/50] loss=0.025051, train_rmse=0.160308\n",
      "[Train epoch 35/50] loss=0.022875, train_rmse=0.155480\n",
      "[Train epoch 40/50] loss=0.020010, train_rmse=0.152786\n",
      "[Train epoch 45/50] loss=0.019061, train_rmse=0.155826\n",
      "[Train epoch 50/50] loss=0.018785, train_rmse=0.153388\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13765146160998668\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 79 | labelled size = 810 | pool size = 59190 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.129372, train_rmse=0.291372\n",
      "[Train epoch 5/50] loss=0.062858, train_rmse=0.230752\n",
      "[Train epoch 10/50] loss=0.044506, train_rmse=0.195936\n",
      "[Train epoch 15/50] loss=0.034141, train_rmse=0.175855\n",
      "[Train epoch 20/50] loss=0.027243, train_rmse=0.162088\n",
      "[Train epoch 25/50] loss=0.024692, train_rmse=0.158518\n",
      "[Train epoch 30/50] loss=0.022265, train_rmse=0.156207\n",
      "[Train epoch 35/50] loss=0.019917, train_rmse=0.156638\n",
      "[Train epoch 40/50] loss=0.018514, train_rmse=0.153213\n",
      "[Train epoch 45/50] loss=0.016868, train_rmse=0.153148\n",
      "[Train epoch 50/50] loss=0.016440, train_rmse=0.152884\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1398815400876122\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 80 | labelled size = 820 | pool size = 59180 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.122103, train_rmse=0.287802\n",
      "[Train epoch 5/50] loss=0.060219, train_rmse=0.225898\n",
      "[Train epoch 10/50] loss=0.041527, train_rmse=0.188297\n",
      "[Train epoch 15/50] loss=0.033461, train_rmse=0.180518\n",
      "[Train epoch 20/50] loss=0.026782, train_rmse=0.162002\n",
      "[Train epoch 25/50] loss=0.024730, train_rmse=0.164129\n",
      "[Train epoch 30/50] loss=0.020897, train_rmse=0.156064\n",
      "[Train epoch 35/50] loss=0.020836, train_rmse=0.156905\n",
      "[Train epoch 40/50] loss=0.017390, train_rmse=0.151116\n",
      "[Train epoch 45/50] loss=0.017830, train_rmse=0.153646\n",
      "[Train epoch 50/50] loss=0.016722, train_rmse=0.156361\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13626147721448006\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 81 | labelled size = 830 | pool size = 59170 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.162831, train_rmse=0.301183\n",
      "[Train epoch 5/50] loss=0.072185, train_rmse=0.255588\n",
      "[Train epoch 10/50] loss=0.053515, train_rmse=0.214831\n",
      "[Train epoch 15/50] loss=0.042530, train_rmse=0.185633\n",
      "[Train epoch 20/50] loss=0.034667, train_rmse=0.174789\n",
      "[Train epoch 25/50] loss=0.030109, train_rmse=0.163036\n",
      "[Train epoch 30/50] loss=0.025416, train_rmse=0.156937\n",
      "[Train epoch 35/50] loss=0.022654, train_rmse=0.154991\n",
      "[Train epoch 40/50] loss=0.020699, train_rmse=0.150207\n",
      "[Train epoch 45/50] loss=0.019924, train_rmse=0.149796\n",
      "[Train epoch 50/50] loss=0.017688, train_rmse=0.153247\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13736797811700138\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 82 | labelled size = 840 | pool size = 59160 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.125438, train_rmse=0.289543\n",
      "[Train epoch 5/50] loss=0.063353, train_rmse=0.230333\n",
      "[Train epoch 10/50] loss=0.046377, train_rmse=0.193226\n",
      "[Train epoch 15/50] loss=0.037424, train_rmse=0.178972\n",
      "[Train epoch 20/50] loss=0.033857, train_rmse=0.173608\n",
      "[Train epoch 25/50] loss=0.026731, train_rmse=0.159593\n",
      "[Train epoch 30/50] loss=0.025198, train_rmse=0.158863\n",
      "[Train epoch 35/50] loss=0.022086, train_rmse=0.157421\n",
      "[Train epoch 40/50] loss=0.022364, train_rmse=0.154121\n",
      "[Train epoch 45/50] loss=0.022588, train_rmse=0.149893\n",
      "[Train epoch 50/50] loss=0.020567, train_rmse=0.149207\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1338567508650913\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 83 | labelled size = 850 | pool size = 59150 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.121263, train_rmse=0.288164\n",
      "[Train epoch 5/50] loss=0.062145, train_rmse=0.225916\n",
      "[Train epoch 10/50] loss=0.042765, train_rmse=0.187317\n",
      "[Train epoch 15/50] loss=0.035072, train_rmse=0.169856\n",
      "[Train epoch 20/50] loss=0.027704, train_rmse=0.165230\n",
      "[Train epoch 25/50] loss=0.024985, train_rmse=0.157156\n",
      "[Train epoch 30/50] loss=0.023042, train_rmse=0.162444\n",
      "[Train epoch 35/50] loss=0.021452, train_rmse=0.156637\n",
      "[Train epoch 40/50] loss=0.020499, train_rmse=0.157638\n",
      "[Train epoch 45/50] loss=0.019108, train_rmse=0.157978\n",
      "[Train epoch 50/50] loss=0.017724, train_rmse=0.153315\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1375587384993509\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 84 | labelled size = 860 | pool size = 59140 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.149930, train_rmse=0.295720\n",
      "[Train epoch 5/50] loss=0.073103, train_rmse=0.254579\n",
      "[Train epoch 10/50] loss=0.054237, train_rmse=0.214345\n",
      "[Train epoch 15/50] loss=0.042563, train_rmse=0.188542\n",
      "[Train epoch 20/50] loss=0.035140, train_rmse=0.171937\n",
      "[Train epoch 25/50] loss=0.030127, train_rmse=0.172496\n",
      "[Train epoch 30/50] loss=0.027017, train_rmse=0.157649\n",
      "[Train epoch 35/50] loss=0.023396, train_rmse=0.152333\n",
      "[Train epoch 40/50] loss=0.021423, train_rmse=0.151032\n",
      "[Train epoch 45/50] loss=0.021104, train_rmse=0.153502\n",
      "[Train epoch 50/50] loss=0.018842, train_rmse=0.151991\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13479681129405421\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 85 | labelled size = 870 | pool size = 59130 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.129176, train_rmse=0.289538\n",
      "[Train epoch 5/50] loss=0.063286, train_rmse=0.233254\n",
      "[Train epoch 10/50] loss=0.044090, train_rmse=0.188747\n",
      "[Train epoch 15/50] loss=0.033268, train_rmse=0.166160\n",
      "[Train epoch 20/50] loss=0.027257, train_rmse=0.159696\n",
      "[Train epoch 25/50] loss=0.023870, train_rmse=0.155223\n",
      "[Train epoch 30/50] loss=0.022357, train_rmse=0.154816\n",
      "[Train epoch 35/50] loss=0.020925, train_rmse=0.153048\n",
      "[Train epoch 40/50] loss=0.018693, train_rmse=0.154628\n",
      "[Train epoch 45/50] loss=0.018528, train_rmse=0.146628\n",
      "[Train epoch 50/50] loss=0.016608, train_rmse=0.153802\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13495830713295198\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 86 | labelled size = 880 | pool size = 59120 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.125385, train_rmse=0.290499\n",
      "[Train epoch 5/50] loss=0.062616, train_rmse=0.224508\n",
      "[Train epoch 10/50] loss=0.041739, train_rmse=0.177848\n",
      "[Train epoch 15/50] loss=0.032457, train_rmse=0.168771\n",
      "[Train epoch 20/50] loss=0.027678, train_rmse=0.162802\n",
      "[Train epoch 25/50] loss=0.023728, train_rmse=0.154610\n",
      "[Train epoch 30/50] loss=0.021433, train_rmse=0.146341\n",
      "[Train epoch 35/50] loss=0.020520, train_rmse=0.154950\n",
      "[Train epoch 40/50] loss=0.018161, train_rmse=0.149587\n",
      "[Train epoch 45/50] loss=0.016204, train_rmse=0.149102\n",
      "[Train epoch 50/50] loss=0.018049, train_rmse=0.148198\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13333609385712306\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 87 | labelled size = 890 | pool size = 59110 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.145729, train_rmse=0.291383\n",
      "[Train epoch 5/50] loss=0.069255, train_rmse=0.243687\n",
      "[Train epoch 10/50] loss=0.052687, train_rmse=0.203835\n",
      "[Train epoch 15/50] loss=0.040181, train_rmse=0.177344\n",
      "[Train epoch 20/50] loss=0.031832, train_rmse=0.164260\n",
      "[Train epoch 25/50] loss=0.027205, train_rmse=0.162764\n",
      "[Train epoch 30/50] loss=0.023245, train_rmse=0.158257\n",
      "[Train epoch 35/50] loss=0.022338, train_rmse=0.150132\n",
      "[Train epoch 40/50] loss=0.021029, train_rmse=0.152344\n",
      "[Train epoch 45/50] loss=0.019821, train_rmse=0.145968\n",
      "[Train epoch 50/50] loss=0.017881, train_rmse=0.149684\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13749083429478376\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 88 | labelled size = 900 | pool size = 59100 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.127319, train_rmse=0.291966\n",
      "[Train epoch 5/50] loss=0.069949, train_rmse=0.244883\n",
      "[Train epoch 10/50] loss=0.052382, train_rmse=0.207596\n",
      "[Train epoch 15/50] loss=0.041714, train_rmse=0.185642\n",
      "[Train epoch 20/50] loss=0.036522, train_rmse=0.170484\n",
      "[Train epoch 25/50] loss=0.031102, train_rmse=0.164950\n",
      "[Train epoch 30/50] loss=0.030515, train_rmse=0.162507\n",
      "[Train epoch 35/50] loss=0.025351, train_rmse=0.155376\n",
      "[Train epoch 40/50] loss=0.023549, train_rmse=0.153594\n",
      "[Train epoch 45/50] loss=0.022488, train_rmse=0.147677\n",
      "[Train epoch 50/50] loss=0.022090, train_rmse=0.151516\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13472211162927464\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 89 | labelled size = 910 | pool size = 59090 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.131454, train_rmse=0.292113\n",
      "[Train epoch 5/50] loss=0.065756, train_rmse=0.231681\n",
      "[Train epoch 10/50] loss=0.047386, train_rmse=0.188799\n",
      "[Train epoch 15/50] loss=0.035137, train_rmse=0.174039\n",
      "[Train epoch 20/50] loss=0.029634, train_rmse=0.159947\n",
      "[Train epoch 25/50] loss=0.025075, train_rmse=0.152334\n",
      "[Train epoch 30/50] loss=0.025262, train_rmse=0.162162\n",
      "[Train epoch 35/50] loss=0.020599, train_rmse=0.151183\n",
      "[Train epoch 40/50] loss=0.020644, train_rmse=0.142722\n",
      "[Train epoch 45/50] loss=0.018236, train_rmse=0.146222\n",
      "[Train epoch 50/50] loss=0.018893, train_rmse=0.146576\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13374210781806103\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 90 | labelled size = 920 | pool size = 59080 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.145165, train_rmse=0.294167\n",
      "[Train epoch 5/50] loss=0.070795, train_rmse=0.244813\n",
      "[Train epoch 10/50] loss=0.051589, train_rmse=0.202919\n",
      "[Train epoch 15/50] loss=0.039225, train_rmse=0.178103\n",
      "[Train epoch 20/50] loss=0.033810, train_rmse=0.169714\n",
      "[Train epoch 25/50] loss=0.028227, train_rmse=0.158180\n",
      "[Train epoch 30/50] loss=0.025933, train_rmse=0.155742\n",
      "[Train epoch 35/50] loss=0.022401, train_rmse=0.155661\n",
      "[Train epoch 40/50] loss=0.022722, train_rmse=0.152783\n",
      "[Train epoch 45/50] loss=0.019604, train_rmse=0.152767\n",
      "[Train epoch 50/50] loss=0.019060, train_rmse=0.142522\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13325401124409691\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 91 | labelled size = 930 | pool size = 59070 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.130247, train_rmse=0.288395\n",
      "[Train epoch 5/50] loss=0.065336, train_rmse=0.233990\n",
      "[Train epoch 10/50] loss=0.044442, train_rmse=0.188647\n",
      "[Train epoch 15/50] loss=0.034642, train_rmse=0.175216\n",
      "[Train epoch 20/50] loss=0.027862, train_rmse=0.154913\n",
      "[Train epoch 25/50] loss=0.024930, train_rmse=0.157058\n",
      "[Train epoch 30/50] loss=0.022479, train_rmse=0.153669\n",
      "[Train epoch 35/50] loss=0.020408, train_rmse=0.148468\n",
      "[Train epoch 40/50] loss=0.018089, train_rmse=0.147340\n",
      "[Train epoch 45/50] loss=0.017870, train_rmse=0.148997\n",
      "[Train epoch 50/50] loss=0.017644, train_rmse=0.144823\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13217030800741586\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 92 | labelled size = 940 | pool size = 59060 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.134881, train_rmse=0.292381\n",
      "[Train epoch 5/50] loss=0.069232, train_rmse=0.246166\n",
      "[Train epoch 10/50] loss=0.051275, train_rmse=0.209190\n",
      "[Train epoch 15/50] loss=0.037997, train_rmse=0.176545\n",
      "[Train epoch 20/50] loss=0.031881, train_rmse=0.163645\n",
      "[Train epoch 25/50] loss=0.025444, train_rmse=0.149758\n",
      "[Train epoch 30/50] loss=0.024340, train_rmse=0.147829\n",
      "[Train epoch 35/50] loss=0.021761, train_rmse=0.147503\n",
      "[Train epoch 40/50] loss=0.020032, train_rmse=0.149558\n",
      "[Train epoch 45/50] loss=0.019935, train_rmse=0.146189\n",
      "[Train epoch 50/50] loss=0.018281, train_rmse=0.142485\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1324587769800424\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 93 | labelled size = 950 | pool size = 59050 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.119893, train_rmse=0.291369\n",
      "[Train epoch 5/50] loss=0.064489, train_rmse=0.231016\n",
      "[Train epoch 10/50] loss=0.044063, train_rmse=0.183740\n",
      "[Train epoch 15/50] loss=0.034198, train_rmse=0.171023\n",
      "[Train epoch 20/50] loss=0.027999, train_rmse=0.156288\n",
      "[Train epoch 25/50] loss=0.024884, train_rmse=0.157108\n",
      "[Train epoch 30/50] loss=0.021545, train_rmse=0.148513\n",
      "[Train epoch 35/50] loss=0.019702, train_rmse=0.148721\n",
      "[Train epoch 40/50] loss=0.019379, train_rmse=0.150390\n",
      "[Train epoch 45/50] loss=0.017942, train_rmse=0.145778\n",
      "[Train epoch 50/50] loss=0.018854, train_rmse=0.144936\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13477989986282082\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 94 | labelled size = 960 | pool size = 59040 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.150596, train_rmse=0.295943\n",
      "[Train epoch 5/50] loss=0.068491, train_rmse=0.242753\n",
      "[Train epoch 10/50] loss=0.050736, train_rmse=0.203535\n",
      "[Train epoch 15/50] loss=0.039066, train_rmse=0.178857\n",
      "[Train epoch 20/50] loss=0.032618, train_rmse=0.164604\n",
      "[Train epoch 25/50] loss=0.026592, train_rmse=0.151004\n",
      "[Train epoch 30/50] loss=0.026275, train_rmse=0.154852\n",
      "[Train epoch 35/50] loss=0.021709, train_rmse=0.150152\n",
      "[Train epoch 40/50] loss=0.018759, train_rmse=0.145567\n",
      "[Train epoch 45/50] loss=0.019585, train_rmse=0.145308\n",
      "[Train epoch 50/50] loss=0.017393, train_rmse=0.146328\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13237660819131308\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 95 | labelled size = 970 | pool size = 59030 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.119118, train_rmse=0.288179\n",
      "[Train epoch 5/50] loss=0.062448, train_rmse=0.228297\n",
      "[Train epoch 10/50] loss=0.044104, train_rmse=0.184365\n",
      "[Train epoch 15/50] loss=0.034275, train_rmse=0.172969\n",
      "[Train epoch 20/50] loss=0.030494, train_rmse=0.157067\n",
      "[Train epoch 25/50] loss=0.025023, train_rmse=0.160520\n",
      "[Train epoch 30/50] loss=0.024325, train_rmse=0.157336\n",
      "[Train epoch 35/50] loss=0.023189, train_rmse=0.148414\n",
      "[Train epoch 40/50] loss=0.020871, train_rmse=0.151754\n",
      "[Train epoch 45/50] loss=0.019232, train_rmse=0.146646\n",
      "[Train epoch 50/50] loss=0.019307, train_rmse=0.143353\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13314060658773852\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 96 | labelled size = 980 | pool size = 59020 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.114252, train_rmse=0.286869\n",
      "[Train epoch 5/50] loss=0.062545, train_rmse=0.222426\n",
      "[Train epoch 10/50] loss=0.042803, train_rmse=0.180240\n",
      "[Train epoch 15/50] loss=0.033791, train_rmse=0.169651\n",
      "[Train epoch 20/50] loss=0.027068, train_rmse=0.157923\n",
      "[Train epoch 25/50] loss=0.024935, train_rmse=0.154840\n",
      "[Train epoch 30/50] loss=0.022327, train_rmse=0.151644\n",
      "[Train epoch 35/50] loss=0.020350, train_rmse=0.152201\n",
      "[Train epoch 40/50] loss=0.019739, train_rmse=0.143417\n",
      "[Train epoch 45/50] loss=0.019383, train_rmse=0.148894\n",
      "[Train epoch 50/50] loss=0.018070, train_rmse=0.147501\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.12929159515756705\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 97 | labelled size = 990 | pool size = 59010 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.113368, train_rmse=0.286664\n",
      "[Train epoch 5/50] loss=0.059069, train_rmse=0.215002\n",
      "[Train epoch 10/50] loss=0.040382, train_rmse=0.177345\n",
      "[Train epoch 15/50] loss=0.030189, train_rmse=0.154633\n",
      "[Train epoch 20/50] loss=0.026615, train_rmse=0.149785\n",
      "[Train epoch 25/50] loss=0.023412, train_rmse=0.159420\n",
      "[Train epoch 30/50] loss=0.020866, train_rmse=0.146849\n",
      "[Train epoch 35/50] loss=0.019781, train_rmse=0.150195\n",
      "[Train epoch 40/50] loss=0.020008, train_rmse=0.150118\n",
      "[Train epoch 45/50] loss=0.017689, train_rmse=0.142736\n",
      "[Train epoch 50/50] loss=0.016929, train_rmse=0.146881\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13157506540236313\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 98 | labelled size = 1000 | pool size = 59000 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.138492, train_rmse=0.295046\n",
      "[Train epoch 5/50] loss=0.067716, train_rmse=0.237154\n",
      "[Train epoch 10/50] loss=0.048377, train_rmse=0.191560\n",
      "[Train epoch 15/50] loss=0.036785, train_rmse=0.173678\n",
      "[Train epoch 20/50] loss=0.031899, train_rmse=0.160089\n",
      "[Train epoch 25/50] loss=0.026972, train_rmse=0.157949\n",
      "[Train epoch 30/50] loss=0.024531, train_rmse=0.150298\n",
      "[Train epoch 35/50] loss=0.022881, train_rmse=0.149101\n",
      "[Train epoch 40/50] loss=0.021285, train_rmse=0.147480\n",
      "[Train epoch 45/50] loss=0.020384, train_rmse=0.146834\n",
      "[Train epoch 50/50] loss=0.019799, train_rmse=0.143593\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.12920113024807747\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 99 | labelled size = 1010 | pool size = 58990 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.145847, train_rmse=0.296804\n",
      "[Train epoch 5/50] loss=0.068007, train_rmse=0.244001\n",
      "[Train epoch 10/50] loss=0.046837, train_rmse=0.188835\n",
      "[Train epoch 15/50] loss=0.035828, train_rmse=0.167377\n",
      "[Train epoch 20/50] loss=0.029846, train_rmse=0.157624\n",
      "[Train epoch 25/50] loss=0.025329, train_rmse=0.154215\n",
      "[Train epoch 30/50] loss=0.023749, train_rmse=0.149031\n",
      "[Train epoch 35/50] loss=0.021488, train_rmse=0.157697\n",
      "[Train epoch 40/50] loss=0.019267, train_rmse=0.148568\n",
      "[Train epoch 45/50] loss=0.019110, train_rmse=0.144249\n",
      "[Train epoch 50/50] loss=0.016971, train_rmse=0.144278\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1292553303152545\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 100 | labelled size = 1020 | pool size = 58980 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.115915, train_rmse=0.286352\n",
      "[Train epoch 5/50] loss=0.055480, train_rmse=0.211420\n",
      "[Train epoch 10/50] loss=0.039183, train_rmse=0.174266\n",
      "[Train epoch 15/50] loss=0.030499, train_rmse=0.158817\n",
      "[Train epoch 20/50] loss=0.025825, train_rmse=0.153620\n",
      "[Train epoch 25/50] loss=0.023812, train_rmse=0.150451\n",
      "[Train epoch 30/50] loss=0.020544, train_rmse=0.147987\n",
      "[Train epoch 35/50] loss=0.019171, train_rmse=0.148536\n",
      "[Train epoch 40/50] loss=0.018662, train_rmse=0.144181\n",
      "[Train epoch 45/50] loss=0.016314, train_rmse=0.145711\n",
      "[Train epoch 50/50] loss=0.016469, train_rmse=0.145099\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1291247690832062\n",
      "Results saved to outputs/bnn_ssl/history_BNN_Analytical_PredCovariance_Run4.json\n",
      "\n",
      "\n",
      "========== Running PredCovariance Seed 5 ==========\n",
      "Starting SSL pretraining (rotation)...\n",
      "[SSL epoch 1/5] loss=0.0963\n",
      "[SSL epoch 2/5] loss=0.0493\n",
      "[SSL epoch 3/5] loss=0.0417\n",
      "[SSL epoch 4/5] loss=0.0390\n",
      "[SSL epoch 5/5] loss=0.0378\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "Training dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "Initial Labelled set size: 20\n",
      "\n",
      "=== Acquisition iteration 0 | labelled size = 20 | pool size = 59980 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.100475, train_rmse=0.307517\n",
      "[Train epoch 5/50] loss=0.079018, train_rmse=0.291976\n",
      "[Train epoch 10/50] loss=0.053158, train_rmse=0.277825\n",
      "[Train epoch 15/50] loss=0.045872, train_rmse=0.266850\n",
      "[Train epoch 20/50] loss=0.026207, train_rmse=0.264905\n",
      "[Train epoch 25/50] loss=0.021236, train_rmse=0.257495\n",
      "[Train epoch 30/50] loss=0.016887, train_rmse=0.256319\n",
      "[Train epoch 35/50] loss=0.016661, train_rmse=0.256743\n",
      "[Train epoch 40/50] loss=0.011759, train_rmse=0.255165\n",
      "[Train epoch 45/50] loss=0.014892, train_rmse=0.255834\n",
      "[Train epoch 50/50] loss=0.016281, train_rmse=0.256570\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.25269805769904163\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 1 | labelled size = 30 | pool size = 59970 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.102784, train_rmse=0.304136\n",
      "[Train epoch 5/50] loss=0.073988, train_rmse=0.296392\n",
      "[Train epoch 10/50] loss=0.059397, train_rmse=0.279432\n",
      "[Train epoch 15/50] loss=0.042195, train_rmse=0.269139\n",
      "[Train epoch 20/50] loss=0.029259, train_rmse=0.261702\n",
      "[Train epoch 25/50] loss=0.023085, train_rmse=0.260131\n",
      "[Train epoch 30/50] loss=0.018326, train_rmse=0.257799\n",
      "[Train epoch 35/50] loss=0.015576, train_rmse=0.253780\n",
      "[Train epoch 40/50] loss=0.014798, train_rmse=0.254119\n",
      "[Train epoch 45/50] loss=0.012897, train_rmse=0.258033\n",
      "[Train epoch 50/50] loss=0.016016, train_rmse=0.257257\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.25240731919735077\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 2 | labelled size = 40 | pool size = 59960 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.102135, train_rmse=0.349610\n",
      "[Train epoch 5/50] loss=0.081745, train_rmse=0.298915\n",
      "[Train epoch 10/50] loss=0.071496, train_rmse=0.289863\n",
      "[Train epoch 15/50] loss=0.057025, train_rmse=0.277713\n",
      "[Train epoch 20/50] loss=0.050749, train_rmse=0.266859\n",
      "[Train epoch 25/50] loss=0.040252, train_rmse=0.258436\n",
      "[Train epoch 30/50] loss=0.034317, train_rmse=0.255781\n",
      "[Train epoch 35/50] loss=0.027172, train_rmse=0.250388\n",
      "[Train epoch 40/50] loss=0.025946, train_rmse=0.246826\n",
      "[Train epoch 45/50] loss=0.021398, train_rmse=0.248951\n",
      "[Train epoch 50/50] loss=0.019051, train_rmse=0.244658\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.23641559856156932\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 3 | labelled size = 50 | pool size = 59950 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.193410, train_rmse=0.485983\n",
      "[Train epoch 5/50] loss=0.227539, train_rmse=0.327108\n",
      "[Train epoch 10/50] loss=0.113311, train_rmse=0.303175\n",
      "[Train epoch 15/50] loss=0.095611, train_rmse=0.302568\n",
      "[Train epoch 20/50] loss=0.086714, train_rmse=0.301196\n",
      "[Train epoch 25/50] loss=0.075444, train_rmse=0.298184\n",
      "[Train epoch 30/50] loss=0.064222, train_rmse=0.293344\n",
      "[Train epoch 35/50] loss=0.056689, train_rmse=0.287270\n",
      "[Train epoch 40/50] loss=0.058718, train_rmse=0.282692\n",
      "[Train epoch 45/50] loss=0.051786, train_rmse=0.279586\n",
      "[Train epoch 50/50] loss=0.046558, train_rmse=0.278415\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.27347298674581244\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 4 | labelled size = 60 | pool size = 59940 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.233206, train_rmse=0.658076\n",
      "[Train epoch 5/50] loss=0.167938, train_rmse=0.312989\n",
      "[Train epoch 10/50] loss=0.101077, train_rmse=0.307351\n",
      "[Train epoch 15/50] loss=0.091890, train_rmse=0.306687\n",
      "[Train epoch 20/50] loss=0.081019, train_rmse=0.304060\n",
      "[Train epoch 25/50] loss=0.074148, train_rmse=0.295613\n",
      "[Train epoch 30/50] loss=0.072143, train_rmse=0.289727\n",
      "[Train epoch 35/50] loss=0.068532, train_rmse=0.285590\n",
      "[Train epoch 40/50] loss=0.062347, train_rmse=0.280536\n",
      "[Train epoch 45/50] loss=0.061463, train_rmse=0.276247\n",
      "[Train epoch 50/50] loss=0.052508, train_rmse=0.273479\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.26740381370755056\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 5 | labelled size = 70 | pool size = 59930 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=1.428564, train_rmse=0.891945\n",
      "[Train epoch 5/50] loss=1.685168, train_rmse=0.375352\n",
      "[Train epoch 10/50] loss=0.274327, train_rmse=0.317717\n",
      "[Train epoch 15/50] loss=0.131084, train_rmse=0.302482\n",
      "[Train epoch 20/50] loss=0.111559, train_rmse=0.304059\n",
      "[Train epoch 25/50] loss=0.089684, train_rmse=0.304117\n",
      "[Train epoch 30/50] loss=0.085211, train_rmse=0.302751\n",
      "[Train epoch 35/50] loss=0.081363, train_rmse=0.300504\n",
      "[Train epoch 40/50] loss=0.078504, train_rmse=0.294568\n",
      "[Train epoch 45/50] loss=0.087439, train_rmse=0.294827\n",
      "[Train epoch 50/50] loss=0.071419, train_rmse=0.292602\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.26271027872896496\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 6 | labelled size = 80 | pool size = 59920 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=90.661690, train_rmse=2.555561\n",
      "[Train epoch 5/50] loss=4.641345, train_rmse=0.991394\n",
      "[Train epoch 10/50] loss=1.155541, train_rmse=0.380349\n",
      "[Train epoch 15/50] loss=0.170774, train_rmse=0.314341\n",
      "[Train epoch 20/50] loss=0.108169, train_rmse=0.308836\n",
      "[Train epoch 25/50] loss=0.147850, train_rmse=0.304261\n",
      "[Train epoch 30/50] loss=0.087382, train_rmse=0.303131\n",
      "[Train epoch 35/50] loss=0.167561, train_rmse=0.300627\n",
      "[Train epoch 40/50] loss=0.080574, train_rmse=0.297401\n",
      "[Train epoch 45/50] loss=0.086366, train_rmse=0.293265\n",
      "[Train epoch 50/50] loss=0.076080, train_rmse=0.291425\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.26813679211701663\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 7 | labelled size = 90 | pool size = 59910 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=2.340334, train_rmse=0.533861\n",
      "[Train epoch 5/50] loss=0.109386, train_rmse=0.309232\n",
      "[Train epoch 10/50] loss=0.094188, train_rmse=0.305359\n",
      "[Train epoch 15/50] loss=0.087753, train_rmse=0.304286\n",
      "[Train epoch 20/50] loss=0.082513, train_rmse=0.295779\n",
      "[Train epoch 25/50] loss=0.074535, train_rmse=0.289627\n",
      "[Train epoch 30/50] loss=0.068891, train_rmse=0.282960\n",
      "[Train epoch 35/50] loss=0.062319, train_rmse=0.279549\n",
      "[Train epoch 40/50] loss=0.062148, train_rmse=0.275478\n",
      "[Train epoch 45/50] loss=0.056802, train_rmse=0.275177\n",
      "[Train epoch 50/50] loss=0.055624, train_rmse=0.272347\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24358082022617394\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 8 | labelled size = 100 | pool size = 59900 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=1.251033, train_rmse=0.763541\n",
      "[Train epoch 5/50] loss=0.155354, train_rmse=0.316275\n",
      "[Train epoch 10/50] loss=0.101110, train_rmse=0.307273\n",
      "[Train epoch 15/50] loss=0.089265, train_rmse=0.303722\n",
      "[Train epoch 20/50] loss=0.081022, train_rmse=0.296599\n",
      "[Train epoch 25/50] loss=0.071561, train_rmse=0.289621\n",
      "[Train epoch 30/50] loss=0.071311, train_rmse=0.282434\n",
      "[Train epoch 35/50] loss=0.062540, train_rmse=0.275693\n",
      "[Train epoch 40/50] loss=0.057423, train_rmse=0.271766\n",
      "[Train epoch 45/50] loss=0.051941, train_rmse=0.267695\n",
      "[Train epoch 50/50] loss=0.049918, train_rmse=0.264548\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24534829542113248\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 9 | labelled size = 110 | pool size = 59890 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=1.507860, train_rmse=0.443407\n",
      "[Train epoch 5/50] loss=0.137653, train_rmse=0.315194\n",
      "[Train epoch 10/50] loss=0.094633, train_rmse=0.306372\n",
      "[Train epoch 15/50] loss=0.088768, train_rmse=0.300697\n",
      "[Train epoch 20/50] loss=0.085905, train_rmse=0.299560\n",
      "[Train epoch 25/50] loss=0.080941, train_rmse=0.292211\n",
      "[Train epoch 30/50] loss=0.072931, train_rmse=0.287435\n",
      "[Train epoch 35/50] loss=0.069069, train_rmse=0.280727\n",
      "[Train epoch 40/50] loss=0.063939, train_rmse=0.276638\n",
      "[Train epoch 45/50] loss=0.060356, train_rmse=0.272346\n",
      "[Train epoch 50/50] loss=0.058353, train_rmse=0.268698\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24512768413546707\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 10 | labelled size = 120 | pool size = 59880 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=1.245645, train_rmse=0.879184\n",
      "[Train epoch 5/50] loss=0.197700, train_rmse=0.313273\n",
      "[Train epoch 10/50] loss=0.091123, train_rmse=0.302255\n",
      "[Train epoch 15/50] loss=0.086503, train_rmse=0.300816\n",
      "[Train epoch 20/50] loss=0.081107, train_rmse=0.294459\n",
      "[Train epoch 25/50] loss=0.072117, train_rmse=0.284319\n",
      "[Train epoch 30/50] loss=0.068221, train_rmse=0.276705\n",
      "[Train epoch 35/50] loss=0.064822, train_rmse=0.271806\n",
      "[Train epoch 40/50] loss=0.058602, train_rmse=0.268130\n",
      "[Train epoch 45/50] loss=0.053194, train_rmse=0.263802\n",
      "[Train epoch 50/50] loss=0.051547, train_rmse=0.261098\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.24237444824738286\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 11 | labelled size = 130 | pool size = 59870 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=55.486761, train_rmse=1.481042\n",
      "[Train epoch 5/50] loss=0.284167, train_rmse=0.331354\n",
      "[Train epoch 10/50] loss=0.136610, train_rmse=0.315006\n",
      "[Train epoch 15/50] loss=0.108924, train_rmse=0.311242\n",
      "[Train epoch 20/50] loss=0.092565, train_rmse=0.304409\n",
      "[Train epoch 25/50] loss=0.091774, train_rmse=0.303372\n",
      "[Train epoch 30/50] loss=0.092438, train_rmse=0.303168\n",
      "[Train epoch 35/50] loss=0.092475, train_rmse=0.304445\n",
      "[Train epoch 40/50] loss=0.089329, train_rmse=0.301256\n",
      "[Train epoch 45/50] loss=0.086101, train_rmse=0.301320\n",
      "[Train epoch 50/50] loss=0.086530, train_rmse=0.299703\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.2709678580447943\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 12 | labelled size = 140 | pool size = 59860 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.265060, train_rmse=0.359066\n",
      "[Train epoch 5/50] loss=0.093723, train_rmse=0.295481\n",
      "[Train epoch 10/50] loss=0.074659, train_rmse=0.291015\n",
      "[Train epoch 15/50] loss=0.062112, train_rmse=0.270665\n",
      "[Train epoch 20/50] loss=0.056599, train_rmse=0.263528\n",
      "[Train epoch 25/50] loss=0.050476, train_rmse=0.256129\n",
      "[Train epoch 30/50] loss=0.047003, train_rmse=0.252098\n",
      "[Train epoch 35/50] loss=0.043848, train_rmse=0.247749\n",
      "[Train epoch 40/50] loss=0.038102, train_rmse=0.246454\n",
      "[Train epoch 45/50] loss=0.036562, train_rmse=0.241987\n",
      "[Train epoch 50/50] loss=0.031135, train_rmse=0.239100\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.224086764619214\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 13 | labelled size = 150 | pool size = 59850 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.563218, train_rmse=0.371286\n",
      "[Train epoch 5/50] loss=0.097241, train_rmse=0.305419\n",
      "[Train epoch 10/50] loss=0.082958, train_rmse=0.296298\n",
      "[Train epoch 15/50] loss=0.074359, train_rmse=0.282791\n",
      "[Train epoch 20/50] loss=0.062607, train_rmse=0.267614\n",
      "[Train epoch 25/50] loss=0.054500, train_rmse=0.265552\n",
      "[Train epoch 30/50] loss=0.051581, train_rmse=0.256813\n",
      "[Train epoch 35/50] loss=0.045647, train_rmse=0.253315\n",
      "[Train epoch 40/50] loss=0.041706, train_rmse=0.246792\n",
      "[Train epoch 45/50] loss=0.039376, train_rmse=0.246448\n",
      "[Train epoch 50/50] loss=0.037423, train_rmse=0.240589\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21431975773414255\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 14 | labelled size = 160 | pool size = 59840 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.654459, train_rmse=0.369995\n",
      "[Train epoch 5/50] loss=0.091839, train_rmse=0.301906\n",
      "[Train epoch 10/50] loss=0.083057, train_rmse=0.292944\n",
      "[Train epoch 15/50] loss=0.075730, train_rmse=0.282395\n",
      "[Train epoch 20/50] loss=0.065453, train_rmse=0.273141\n",
      "[Train epoch 25/50] loss=0.057054, train_rmse=0.262337\n",
      "[Train epoch 30/50] loss=0.052514, train_rmse=0.258374\n",
      "[Train epoch 35/50] loss=0.048988, train_rmse=0.254587\n",
      "[Train epoch 40/50] loss=0.042582, train_rmse=0.251074\n",
      "[Train epoch 45/50] loss=0.042606, train_rmse=0.248206\n",
      "[Train epoch 50/50] loss=0.037247, train_rmse=0.243908\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.22606994650179976\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 15 | labelled size = 170 | pool size = 59830 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.450471, train_rmse=0.343202\n",
      "[Train epoch 5/50] loss=0.088149, train_rmse=0.299889\n",
      "[Train epoch 10/50] loss=0.078327, train_rmse=0.288240\n",
      "[Train epoch 15/50] loss=0.070078, train_rmse=0.272374\n",
      "[Train epoch 20/50] loss=0.058499, train_rmse=0.263792\n",
      "[Train epoch 25/50] loss=0.052394, train_rmse=0.254180\n",
      "[Train epoch 30/50] loss=0.044950, train_rmse=0.254238\n",
      "[Train epoch 35/50] loss=0.042065, train_rmse=0.249351\n",
      "[Train epoch 40/50] loss=0.038212, train_rmse=0.245706\n",
      "[Train epoch 45/50] loss=0.033767, train_rmse=0.239061\n",
      "[Train epoch 50/50] loss=0.031778, train_rmse=0.238857\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21451564781538388\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 16 | labelled size = 180 | pool size = 59820 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.320455, train_rmse=0.312918\n",
      "[Train epoch 5/50] loss=0.086295, train_rmse=0.295472\n",
      "[Train epoch 10/50] loss=0.077402, train_rmse=0.283092\n",
      "[Train epoch 15/50] loss=0.063403, train_rmse=0.268261\n",
      "[Train epoch 20/50] loss=0.055096, train_rmse=0.256311\n",
      "[Train epoch 25/50] loss=0.046291, train_rmse=0.253171\n",
      "[Train epoch 30/50] loss=0.039838, train_rmse=0.246062\n",
      "[Train epoch 35/50] loss=0.038555, train_rmse=0.240936\n",
      "[Train epoch 40/50] loss=0.039299, train_rmse=0.238534\n",
      "[Train epoch 45/50] loss=0.031600, train_rmse=0.234980\n",
      "[Train epoch 50/50] loss=0.032010, train_rmse=0.232862\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21345003548668973\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 17 | labelled size = 190 | pool size = 59810 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.513983, train_rmse=0.328868\n",
      "[Train epoch 5/50] loss=0.090428, train_rmse=0.299208\n",
      "[Train epoch 10/50] loss=0.082068, train_rmse=0.294612\n",
      "[Train epoch 15/50] loss=0.071703, train_rmse=0.282017\n",
      "[Train epoch 20/50] loss=0.064130, train_rmse=0.271969\n",
      "[Train epoch 25/50] loss=0.059159, train_rmse=0.265956\n",
      "[Train epoch 30/50] loss=0.051523, train_rmse=0.257942\n",
      "[Train epoch 35/50] loss=0.047299, train_rmse=0.253165\n",
      "[Train epoch 40/50] loss=0.043650, train_rmse=0.248896\n",
      "[Train epoch 45/50] loss=0.042094, train_rmse=0.245492\n",
      "[Train epoch 50/50] loss=0.041765, train_rmse=0.243613\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21649960198707205\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 18 | labelled size = 200 | pool size = 59800 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.398120, train_rmse=0.316120\n",
      "[Train epoch 5/50] loss=0.087257, train_rmse=0.300839\n",
      "[Train epoch 10/50] loss=0.080853, train_rmse=0.288832\n",
      "[Train epoch 15/50] loss=0.068257, train_rmse=0.278982\n",
      "[Train epoch 20/50] loss=0.062045, train_rmse=0.266741\n",
      "[Train epoch 25/50] loss=0.055386, train_rmse=0.260938\n",
      "[Train epoch 30/50] loss=0.050361, train_rmse=0.254830\n",
      "[Train epoch 35/50] loss=0.047721, train_rmse=0.249865\n",
      "[Train epoch 40/50] loss=0.042589, train_rmse=0.242261\n",
      "[Train epoch 45/50] loss=0.040507, train_rmse=0.242251\n",
      "[Train epoch 50/50] loss=0.039628, train_rmse=0.242960\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.21033733190714657\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 19 | labelled size = 210 | pool size = 59790 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.384849, train_rmse=0.320976\n",
      "[Train epoch 5/50] loss=0.086610, train_rmse=0.296096\n",
      "[Train epoch 10/50] loss=0.074572, train_rmse=0.279340\n",
      "[Train epoch 15/50] loss=0.062172, train_rmse=0.264047\n",
      "[Train epoch 20/50] loss=0.054243, train_rmse=0.252645\n",
      "[Train epoch 25/50] loss=0.047562, train_rmse=0.248013\n",
      "[Train epoch 30/50] loss=0.043618, train_rmse=0.243984\n",
      "[Train epoch 35/50] loss=0.039989, train_rmse=0.239257\n",
      "[Train epoch 40/50] loss=0.036211, train_rmse=0.234565\n",
      "[Train epoch 45/50] loss=0.031344, train_rmse=0.234330\n",
      "[Train epoch 50/50] loss=0.029015, train_rmse=0.233638\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20800116952237208\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 20 | labelled size = 220 | pool size = 59780 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.335125, train_rmse=0.316763\n",
      "[Train epoch 5/50] loss=0.085209, train_rmse=0.293206\n",
      "[Train epoch 10/50] loss=0.070040, train_rmse=0.274420\n",
      "[Train epoch 15/50] loss=0.061366, train_rmse=0.262272\n",
      "[Train epoch 20/50] loss=0.052368, train_rmse=0.250442\n",
      "[Train epoch 25/50] loss=0.047432, train_rmse=0.242937\n",
      "[Train epoch 30/50] loss=0.039556, train_rmse=0.239375\n",
      "[Train epoch 35/50] loss=0.034556, train_rmse=0.234585\n",
      "[Train epoch 40/50] loss=0.031266, train_rmse=0.231739\n",
      "[Train epoch 45/50] loss=0.028325, train_rmse=0.226152\n",
      "[Train epoch 50/50] loss=0.027421, train_rmse=0.226206\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1996277208948992\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 21 | labelled size = 230 | pool size = 59770 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.337988, train_rmse=0.322407\n",
      "[Train epoch 5/50] loss=0.083444, train_rmse=0.296941\n",
      "[Train epoch 10/50] loss=0.072782, train_rmse=0.280733\n",
      "[Train epoch 15/50] loss=0.062282, train_rmse=0.267101\n",
      "[Train epoch 20/50] loss=0.055738, train_rmse=0.254683\n",
      "[Train epoch 25/50] loss=0.048934, train_rmse=0.246909\n",
      "[Train epoch 30/50] loss=0.044154, train_rmse=0.244230\n",
      "[Train epoch 35/50] loss=0.038583, train_rmse=0.240377\n",
      "[Train epoch 40/50] loss=0.033863, train_rmse=0.235652\n",
      "[Train epoch 45/50] loss=0.031401, train_rmse=0.233047\n",
      "[Train epoch 50/50] loss=0.026203, train_rmse=0.228652\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1997229587670747\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 22 | labelled size = 240 | pool size = 59760 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.389593, train_rmse=0.318821\n",
      "[Train epoch 5/50] loss=0.085881, train_rmse=0.296428\n",
      "[Train epoch 10/50] loss=0.077076, train_rmse=0.280863\n",
      "[Train epoch 15/50] loss=0.066690, train_rmse=0.269825\n",
      "[Train epoch 20/50] loss=0.060377, train_rmse=0.259486\n",
      "[Train epoch 25/50] loss=0.052535, train_rmse=0.250647\n",
      "[Train epoch 30/50] loss=0.046273, train_rmse=0.244351\n",
      "[Train epoch 35/50] loss=0.042167, train_rmse=0.239934\n",
      "[Train epoch 40/50] loss=0.038545, train_rmse=0.237249\n",
      "[Train epoch 45/50] loss=0.034236, train_rmse=0.234002\n",
      "[Train epoch 50/50] loss=0.031221, train_rmse=0.231706\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20877160405962475\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 23 | labelled size = 250 | pool size = 59750 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.388843, train_rmse=0.318126\n",
      "[Train epoch 5/50] loss=0.085769, train_rmse=0.296014\n",
      "[Train epoch 10/50] loss=0.076034, train_rmse=0.279346\n",
      "[Train epoch 15/50] loss=0.067346, train_rmse=0.266298\n",
      "[Train epoch 20/50] loss=0.057425, train_rmse=0.254245\n",
      "[Train epoch 25/50] loss=0.050990, train_rmse=0.247181\n",
      "[Train epoch 30/50] loss=0.047538, train_rmse=0.240405\n",
      "[Train epoch 35/50] loss=0.042789, train_rmse=0.234353\n",
      "[Train epoch 40/50] loss=0.039440, train_rmse=0.231408\n",
      "[Train epoch 45/50] loss=0.031610, train_rmse=0.227341\n",
      "[Train epoch 50/50] loss=0.028917, train_rmse=0.224591\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19954861016206477\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 24 | labelled size = 260 | pool size = 59740 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.407472, train_rmse=0.317189\n",
      "[Train epoch 5/50] loss=0.087860, train_rmse=0.295135\n",
      "[Train epoch 10/50] loss=0.076910, train_rmse=0.284292\n",
      "[Train epoch 15/50] loss=0.068868, train_rmse=0.270030\n",
      "[Train epoch 20/50] loss=0.061569, train_rmse=0.257412\n",
      "[Train epoch 25/50] loss=0.058774, train_rmse=0.253738\n",
      "[Train epoch 30/50] loss=0.051762, train_rmse=0.250149\n",
      "[Train epoch 35/50] loss=0.046462, train_rmse=0.243201\n",
      "[Train epoch 40/50] loss=0.040682, train_rmse=0.236897\n",
      "[Train epoch 45/50] loss=0.039751, train_rmse=0.233585\n",
      "[Train epoch 50/50] loss=0.037470, train_rmse=0.229123\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20577049183222562\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 25 | labelled size = 270 | pool size = 59730 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.366972, train_rmse=0.320628\n",
      "[Train epoch 5/50] loss=0.085809, train_rmse=0.294581\n",
      "[Train epoch 10/50] loss=0.073706, train_rmse=0.277715\n",
      "[Train epoch 15/50] loss=0.065169, train_rmse=0.265703\n",
      "[Train epoch 20/50] loss=0.056607, train_rmse=0.252084\n",
      "[Train epoch 25/50] loss=0.049644, train_rmse=0.246920\n",
      "[Train epoch 30/50] loss=0.044251, train_rmse=0.239468\n",
      "[Train epoch 35/50] loss=0.040189, train_rmse=0.233559\n",
      "[Train epoch 40/50] loss=0.035150, train_rmse=0.229357\n",
      "[Train epoch 45/50] loss=0.035791, train_rmse=0.227629\n",
      "[Train epoch 50/50] loss=0.030334, train_rmse=0.228218\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20630592993508304\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 26 | labelled size = 280 | pool size = 59720 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.369388, train_rmse=0.311380\n",
      "[Train epoch 5/50] loss=0.084923, train_rmse=0.293248\n",
      "[Train epoch 10/50] loss=0.071222, train_rmse=0.276668\n",
      "[Train epoch 15/50] loss=0.065643, train_rmse=0.261232\n",
      "[Train epoch 20/50] loss=0.057752, train_rmse=0.251013\n",
      "[Train epoch 25/50] loss=0.049624, train_rmse=0.244491\n",
      "[Train epoch 30/50] loss=0.043878, train_rmse=0.238658\n",
      "[Train epoch 35/50] loss=0.044096, train_rmse=0.232528\n",
      "[Train epoch 40/50] loss=0.036308, train_rmse=0.225267\n",
      "[Train epoch 45/50] loss=0.033435, train_rmse=0.223430\n",
      "[Train epoch 50/50] loss=0.029540, train_rmse=0.224701\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1997725656412875\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 27 | labelled size = 290 | pool size = 59710 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.418772, train_rmse=0.318687\n",
      "[Train epoch 5/50] loss=0.086547, train_rmse=0.293316\n",
      "[Train epoch 10/50] loss=0.075616, train_rmse=0.278040\n",
      "[Train epoch 15/50] loss=0.063968, train_rmse=0.261171\n",
      "[Train epoch 20/50] loss=0.056491, train_rmse=0.251868\n",
      "[Train epoch 25/50] loss=0.048624, train_rmse=0.240651\n",
      "[Train epoch 30/50] loss=0.045416, train_rmse=0.235732\n",
      "[Train epoch 35/50] loss=0.039689, train_rmse=0.228737\n",
      "[Train epoch 40/50] loss=0.035246, train_rmse=0.224585\n",
      "[Train epoch 45/50] loss=0.032624, train_rmse=0.221282\n",
      "[Train epoch 50/50] loss=0.028633, train_rmse=0.219228\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20108290016289965\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 28 | labelled size = 300 | pool size = 59700 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.412636, train_rmse=0.312096\n",
      "[Train epoch 5/50] loss=0.085750, train_rmse=0.292545\n",
      "[Train epoch 10/50] loss=0.071360, train_rmse=0.273615\n",
      "[Train epoch 15/50] loss=0.063309, train_rmse=0.259675\n",
      "[Train epoch 20/50] loss=0.054947, train_rmse=0.247088\n",
      "[Train epoch 25/50] loss=0.047249, train_rmse=0.239424\n",
      "[Train epoch 30/50] loss=0.043760, train_rmse=0.233853\n",
      "[Train epoch 35/50] loss=0.036858, train_rmse=0.226776\n",
      "[Train epoch 40/50] loss=0.034260, train_rmse=0.227622\n",
      "[Train epoch 45/50] loss=0.032000, train_rmse=0.223860\n",
      "[Train epoch 50/50] loss=0.030156, train_rmse=0.220452\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19674270887570505\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 29 | labelled size = 310 | pool size = 59690 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.404074, train_rmse=0.320744\n",
      "[Train epoch 5/50] loss=0.088384, train_rmse=0.298513\n",
      "[Train epoch 10/50] loss=0.078700, train_rmse=0.282303\n",
      "[Train epoch 15/50] loss=0.067370, train_rmse=0.267561\n",
      "[Train epoch 20/50] loss=0.061384, train_rmse=0.254999\n",
      "[Train epoch 25/50] loss=0.054725, train_rmse=0.243852\n",
      "[Train epoch 30/50] loss=0.049047, train_rmse=0.237846\n",
      "[Train epoch 35/50] loss=0.043766, train_rmse=0.233559\n",
      "[Train epoch 40/50] loss=0.039461, train_rmse=0.230822\n",
      "[Train epoch 45/50] loss=0.038054, train_rmse=0.228106\n",
      "[Train epoch 50/50] loss=0.035134, train_rmse=0.224854\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1977025746336578\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 30 | labelled size = 320 | pool size = 59680 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.330320, train_rmse=0.321186\n",
      "[Train epoch 5/50] loss=0.084707, train_rmse=0.291988\n",
      "[Train epoch 10/50] loss=0.070977, train_rmse=0.270432\n",
      "[Train epoch 15/50] loss=0.059937, train_rmse=0.258086\n",
      "[Train epoch 20/50] loss=0.052630, train_rmse=0.246052\n",
      "[Train epoch 25/50] loss=0.048863, train_rmse=0.238727\n",
      "[Train epoch 30/50] loss=0.041785, train_rmse=0.233438\n",
      "[Train epoch 35/50] loss=0.036966, train_rmse=0.227011\n",
      "[Train epoch 40/50] loss=0.036538, train_rmse=0.224948\n",
      "[Train epoch 45/50] loss=0.029835, train_rmse=0.221019\n",
      "[Train epoch 50/50] loss=0.027091, train_rmse=0.219172\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19653369566368795\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 31 | labelled size = 330 | pool size = 59670 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.393062, train_rmse=0.318478\n",
      "[Train epoch 5/50] loss=0.086047, train_rmse=0.294581\n",
      "[Train epoch 10/50] loss=0.074591, train_rmse=0.276247\n",
      "[Train epoch 15/50] loss=0.067283, train_rmse=0.261198\n",
      "[Train epoch 20/50] loss=0.057724, train_rmse=0.252378\n",
      "[Train epoch 25/50] loss=0.055500, train_rmse=0.247380\n",
      "[Train epoch 30/50] loss=0.051867, train_rmse=0.243140\n",
      "[Train epoch 35/50] loss=0.045243, train_rmse=0.239835\n",
      "[Train epoch 40/50] loss=0.041793, train_rmse=0.234921\n",
      "[Train epoch 45/50] loss=0.039793, train_rmse=0.231367\n",
      "[Train epoch 50/50] loss=0.037827, train_rmse=0.228359\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.20089207721086513\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 32 | labelled size = 340 | pool size = 59660 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.412741, train_rmse=0.315150\n",
      "[Train epoch 5/50] loss=0.086619, train_rmse=0.298888\n",
      "[Train epoch 10/50] loss=0.074270, train_rmse=0.278436\n",
      "[Train epoch 15/50] loss=0.065244, train_rmse=0.262315\n",
      "[Train epoch 20/50] loss=0.057014, train_rmse=0.250158\n",
      "[Train epoch 25/50] loss=0.052236, train_rmse=0.242828\n",
      "[Train epoch 30/50] loss=0.048621, train_rmse=0.235513\n",
      "[Train epoch 35/50] loss=0.040608, train_rmse=0.231778\n",
      "[Train epoch 40/50] loss=0.036526, train_rmse=0.225014\n",
      "[Train epoch 45/50] loss=0.032119, train_rmse=0.224579\n",
      "[Train epoch 50/50] loss=0.032203, train_rmse=0.222397\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19833855783035337\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 33 | labelled size = 350 | pool size = 59650 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.423931, train_rmse=0.319818\n",
      "[Train epoch 5/50] loss=0.085716, train_rmse=0.293600\n",
      "[Train epoch 10/50] loss=0.073740, train_rmse=0.274092\n",
      "[Train epoch 15/50] loss=0.062843, train_rmse=0.262325\n",
      "[Train epoch 20/50] loss=0.057864, train_rmse=0.248552\n",
      "[Train epoch 25/50] loss=0.049807, train_rmse=0.241093\n",
      "[Train epoch 30/50] loss=0.042488, train_rmse=0.231802\n",
      "[Train epoch 35/50] loss=0.038849, train_rmse=0.227714\n",
      "[Train epoch 40/50] loss=0.033963, train_rmse=0.220177\n",
      "[Train epoch 45/50] loss=0.031546, train_rmse=0.215556\n",
      "[Train epoch 50/50] loss=0.027827, train_rmse=0.216426\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.19147970247890642\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 34 | labelled size = 360 | pool size = 59640 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.419823, train_rmse=0.317932\n",
      "[Train epoch 5/50] loss=0.087556, train_rmse=0.296421\n",
      "[Train epoch 10/50] loss=0.075663, train_rmse=0.279513\n",
      "[Train epoch 15/50] loss=0.065947, train_rmse=0.262651\n",
      "[Train epoch 20/50] loss=0.057504, train_rmse=0.250962\n",
      "[Train epoch 25/50] loss=0.050100, train_rmse=0.241627\n",
      "[Train epoch 30/50] loss=0.044905, train_rmse=0.234121\n",
      "[Train epoch 35/50] loss=0.038822, train_rmse=0.225974\n",
      "[Train epoch 40/50] loss=0.036577, train_rmse=0.222388\n",
      "[Train epoch 45/50] loss=0.030794, train_rmse=0.219367\n",
      "[Train epoch 50/50] loss=0.030718, train_rmse=0.215775\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18560051743089964\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 35 | labelled size = 370 | pool size = 59630 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.329906, train_rmse=0.312974\n",
      "[Train epoch 5/50] loss=0.079548, train_rmse=0.283056\n",
      "[Train epoch 10/50] loss=0.063397, train_rmse=0.257605\n",
      "[Train epoch 15/50] loss=0.050522, train_rmse=0.241192\n",
      "[Train epoch 20/50] loss=0.043931, train_rmse=0.228463\n",
      "[Train epoch 25/50] loss=0.039420, train_rmse=0.224173\n",
      "[Train epoch 30/50] loss=0.032148, train_rmse=0.218820\n",
      "[Train epoch 35/50] loss=0.029388, train_rmse=0.214507\n",
      "[Train epoch 40/50] loss=0.026767, train_rmse=0.212235\n",
      "[Train epoch 45/50] loss=0.026992, train_rmse=0.210415\n",
      "[Train epoch 50/50] loss=0.024812, train_rmse=0.207200\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17902938111751893\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 36 | labelled size = 380 | pool size = 59620 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.330307, train_rmse=0.314069\n",
      "[Train epoch 5/50] loss=0.082829, train_rmse=0.290230\n",
      "[Train epoch 10/50] loss=0.067348, train_rmse=0.267368\n",
      "[Train epoch 15/50] loss=0.057669, train_rmse=0.250127\n",
      "[Train epoch 20/50] loss=0.048065, train_rmse=0.239968\n",
      "[Train epoch 25/50] loss=0.040733, train_rmse=0.231206\n",
      "[Train epoch 30/50] loss=0.037831, train_rmse=0.225210\n",
      "[Train epoch 35/50] loss=0.032365, train_rmse=0.219107\n",
      "[Train epoch 40/50] loss=0.028193, train_rmse=0.215125\n",
      "[Train epoch 45/50] loss=0.026547, train_rmse=0.211438\n",
      "[Train epoch 50/50] loss=0.024278, train_rmse=0.207680\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1778760938979375\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 37 | labelled size = 390 | pool size = 59610 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.382952, train_rmse=0.316167\n",
      "[Train epoch 5/50] loss=0.085972, train_rmse=0.297301\n",
      "[Train epoch 10/50] loss=0.075275, train_rmse=0.277442\n",
      "[Train epoch 15/50] loss=0.065395, train_rmse=0.258155\n",
      "[Train epoch 20/50] loss=0.061121, train_rmse=0.249494\n",
      "[Train epoch 25/50] loss=0.051552, train_rmse=0.237125\n",
      "[Train epoch 30/50] loss=0.046988, train_rmse=0.234896\n",
      "[Train epoch 35/50] loss=0.043841, train_rmse=0.225255\n",
      "[Train epoch 40/50] loss=0.040096, train_rmse=0.229063\n",
      "[Train epoch 45/50] loss=0.036431, train_rmse=0.224869\n",
      "[Train epoch 50/50] loss=0.033464, train_rmse=0.220228\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18586547917223165\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 38 | labelled size = 400 | pool size = 59600 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.327910, train_rmse=0.307021\n",
      "[Train epoch 5/50] loss=0.083055, train_rmse=0.286965\n",
      "[Train epoch 10/50] loss=0.069471, train_rmse=0.265646\n",
      "[Train epoch 15/50] loss=0.060285, train_rmse=0.249578\n",
      "[Train epoch 20/50] loss=0.049577, train_rmse=0.237005\n",
      "[Train epoch 25/50] loss=0.043976, train_rmse=0.232156\n",
      "[Train epoch 30/50] loss=0.040018, train_rmse=0.222673\n",
      "[Train epoch 35/50] loss=0.036204, train_rmse=0.220485\n",
      "[Train epoch 40/50] loss=0.032860, train_rmse=0.215112\n",
      "[Train epoch 45/50] loss=0.029639, train_rmse=0.218080\n",
      "[Train epoch 50/50] loss=0.027479, train_rmse=0.212389\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1848994682993447\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 39 | labelled size = 410 | pool size = 59590 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.255034, train_rmse=0.307528\n",
      "[Train epoch 5/50] loss=0.081828, train_rmse=0.277954\n",
      "[Train epoch 10/50] loss=0.062164, train_rmse=0.250395\n",
      "[Train epoch 15/50] loss=0.047752, train_rmse=0.238754\n",
      "[Train epoch 20/50] loss=0.041878, train_rmse=0.223920\n",
      "[Train epoch 25/50] loss=0.035985, train_rmse=0.216979\n",
      "[Train epoch 30/50] loss=0.028664, train_rmse=0.212506\n",
      "[Train epoch 35/50] loss=0.026850, train_rmse=0.211486\n",
      "[Train epoch 40/50] loss=0.024458, train_rmse=0.206616\n",
      "[Train epoch 45/50] loss=0.024685, train_rmse=0.206158\n",
      "[Train epoch 50/50] loss=0.022400, train_rmse=0.206520\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1760223234064428\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 40 | labelled size = 420 | pool size = 59580 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.236116, train_rmse=0.306793\n",
      "[Train epoch 5/50] loss=0.078770, train_rmse=0.276080\n",
      "[Train epoch 10/50] loss=0.064628, train_rmse=0.256495\n",
      "[Train epoch 15/50] loss=0.054798, train_rmse=0.241749\n",
      "[Train epoch 20/50] loss=0.045990, train_rmse=0.229818\n",
      "[Train epoch 25/50] loss=0.040419, train_rmse=0.225672\n",
      "[Train epoch 30/50] loss=0.034571, train_rmse=0.220400\n",
      "[Train epoch 35/50] loss=0.031304, train_rmse=0.210751\n",
      "[Train epoch 40/50] loss=0.028464, train_rmse=0.209163\n",
      "[Train epoch 45/50] loss=0.025414, train_rmse=0.207472\n",
      "[Train epoch 50/50] loss=0.024424, train_rmse=0.200531\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17375014431350533\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 41 | labelled size = 430 | pool size = 59570 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.297314, train_rmse=0.308766\n",
      "[Train epoch 5/50] loss=0.075864, train_rmse=0.273073\n",
      "[Train epoch 10/50] loss=0.060232, train_rmse=0.250762\n",
      "[Train epoch 15/50] loss=0.051906, train_rmse=0.235311\n",
      "[Train epoch 20/50] loss=0.043604, train_rmse=0.224121\n",
      "[Train epoch 25/50] loss=0.036506, train_rmse=0.220423\n",
      "[Train epoch 30/50] loss=0.032345, train_rmse=0.210926\n",
      "[Train epoch 35/50] loss=0.028994, train_rmse=0.209791\n",
      "[Train epoch 40/50] loss=0.026664, train_rmse=0.208916\n",
      "[Train epoch 45/50] loss=0.024695, train_rmse=0.206296\n",
      "[Train epoch 50/50] loss=0.021271, train_rmse=0.201895\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17366551629977167\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 42 | labelled size = 440 | pool size = 59560 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.291103, train_rmse=0.315973\n",
      "[Train epoch 5/50] loss=0.079549, train_rmse=0.284208\n",
      "[Train epoch 10/50] loss=0.067223, train_rmse=0.257612\n",
      "[Train epoch 15/50] loss=0.052859, train_rmse=0.239832\n",
      "[Train epoch 20/50] loss=0.045847, train_rmse=0.229352\n",
      "[Train epoch 25/50] loss=0.037881, train_rmse=0.221757\n",
      "[Train epoch 30/50] loss=0.033816, train_rmse=0.214916\n",
      "[Train epoch 35/50] loss=0.029725, train_rmse=0.213957\n",
      "[Train epoch 40/50] loss=0.026683, train_rmse=0.211656\n",
      "[Train epoch 45/50] loss=0.024641, train_rmse=0.206929\n",
      "[Train epoch 50/50] loss=0.022441, train_rmse=0.204003\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17940692624135918\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 43 | labelled size = 450 | pool size = 59550 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.259907, train_rmse=0.308072\n",
      "[Train epoch 5/50] loss=0.076184, train_rmse=0.274613\n",
      "[Train epoch 10/50] loss=0.068326, train_rmse=0.262443\n",
      "[Train epoch 15/50] loss=0.056414, train_rmse=0.239924\n",
      "[Train epoch 20/50] loss=0.047894, train_rmse=0.232430\n",
      "[Train epoch 25/50] loss=0.044664, train_rmse=0.226704\n",
      "[Train epoch 30/50] loss=0.042068, train_rmse=0.225352\n",
      "[Train epoch 35/50] loss=0.038738, train_rmse=0.219811\n",
      "[Train epoch 40/50] loss=0.034480, train_rmse=0.219916\n",
      "[Train epoch 45/50] loss=0.031597, train_rmse=0.213135\n",
      "[Train epoch 50/50] loss=0.030980, train_rmse=0.213992\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18194970416878103\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 44 | labelled size = 460 | pool size = 59540 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.280176, train_rmse=0.309349\n",
      "[Train epoch 5/50] loss=0.080174, train_rmse=0.280983\n",
      "[Train epoch 10/50] loss=0.066925, train_rmse=0.259737\n",
      "[Train epoch 15/50] loss=0.055628, train_rmse=0.242655\n",
      "[Train epoch 20/50] loss=0.044353, train_rmse=0.226397\n",
      "[Train epoch 25/50] loss=0.039144, train_rmse=0.219765\n",
      "[Train epoch 30/50] loss=0.035525, train_rmse=0.216873\n",
      "[Train epoch 35/50] loss=0.032765, train_rmse=0.213148\n",
      "[Train epoch 40/50] loss=0.028469, train_rmse=0.206953\n",
      "[Train epoch 45/50] loss=0.025989, train_rmse=0.204384\n",
      "[Train epoch 50/50] loss=0.026799, train_rmse=0.204640\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1747987248841224\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 45 | labelled size = 470 | pool size = 59530 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.282135, train_rmse=0.304379\n",
      "[Train epoch 5/50] loss=0.080007, train_rmse=0.278811\n",
      "[Train epoch 10/50] loss=0.065860, train_rmse=0.254991\n",
      "[Train epoch 15/50] loss=0.053771, train_rmse=0.238908\n",
      "[Train epoch 20/50] loss=0.046774, train_rmse=0.225111\n",
      "[Train epoch 25/50] loss=0.041492, train_rmse=0.221032\n",
      "[Train epoch 30/50] loss=0.034864, train_rmse=0.214012\n",
      "[Train epoch 35/50] loss=0.029616, train_rmse=0.208282\n",
      "[Train epoch 40/50] loss=0.029661, train_rmse=0.208172\n",
      "[Train epoch 45/50] loss=0.026622, train_rmse=0.204755\n",
      "[Train epoch 50/50] loss=0.024220, train_rmse=0.203591\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17692723542855318\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 46 | labelled size = 480 | pool size = 59520 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.294916, train_rmse=0.307108\n",
      "[Train epoch 5/50] loss=0.077711, train_rmse=0.274491\n",
      "[Train epoch 10/50] loss=0.062338, train_rmse=0.247226\n",
      "[Train epoch 15/50] loss=0.051801, train_rmse=0.232448\n",
      "[Train epoch 20/50] loss=0.043529, train_rmse=0.220761\n",
      "[Train epoch 25/50] loss=0.037212, train_rmse=0.215572\n",
      "[Train epoch 30/50] loss=0.033941, train_rmse=0.212343\n",
      "[Train epoch 35/50] loss=0.031488, train_rmse=0.209999\n",
      "[Train epoch 40/50] loss=0.027929, train_rmse=0.206117\n",
      "[Train epoch 45/50] loss=0.024718, train_rmse=0.202536\n",
      "[Train epoch 50/50] loss=0.022932, train_rmse=0.198209\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.170975793611481\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 47 | labelled size = 490 | pool size = 59510 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.377806, train_rmse=0.311497\n",
      "[Train epoch 5/50] loss=0.081949, train_rmse=0.280385\n",
      "[Train epoch 10/50] loss=0.067666, train_rmse=0.260970\n",
      "[Train epoch 15/50] loss=0.056688, train_rmse=0.241214\n",
      "[Train epoch 20/50] loss=0.049668, train_rmse=0.234355\n",
      "[Train epoch 25/50] loss=0.040478, train_rmse=0.222470\n",
      "[Train epoch 30/50] loss=0.038837, train_rmse=0.215729\n",
      "[Train epoch 35/50] loss=0.034582, train_rmse=0.214138\n",
      "[Train epoch 40/50] loss=0.030656, train_rmse=0.210860\n",
      "[Train epoch 45/50] loss=0.027532, train_rmse=0.204736\n",
      "[Train epoch 50/50] loss=0.025291, train_rmse=0.203169\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1696752706234124\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 48 | labelled size = 500 | pool size = 59500 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.277041, train_rmse=0.304181\n",
      "[Train epoch 5/50] loss=0.075928, train_rmse=0.273554\n",
      "[Train epoch 10/50] loss=0.061198, train_rmse=0.249374\n",
      "[Train epoch 15/50] loss=0.053507, train_rmse=0.240009\n",
      "[Train epoch 20/50] loss=0.046230, train_rmse=0.225527\n",
      "[Train epoch 25/50] loss=0.037058, train_rmse=0.214209\n",
      "[Train epoch 30/50] loss=0.034214, train_rmse=0.212818\n",
      "[Train epoch 35/50] loss=0.028654, train_rmse=0.206561\n",
      "[Train epoch 40/50] loss=0.027688, train_rmse=0.205891\n",
      "[Train epoch 45/50] loss=0.024105, train_rmse=0.200557\n",
      "[Train epoch 50/50] loss=0.022470, train_rmse=0.200866\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17216018482253284\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 49 | labelled size = 510 | pool size = 59490 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.395617, train_rmse=0.310474\n",
      "[Train epoch 5/50] loss=0.082882, train_rmse=0.286548\n",
      "[Train epoch 10/50] loss=0.067454, train_rmse=0.261024\n",
      "[Train epoch 15/50] loss=0.057845, train_rmse=0.246132\n",
      "[Train epoch 20/50] loss=0.049033, train_rmse=0.233855\n",
      "[Train epoch 25/50] loss=0.043658, train_rmse=0.223877\n",
      "[Train epoch 30/50] loss=0.038426, train_rmse=0.218275\n",
      "[Train epoch 35/50] loss=0.034557, train_rmse=0.212795\n",
      "[Train epoch 40/50] loss=0.031980, train_rmse=0.210171\n",
      "[Train epoch 45/50] loss=0.026718, train_rmse=0.204521\n",
      "[Train epoch 50/50] loss=0.026859, train_rmse=0.204465\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.16578083418669043\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 50 | labelled size = 520 | pool size = 59480 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.259483, train_rmse=0.304432\n",
      "[Train epoch 5/50] loss=0.078871, train_rmse=0.276887\n",
      "[Train epoch 10/50] loss=0.065084, train_rmse=0.256039\n",
      "[Train epoch 15/50] loss=0.054451, train_rmse=0.240197\n",
      "[Train epoch 20/50] loss=0.047880, train_rmse=0.231797\n",
      "[Train epoch 25/50] loss=0.039295, train_rmse=0.221021\n",
      "[Train epoch 30/50] loss=0.035078, train_rmse=0.216645\n",
      "[Train epoch 35/50] loss=0.032531, train_rmse=0.207912\n",
      "[Train epoch 40/50] loss=0.032093, train_rmse=0.208231\n",
      "[Train epoch 45/50] loss=0.027916, train_rmse=0.203822\n",
      "[Train epoch 50/50] loss=0.025222, train_rmse=0.203011\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17663935327219743\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 51 | labelled size = 530 | pool size = 59470 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.300456, train_rmse=0.309373\n",
      "[Train epoch 5/50] loss=0.082496, train_rmse=0.284821\n",
      "[Train epoch 10/50] loss=0.066321, train_rmse=0.262618\n",
      "[Train epoch 15/50] loss=0.058010, train_rmse=0.243796\n",
      "[Train epoch 20/50] loss=0.050290, train_rmse=0.229547\n",
      "[Train epoch 25/50] loss=0.042612, train_rmse=0.223438\n",
      "[Train epoch 30/50] loss=0.036671, train_rmse=0.217703\n",
      "[Train epoch 35/50] loss=0.032360, train_rmse=0.210349\n",
      "[Train epoch 40/50] loss=0.029409, train_rmse=0.205748\n",
      "[Train epoch 45/50] loss=0.027169, train_rmse=0.202112\n",
      "[Train epoch 50/50] loss=0.026306, train_rmse=0.198074\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1712883412605856\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 52 | labelled size = 540 | pool size = 59460 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.290696, train_rmse=0.307633\n",
      "[Train epoch 5/50] loss=0.077189, train_rmse=0.275288\n",
      "[Train epoch 10/50] loss=0.061953, train_rmse=0.251528\n",
      "[Train epoch 15/50] loss=0.052739, train_rmse=0.236132\n",
      "[Train epoch 20/50] loss=0.045172, train_rmse=0.227867\n",
      "[Train epoch 25/50] loss=0.036742, train_rmse=0.217986\n",
      "[Train epoch 30/50] loss=0.035485, train_rmse=0.215618\n",
      "[Train epoch 35/50] loss=0.032626, train_rmse=0.210313\n",
      "[Train epoch 40/50] loss=0.027983, train_rmse=0.204040\n",
      "[Train epoch 45/50] loss=0.024264, train_rmse=0.202151\n",
      "[Train epoch 50/50] loss=0.022743, train_rmse=0.198586\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.18118545490543705\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 53 | labelled size = 550 | pool size = 59450 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.367186, train_rmse=0.313305\n",
      "[Train epoch 5/50] loss=0.082450, train_rmse=0.284831\n",
      "[Train epoch 10/50] loss=0.067751, train_rmse=0.261122\n",
      "[Train epoch 15/50] loss=0.058778, train_rmse=0.246923\n",
      "[Train epoch 20/50] loss=0.048998, train_rmse=0.234657\n",
      "[Train epoch 25/50] loss=0.042859, train_rmse=0.223667\n",
      "[Train epoch 30/50] loss=0.038499, train_rmse=0.219212\n",
      "[Train epoch 35/50] loss=0.034648, train_rmse=0.214623\n",
      "[Train epoch 40/50] loss=0.033455, train_rmse=0.211602\n",
      "[Train epoch 45/50] loss=0.028911, train_rmse=0.203169\n",
      "[Train epoch 50/50] loss=0.025044, train_rmse=0.199749\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17487816757703611\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 54 | labelled size = 560 | pool size = 59440 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.269092, train_rmse=0.305174\n",
      "[Train epoch 5/50] loss=0.077179, train_rmse=0.275727\n",
      "[Train epoch 10/50] loss=0.062042, train_rmse=0.249788\n",
      "[Train epoch 15/50] loss=0.051691, train_rmse=0.234288\n",
      "[Train epoch 20/50] loss=0.042335, train_rmse=0.223335\n",
      "[Train epoch 25/50] loss=0.036680, train_rmse=0.218558\n",
      "[Train epoch 30/50] loss=0.033852, train_rmse=0.213998\n",
      "[Train epoch 35/50] loss=0.027121, train_rmse=0.203793\n",
      "[Train epoch 40/50] loss=0.025612, train_rmse=0.204020\n",
      "[Train epoch 45/50] loss=0.023415, train_rmse=0.196320\n",
      "[Train epoch 50/50] loss=0.022018, train_rmse=0.196771\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17236807607751872\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 55 | labelled size = 570 | pool size = 59430 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.310213, train_rmse=0.305793\n",
      "[Train epoch 5/50] loss=0.075983, train_rmse=0.270273\n",
      "[Train epoch 10/50] loss=0.059032, train_rmse=0.248330\n",
      "[Train epoch 15/50] loss=0.051657, train_rmse=0.235974\n",
      "[Train epoch 20/50] loss=0.043091, train_rmse=0.222806\n",
      "[Train epoch 25/50] loss=0.037956, train_rmse=0.216643\n",
      "[Train epoch 30/50] loss=0.030739, train_rmse=0.208582\n",
      "[Train epoch 35/50] loss=0.027363, train_rmse=0.202561\n",
      "[Train epoch 40/50] loss=0.027202, train_rmse=0.198022\n",
      "[Train epoch 45/50] loss=0.021867, train_rmse=0.198034\n",
      "[Train epoch 50/50] loss=0.021397, train_rmse=0.194492\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17874703047359858\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 56 | labelled size = 580 | pool size = 59420 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.261190, train_rmse=0.304571\n",
      "[Train epoch 5/50] loss=0.078294, train_rmse=0.279535\n",
      "[Train epoch 10/50] loss=0.062304, train_rmse=0.251135\n",
      "[Train epoch 15/50] loss=0.052092, train_rmse=0.234916\n",
      "[Train epoch 20/50] loss=0.045786, train_rmse=0.227000\n",
      "[Train epoch 25/50] loss=0.041110, train_rmse=0.219582\n",
      "[Train epoch 30/50] loss=0.037390, train_rmse=0.215683\n",
      "[Train epoch 35/50] loss=0.034383, train_rmse=0.214558\n",
      "[Train epoch 40/50] loss=0.032236, train_rmse=0.205283\n",
      "[Train epoch 45/50] loss=0.027506, train_rmse=0.201390\n",
      "[Train epoch 50/50] loss=0.025270, train_rmse=0.196671\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.17673055362153434\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 57 | labelled size = 590 | pool size = 59410 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.259997, train_rmse=0.304914\n",
      "[Train epoch 5/50] loss=0.076893, train_rmse=0.274141\n",
      "[Train epoch 10/50] loss=0.061966, train_rmse=0.249868\n",
      "[Train epoch 15/50] loss=0.051536, train_rmse=0.233357\n",
      "[Train epoch 20/50] loss=0.044134, train_rmse=0.220490\n",
      "[Train epoch 25/50] loss=0.038279, train_rmse=0.213931\n",
      "[Train epoch 30/50] loss=0.034507, train_rmse=0.207047\n",
      "[Train epoch 35/50] loss=0.030056, train_rmse=0.203471\n",
      "[Train epoch 40/50] loss=0.025009, train_rmse=0.198471\n",
      "[Train epoch 45/50] loss=0.023799, train_rmse=0.196225\n",
      "[Train epoch 50/50] loss=0.022143, train_rmse=0.196724\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.166350331140618\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 58 | labelled size = 600 | pool size = 59400 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.235319, train_rmse=0.303731\n",
      "[Train epoch 5/50] loss=0.073488, train_rmse=0.269093\n",
      "[Train epoch 10/50] loss=0.057210, train_rmse=0.244804\n",
      "[Train epoch 15/50] loss=0.046352, train_rmse=0.225064\n",
      "[Train epoch 20/50] loss=0.039420, train_rmse=0.216361\n",
      "[Train epoch 25/50] loss=0.033435, train_rmse=0.208682\n",
      "[Train epoch 30/50] loss=0.030427, train_rmse=0.201245\n",
      "[Train epoch 35/50] loss=0.025488, train_rmse=0.199861\n",
      "[Train epoch 40/50] loss=0.023344, train_rmse=0.196056\n",
      "[Train epoch 45/50] loss=0.021713, train_rmse=0.190600\n",
      "[Train epoch 50/50] loss=0.022679, train_rmse=0.191494\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.16590690830090768\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 59 | labelled size = 610 | pool size = 59390 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.231301, train_rmse=0.304552\n",
      "[Train epoch 5/50] loss=0.076272, train_rmse=0.270127\n",
      "[Train epoch 10/50] loss=0.059046, train_rmse=0.241364\n",
      "[Train epoch 15/50] loss=0.049730, train_rmse=0.227089\n",
      "[Train epoch 20/50] loss=0.041248, train_rmse=0.218827\n",
      "[Train epoch 25/50] loss=0.033602, train_rmse=0.208424\n",
      "[Train epoch 30/50] loss=0.031001, train_rmse=0.201856\n",
      "[Train epoch 35/50] loss=0.026971, train_rmse=0.197091\n",
      "[Train epoch 40/50] loss=0.022358, train_rmse=0.190999\n",
      "[Train epoch 45/50] loss=0.022387, train_rmse=0.191545\n",
      "[Train epoch 50/50] loss=0.020196, train_rmse=0.185973\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15868585419975173\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 60 | labelled size = 620 | pool size = 59380 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.213343, train_rmse=0.302306\n",
      "[Train epoch 5/50] loss=0.075191, train_rmse=0.270539\n",
      "[Train epoch 10/50] loss=0.061089, train_rmse=0.239801\n",
      "[Train epoch 15/50] loss=0.049271, train_rmse=0.226559\n",
      "[Train epoch 20/50] loss=0.038766, train_rmse=0.208255\n",
      "[Train epoch 25/50] loss=0.034808, train_rmse=0.205415\n",
      "[Train epoch 30/50] loss=0.031024, train_rmse=0.196320\n",
      "[Train epoch 35/50] loss=0.028367, train_rmse=0.191470\n",
      "[Train epoch 40/50] loss=0.024273, train_rmse=0.186060\n",
      "[Train epoch 45/50] loss=0.022115, train_rmse=0.184245\n",
      "[Train epoch 50/50] loss=0.020960, train_rmse=0.181014\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15730000106086414\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 61 | labelled size = 630 | pool size = 59370 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.228291, train_rmse=0.305589\n",
      "[Train epoch 5/50] loss=0.076911, train_rmse=0.272194\n",
      "[Train epoch 10/50] loss=0.062270, train_rmse=0.246715\n",
      "[Train epoch 15/50] loss=0.052435, train_rmse=0.227207\n",
      "[Train epoch 20/50] loss=0.042126, train_rmse=0.215257\n",
      "[Train epoch 25/50] loss=0.037032, train_rmse=0.202815\n",
      "[Train epoch 30/50] loss=0.031517, train_rmse=0.196098\n",
      "[Train epoch 35/50] loss=0.028030, train_rmse=0.189458\n",
      "[Train epoch 40/50] loss=0.026387, train_rmse=0.179230\n",
      "[Train epoch 45/50] loss=0.022477, train_rmse=0.174334\n",
      "[Train epoch 50/50] loss=0.019793, train_rmse=0.174110\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15496063985524347\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 62 | labelled size = 640 | pool size = 59360 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.238538, train_rmse=0.302268\n",
      "[Train epoch 5/50] loss=0.074738, train_rmse=0.268227\n",
      "[Train epoch 10/50] loss=0.058934, train_rmse=0.241965\n",
      "[Train epoch 15/50] loss=0.046651, train_rmse=0.220405\n",
      "[Train epoch 20/50] loss=0.040013, train_rmse=0.206005\n",
      "[Train epoch 25/50] loss=0.034150, train_rmse=0.198199\n",
      "[Train epoch 30/50] loss=0.030430, train_rmse=0.192754\n",
      "[Train epoch 35/50] loss=0.026920, train_rmse=0.187936\n",
      "[Train epoch 40/50] loss=0.023851, train_rmse=0.181334\n",
      "[Train epoch 45/50] loss=0.021945, train_rmse=0.178248\n",
      "[Train epoch 50/50] loss=0.021310, train_rmse=0.174774\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1553830048546815\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 63 | labelled size = 650 | pool size = 59350 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.208243, train_rmse=0.300061\n",
      "[Train epoch 5/50] loss=0.071762, train_rmse=0.263646\n",
      "[Train epoch 10/50] loss=0.054026, train_rmse=0.233230\n",
      "[Train epoch 15/50] loss=0.045075, train_rmse=0.213657\n",
      "[Train epoch 20/50] loss=0.036400, train_rmse=0.204052\n",
      "[Train epoch 25/50] loss=0.032816, train_rmse=0.198501\n",
      "[Train epoch 30/50] loss=0.030194, train_rmse=0.197218\n",
      "[Train epoch 35/50] loss=0.028009, train_rmse=0.191680\n",
      "[Train epoch 40/50] loss=0.024983, train_rmse=0.184427\n",
      "[Train epoch 45/50] loss=0.024611, train_rmse=0.180747\n",
      "[Train epoch 50/50] loss=0.021610, train_rmse=0.176708\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1522161054262049\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 64 | labelled size = 660 | pool size = 59340 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.197576, train_rmse=0.294069\n",
      "[Train epoch 5/50] loss=0.071927, train_rmse=0.260115\n",
      "[Train epoch 10/50] loss=0.051762, train_rmse=0.228081\n",
      "[Train epoch 15/50] loss=0.040294, train_rmse=0.210609\n",
      "[Train epoch 20/50] loss=0.034572, train_rmse=0.197862\n",
      "[Train epoch 25/50] loss=0.030422, train_rmse=0.188910\n",
      "[Train epoch 30/50] loss=0.025646, train_rmse=0.180424\n",
      "[Train epoch 35/50] loss=0.023923, train_rmse=0.173279\n",
      "[Train epoch 40/50] loss=0.021842, train_rmse=0.168266\n",
      "[Train epoch 45/50] loss=0.020381, train_rmse=0.171789\n",
      "[Train epoch 50/50] loss=0.018482, train_rmse=0.165772\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14922768098158282\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 65 | labelled size = 670 | pool size = 59330 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.220253, train_rmse=0.301765\n",
      "[Train epoch 5/50] loss=0.076321, train_rmse=0.271333\n",
      "[Train epoch 10/50] loss=0.060046, train_rmse=0.240136\n",
      "[Train epoch 15/50] loss=0.048398, train_rmse=0.224914\n",
      "[Train epoch 20/50] loss=0.041683, train_rmse=0.211153\n",
      "[Train epoch 25/50] loss=0.034941, train_rmse=0.197876\n",
      "[Train epoch 30/50] loss=0.030061, train_rmse=0.190527\n",
      "[Train epoch 35/50] loss=0.027496, train_rmse=0.178933\n",
      "[Train epoch 40/50] loss=0.024436, train_rmse=0.176489\n",
      "[Train epoch 45/50] loss=0.022821, train_rmse=0.167429\n",
      "[Train epoch 50/50] loss=0.019772, train_rmse=0.166746\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14832249950999762\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 66 | labelled size = 680 | pool size = 59320 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.263689, train_rmse=0.301548\n",
      "[Train epoch 5/50] loss=0.074236, train_rmse=0.267249\n",
      "[Train epoch 10/50] loss=0.059731, train_rmse=0.236688\n",
      "[Train epoch 15/50] loss=0.047146, train_rmse=0.221482\n",
      "[Train epoch 20/50] loss=0.040441, train_rmse=0.204460\n",
      "[Train epoch 25/50] loss=0.033005, train_rmse=0.197305\n",
      "[Train epoch 30/50] loss=0.029234, train_rmse=0.184872\n",
      "[Train epoch 35/50] loss=0.024503, train_rmse=0.174807\n",
      "[Train epoch 40/50] loss=0.023484, train_rmse=0.170976\n",
      "[Train epoch 45/50] loss=0.021007, train_rmse=0.172588\n",
      "[Train epoch 50/50] loss=0.019409, train_rmse=0.161715\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.15034195799662525\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 67 | labelled size = 690 | pool size = 59310 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.271600, train_rmse=0.305610\n",
      "[Train epoch 5/50] loss=0.075954, train_rmse=0.267171\n",
      "[Train epoch 10/50] loss=0.060230, train_rmse=0.236915\n",
      "[Train epoch 15/50] loss=0.048780, train_rmse=0.219021\n",
      "[Train epoch 20/50] loss=0.041329, train_rmse=0.208207\n",
      "[Train epoch 25/50] loss=0.034980, train_rmse=0.195470\n",
      "[Train epoch 30/50] loss=0.029808, train_rmse=0.189623\n",
      "[Train epoch 35/50] loss=0.027454, train_rmse=0.180969\n",
      "[Train epoch 40/50] loss=0.023490, train_rmse=0.171262\n",
      "[Train epoch 45/50] loss=0.023416, train_rmse=0.176470\n",
      "[Train epoch 50/50] loss=0.020011, train_rmse=0.169491\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1508147586648631\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 68 | labelled size = 700 | pool size = 59300 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.379084, train_rmse=0.310519\n",
      "[Train epoch 5/50] loss=0.080846, train_rmse=0.280385\n",
      "[Train epoch 10/50] loss=0.065032, train_rmse=0.250527\n",
      "[Train epoch 15/50] loss=0.054377, train_rmse=0.229131\n",
      "[Train epoch 20/50] loss=0.047723, train_rmse=0.219943\n",
      "[Train epoch 25/50] loss=0.043301, train_rmse=0.213296\n",
      "[Train epoch 30/50] loss=0.038032, train_rmse=0.205950\n",
      "[Train epoch 35/50] loss=0.033386, train_rmse=0.196349\n",
      "[Train epoch 40/50] loss=0.030538, train_rmse=0.189403\n",
      "[Train epoch 45/50] loss=0.028326, train_rmse=0.178147\n",
      "[Train epoch 50/50] loss=0.025899, train_rmse=0.176370\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14782912798336553\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 69 | labelled size = 710 | pool size = 59290 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.327484, train_rmse=0.304956\n",
      "[Train epoch 5/50] loss=0.080089, train_rmse=0.272835\n",
      "[Train epoch 10/50] loss=0.064548, train_rmse=0.248476\n",
      "[Train epoch 15/50] loss=0.056180, train_rmse=0.234219\n",
      "[Train epoch 20/50] loss=0.048335, train_rmse=0.221525\n",
      "[Train epoch 25/50] loss=0.041546, train_rmse=0.210333\n",
      "[Train epoch 30/50] loss=0.037581, train_rmse=0.200486\n",
      "[Train epoch 35/50] loss=0.036103, train_rmse=0.194726\n",
      "[Train epoch 40/50] loss=0.033023, train_rmse=0.189065\n",
      "[Train epoch 45/50] loss=0.029983, train_rmse=0.186043\n",
      "[Train epoch 50/50] loss=0.027295, train_rmse=0.176797\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14781682728729886\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 70 | labelled size = 720 | pool size = 59280 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.215704, train_rmse=0.301325\n",
      "[Train epoch 5/50] loss=0.075740, train_rmse=0.267724\n",
      "[Train epoch 10/50] loss=0.057035, train_rmse=0.230846\n",
      "[Train epoch 15/50] loss=0.046399, train_rmse=0.215158\n",
      "[Train epoch 20/50] loss=0.038864, train_rmse=0.200468\n",
      "[Train epoch 25/50] loss=0.032601, train_rmse=0.191359\n",
      "[Train epoch 30/50] loss=0.030559, train_rmse=0.184051\n",
      "[Train epoch 35/50] loss=0.027739, train_rmse=0.179569\n",
      "[Train epoch 40/50] loss=0.025279, train_rmse=0.173804\n",
      "[Train epoch 45/50] loss=0.022621, train_rmse=0.173156\n",
      "[Train epoch 50/50] loss=0.022491, train_rmse=0.174000\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14674034245766013\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 71 | labelled size = 730 | pool size = 59270 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.268577, train_rmse=0.308878\n",
      "[Train epoch 5/50] loss=0.079950, train_rmse=0.273109\n",
      "[Train epoch 10/50] loss=0.064828, train_rmse=0.241749\n",
      "[Train epoch 15/50] loss=0.052173, train_rmse=0.216567\n",
      "[Train epoch 20/50] loss=0.044919, train_rmse=0.203001\n",
      "[Train epoch 25/50] loss=0.038312, train_rmse=0.193371\n",
      "[Train epoch 30/50] loss=0.033142, train_rmse=0.179088\n",
      "[Train epoch 35/50] loss=0.029247, train_rmse=0.177789\n",
      "[Train epoch 40/50] loss=0.028521, train_rmse=0.171780\n",
      "[Train epoch 45/50] loss=0.025527, train_rmse=0.166178\n",
      "[Train epoch 50/50] loss=0.023389, train_rmse=0.168327\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14675933809479955\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 72 | labelled size = 740 | pool size = 59260 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.334249, train_rmse=0.308445\n",
      "[Train epoch 5/50] loss=0.083169, train_rmse=0.280562\n",
      "[Train epoch 10/50] loss=0.069395, train_rmse=0.250883\n",
      "[Train epoch 15/50] loss=0.056809, train_rmse=0.227431\n",
      "[Train epoch 20/50] loss=0.049309, train_rmse=0.211409\n",
      "[Train epoch 25/50] loss=0.043542, train_rmse=0.203567\n",
      "[Train epoch 30/50] loss=0.038928, train_rmse=0.190469\n",
      "[Train epoch 35/50] loss=0.034262, train_rmse=0.182623\n",
      "[Train epoch 40/50] loss=0.029115, train_rmse=0.173084\n",
      "[Train epoch 45/50] loss=0.025485, train_rmse=0.166246\n",
      "[Train epoch 50/50] loss=0.025004, train_rmse=0.165991\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14815696904093037\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 73 | labelled size = 750 | pool size = 59250 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.249611, train_rmse=0.303919\n",
      "[Train epoch 5/50] loss=0.079157, train_rmse=0.276132\n",
      "[Train epoch 10/50] loss=0.062001, train_rmse=0.240515\n",
      "[Train epoch 15/50] loss=0.051864, train_rmse=0.218624\n",
      "[Train epoch 20/50] loss=0.043585, train_rmse=0.203550\n",
      "[Train epoch 25/50] loss=0.035712, train_rmse=0.188331\n",
      "[Train epoch 30/50] loss=0.031026, train_rmse=0.178959\n",
      "[Train epoch 35/50] loss=0.028969, train_rmse=0.171827\n",
      "[Train epoch 40/50] loss=0.027532, train_rmse=0.166831\n",
      "[Train epoch 45/50] loss=0.022783, train_rmse=0.163827\n",
      "[Train epoch 50/50] loss=0.022103, train_rmse=0.157515\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14214645048903266\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 74 | labelled size = 760 | pool size = 59240 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.258132, train_rmse=0.306591\n",
      "[Train epoch 5/50] loss=0.080513, train_rmse=0.277100\n",
      "[Train epoch 10/50] loss=0.065464, train_rmse=0.245406\n",
      "[Train epoch 15/50] loss=0.053581, train_rmse=0.223602\n",
      "[Train epoch 20/50] loss=0.046314, train_rmse=0.207620\n",
      "[Train epoch 25/50] loss=0.039867, train_rmse=0.191906\n",
      "[Train epoch 30/50] loss=0.034856, train_rmse=0.184360\n",
      "[Train epoch 35/50] loss=0.030259, train_rmse=0.174019\n",
      "[Train epoch 40/50] loss=0.027189, train_rmse=0.165018\n",
      "[Train epoch 45/50] loss=0.025161, train_rmse=0.159120\n",
      "[Train epoch 50/50] loss=0.022670, train_rmse=0.167418\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14581468728980207\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 75 | labelled size = 770 | pool size = 59230 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.193417, train_rmse=0.299650\n",
      "[Train epoch 5/50] loss=0.074036, train_rmse=0.256643\n",
      "[Train epoch 10/50] loss=0.059529, train_rmse=0.227086\n",
      "[Train epoch 15/50] loss=0.046771, train_rmse=0.203358\n",
      "[Train epoch 20/50] loss=0.042711, train_rmse=0.188309\n",
      "[Train epoch 25/50] loss=0.037128, train_rmse=0.184097\n",
      "[Train epoch 30/50] loss=0.033160, train_rmse=0.181601\n",
      "[Train epoch 35/50] loss=0.033645, train_rmse=0.187762\n",
      "[Train epoch 40/50] loss=0.031138, train_rmse=0.176535\n",
      "[Train epoch 45/50] loss=0.030749, train_rmse=0.168707\n",
      "[Train epoch 50/50] loss=0.028393, train_rmse=0.170102\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14503030839222714\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 76 | labelled size = 780 | pool size = 59220 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.284071, train_rmse=0.305919\n",
      "[Train epoch 5/50] loss=0.083132, train_rmse=0.279095\n",
      "[Train epoch 10/50] loss=0.070890, train_rmse=0.253866\n",
      "[Train epoch 15/50] loss=0.059190, train_rmse=0.231489\n",
      "[Train epoch 20/50] loss=0.049231, train_rmse=0.217688\n",
      "[Train epoch 25/50] loss=0.044078, train_rmse=0.198875\n",
      "[Train epoch 30/50] loss=0.036987, train_rmse=0.187901\n",
      "[Train epoch 35/50] loss=0.032918, train_rmse=0.173553\n",
      "[Train epoch 40/50] loss=0.032290, train_rmse=0.174268\n",
      "[Train epoch 45/50] loss=0.027661, train_rmse=0.166696\n",
      "[Train epoch 50/50] loss=0.026622, train_rmse=0.162037\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14605224751803628\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 77 | labelled size = 790 | pool size = 59210 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.238371, train_rmse=0.300715\n",
      "[Train epoch 5/50] loss=0.074692, train_rmse=0.258998\n",
      "[Train epoch 10/50] loss=0.058544, train_rmse=0.224326\n",
      "[Train epoch 15/50] loss=0.047969, train_rmse=0.200777\n",
      "[Train epoch 20/50] loss=0.037886, train_rmse=0.182636\n",
      "[Train epoch 25/50] loss=0.032704, train_rmse=0.175039\n",
      "[Train epoch 30/50] loss=0.030001, train_rmse=0.168658\n",
      "[Train epoch 35/50] loss=0.025756, train_rmse=0.165040\n",
      "[Train epoch 40/50] loss=0.023053, train_rmse=0.156239\n",
      "[Train epoch 45/50] loss=0.022178, train_rmse=0.165010\n",
      "[Train epoch 50/50] loss=0.022090, train_rmse=0.161539\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14378611074587486\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 78 | labelled size = 800 | pool size = 59200 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.277234, train_rmse=0.308538\n",
      "[Train epoch 5/50] loss=0.081281, train_rmse=0.274553\n",
      "[Train epoch 10/50] loss=0.066323, train_rmse=0.243342\n",
      "[Train epoch 15/50] loss=0.057739, train_rmse=0.221767\n",
      "[Train epoch 20/50] loss=0.049117, train_rmse=0.206659\n",
      "[Train epoch 25/50] loss=0.043070, train_rmse=0.193274\n",
      "[Train epoch 30/50] loss=0.037068, train_rmse=0.181270\n",
      "[Train epoch 35/50] loss=0.033131, train_rmse=0.173921\n",
      "[Train epoch 40/50] loss=0.026687, train_rmse=0.165189\n",
      "[Train epoch 45/50] loss=0.025159, train_rmse=0.165040\n",
      "[Train epoch 50/50] loss=0.025728, train_rmse=0.162538\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14007931295934725\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 79 | labelled size = 810 | pool size = 59190 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.180794, train_rmse=0.297285\n",
      "[Train epoch 5/50] loss=0.071325, train_rmse=0.250198\n",
      "[Train epoch 10/50] loss=0.050154, train_rmse=0.207586\n",
      "[Train epoch 15/50] loss=0.040190, train_rmse=0.187130\n",
      "[Train epoch 20/50] loss=0.033081, train_rmse=0.177801\n",
      "[Train epoch 25/50] loss=0.026951, train_rmse=0.164772\n",
      "[Train epoch 30/50] loss=0.024753, train_rmse=0.165976\n",
      "[Train epoch 35/50] loss=0.022928, train_rmse=0.159079\n",
      "[Train epoch 40/50] loss=0.019381, train_rmse=0.154512\n",
      "[Train epoch 45/50] loss=0.019036, train_rmse=0.155187\n",
      "[Train epoch 50/50] loss=0.018795, train_rmse=0.155094\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14027952045369585\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 80 | labelled size = 820 | pool size = 59180 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.216669, train_rmse=0.298950\n",
      "[Train epoch 5/50] loss=0.074982, train_rmse=0.258785\n",
      "[Train epoch 10/50] loss=0.058131, train_rmse=0.222530\n",
      "[Train epoch 15/50] loss=0.046037, train_rmse=0.199428\n",
      "[Train epoch 20/50] loss=0.036779, train_rmse=0.183068\n",
      "[Train epoch 25/50] loss=0.031687, train_rmse=0.178041\n",
      "[Train epoch 30/50] loss=0.029068, train_rmse=0.162263\n",
      "[Train epoch 35/50] loss=0.024647, train_rmse=0.157643\n",
      "[Train epoch 40/50] loss=0.023335, train_rmse=0.153827\n",
      "[Train epoch 45/50] loss=0.021074, train_rmse=0.154621\n",
      "[Train epoch 50/50] loss=0.020139, train_rmse=0.156330\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14096390095435987\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 81 | labelled size = 830 | pool size = 59170 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.276089, train_rmse=0.303408\n",
      "[Train epoch 5/50] loss=0.080040, train_rmse=0.274916\n",
      "[Train epoch 10/50] loss=0.065191, train_rmse=0.236059\n",
      "[Train epoch 15/50] loss=0.052454, train_rmse=0.211048\n",
      "[Train epoch 20/50] loss=0.043407, train_rmse=0.194226\n",
      "[Train epoch 25/50] loss=0.037665, train_rmse=0.184976\n",
      "[Train epoch 30/50] loss=0.031783, train_rmse=0.173932\n",
      "[Train epoch 35/50] loss=0.029409, train_rmse=0.171384\n",
      "[Train epoch 40/50] loss=0.025690, train_rmse=0.158815\n",
      "[Train epoch 45/50] loss=0.024319, train_rmse=0.163639\n",
      "[Train epoch 50/50] loss=0.021438, train_rmse=0.154991\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1412026804766845\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 82 | labelled size = 840 | pool size = 59160 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.277000, train_rmse=0.303428\n",
      "[Train epoch 5/50] loss=0.081343, train_rmse=0.276531\n",
      "[Train epoch 10/50] loss=0.068262, train_rmse=0.244933\n",
      "[Train epoch 15/50] loss=0.055594, train_rmse=0.218650\n",
      "[Train epoch 20/50] loss=0.047007, train_rmse=0.203116\n",
      "[Train epoch 25/50] loss=0.042323, train_rmse=0.192945\n",
      "[Train epoch 30/50] loss=0.035510, train_rmse=0.184855\n",
      "[Train epoch 35/50] loss=0.033364, train_rmse=0.177510\n",
      "[Train epoch 40/50] loss=0.030412, train_rmse=0.169384\n",
      "[Train epoch 45/50] loss=0.027938, train_rmse=0.167006\n",
      "[Train epoch 50/50] loss=0.027819, train_rmse=0.166582\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14375984659886495\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 83 | labelled size = 850 | pool size = 59150 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.259043, train_rmse=0.303203\n",
      "[Train epoch 5/50] loss=0.080496, train_rmse=0.273388\n",
      "[Train epoch 10/50] loss=0.066093, train_rmse=0.240631\n",
      "[Train epoch 15/50] loss=0.052251, train_rmse=0.216471\n",
      "[Train epoch 20/50] loss=0.043486, train_rmse=0.196882\n",
      "[Train epoch 25/50] loss=0.039247, train_rmse=0.182633\n",
      "[Train epoch 30/50] loss=0.031604, train_rmse=0.179816\n",
      "[Train epoch 35/50] loss=0.029120, train_rmse=0.171351\n",
      "[Train epoch 40/50] loss=0.026446, train_rmse=0.162070\n",
      "[Train epoch 45/50] loss=0.024028, train_rmse=0.162652\n",
      "[Train epoch 50/50] loss=0.021698, train_rmse=0.156258\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1404634109008562\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 84 | labelled size = 860 | pool size = 59140 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.220050, train_rmse=0.297754\n",
      "[Train epoch 5/50] loss=0.076015, train_rmse=0.266278\n",
      "[Train epoch 10/50] loss=0.062816, train_rmse=0.233277\n",
      "[Train epoch 15/50] loss=0.050422, train_rmse=0.206399\n",
      "[Train epoch 20/50] loss=0.041345, train_rmse=0.188528\n",
      "[Train epoch 25/50] loss=0.036390, train_rmse=0.177844\n",
      "[Train epoch 30/50] loss=0.031482, train_rmse=0.178240\n",
      "[Train epoch 35/50] loss=0.028384, train_rmse=0.171312\n",
      "[Train epoch 40/50] loss=0.027150, train_rmse=0.166907\n",
      "[Train epoch 45/50] loss=0.024251, train_rmse=0.165062\n",
      "[Train epoch 50/50] loss=0.022064, train_rmse=0.158268\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13975193212057252\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 85 | labelled size = 870 | pool size = 59130 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.260070, train_rmse=0.300981\n",
      "[Train epoch 5/50] loss=0.079211, train_rmse=0.269833\n",
      "[Train epoch 10/50] loss=0.064244, train_rmse=0.238541\n",
      "[Train epoch 15/50] loss=0.054478, train_rmse=0.211557\n",
      "[Train epoch 20/50] loss=0.044634, train_rmse=0.193224\n",
      "[Train epoch 25/50] loss=0.036531, train_rmse=0.180708\n",
      "[Train epoch 30/50] loss=0.032852, train_rmse=0.179288\n",
      "[Train epoch 35/50] loss=0.028360, train_rmse=0.170293\n",
      "[Train epoch 40/50] loss=0.027564, train_rmse=0.164729\n",
      "[Train epoch 45/50] loss=0.025614, train_rmse=0.162632\n",
      "[Train epoch 50/50] loss=0.023396, train_rmse=0.158329\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13960235804346546\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 86 | labelled size = 880 | pool size = 59120 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.280180, train_rmse=0.304122\n",
      "[Train epoch 5/50] loss=0.079493, train_rmse=0.269030\n",
      "[Train epoch 10/50] loss=0.063840, train_rmse=0.236899\n",
      "[Train epoch 15/50] loss=0.051724, train_rmse=0.212344\n",
      "[Train epoch 20/50] loss=0.044274, train_rmse=0.194195\n",
      "[Train epoch 25/50] loss=0.039059, train_rmse=0.186981\n",
      "[Train epoch 30/50] loss=0.030851, train_rmse=0.173027\n",
      "[Train epoch 35/50] loss=0.030177, train_rmse=0.165900\n",
      "[Train epoch 40/50] loss=0.026553, train_rmse=0.163911\n",
      "[Train epoch 45/50] loss=0.025670, train_rmse=0.164306\n",
      "[Train epoch 50/50] loss=0.022761, train_rmse=0.157271\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1397467842175629\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 87 | labelled size = 890 | pool size = 59110 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.228631, train_rmse=0.301069\n",
      "[Train epoch 5/50] loss=0.076121, train_rmse=0.264569\n",
      "[Train epoch 10/50] loss=0.057658, train_rmse=0.224018\n",
      "[Train epoch 15/50] loss=0.045343, train_rmse=0.193149\n",
      "[Train epoch 20/50] loss=0.037999, train_rmse=0.176425\n",
      "[Train epoch 25/50] loss=0.032959, train_rmse=0.168253\n",
      "[Train epoch 30/50] loss=0.028307, train_rmse=0.164451\n",
      "[Train epoch 35/50] loss=0.025133, train_rmse=0.158614\n",
      "[Train epoch 40/50] loss=0.022343, train_rmse=0.164474\n",
      "[Train epoch 45/50] loss=0.021084, train_rmse=0.155050\n",
      "[Train epoch 50/50] loss=0.019517, train_rmse=0.152256\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13820088567477568\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 88 | labelled size = 900 | pool size = 59100 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.221546, train_rmse=0.298533\n",
      "[Train epoch 5/50] loss=0.074911, train_rmse=0.259797\n",
      "[Train epoch 10/50] loss=0.059764, train_rmse=0.225408\n",
      "[Train epoch 15/50] loss=0.049420, train_rmse=0.204652\n",
      "[Train epoch 20/50] loss=0.039765, train_rmse=0.190145\n",
      "[Train epoch 25/50] loss=0.036986, train_rmse=0.179672\n",
      "[Train epoch 30/50] loss=0.033508, train_rmse=0.173404\n",
      "[Train epoch 35/50] loss=0.028367, train_rmse=0.168942\n",
      "[Train epoch 40/50] loss=0.027912, train_rmse=0.164569\n",
      "[Train epoch 45/50] loss=0.024663, train_rmse=0.166803\n",
      "[Train epoch 50/50] loss=0.025962, train_rmse=0.159594\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14110639554763182\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 89 | labelled size = 910 | pool size = 59090 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.188175, train_rmse=0.297027\n",
      "[Train epoch 5/50] loss=0.073636, train_rmse=0.258960\n",
      "[Train epoch 10/50] loss=0.056281, train_rmse=0.217424\n",
      "[Train epoch 15/50] loss=0.044072, train_rmse=0.198727\n",
      "[Train epoch 20/50] loss=0.036906, train_rmse=0.178446\n",
      "[Train epoch 25/50] loss=0.031682, train_rmse=0.172561\n",
      "[Train epoch 30/50] loss=0.028144, train_rmse=0.175844\n",
      "[Train epoch 35/50] loss=0.025859, train_rmse=0.163810\n",
      "[Train epoch 40/50] loss=0.023447, train_rmse=0.161561\n",
      "[Train epoch 45/50] loss=0.022395, train_rmse=0.154782\n",
      "[Train epoch 50/50] loss=0.020672, train_rmse=0.154750\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13868009081935467\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 90 | labelled size = 920 | pool size = 59080 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.218777, train_rmse=0.301003\n",
      "[Train epoch 5/50] loss=0.074293, train_rmse=0.257443\n",
      "[Train epoch 10/50] loss=0.056165, train_rmse=0.216299\n",
      "[Train epoch 15/50] loss=0.044178, train_rmse=0.189769\n",
      "[Train epoch 20/50] loss=0.036945, train_rmse=0.180171\n",
      "[Train epoch 25/50] loss=0.031473, train_rmse=0.170495\n",
      "[Train epoch 30/50] loss=0.027967, train_rmse=0.171493\n",
      "[Train epoch 35/50] loss=0.025713, train_rmse=0.157979\n",
      "[Train epoch 40/50] loss=0.022957, train_rmse=0.154855\n",
      "[Train epoch 45/50] loss=0.021007, train_rmse=0.155280\n",
      "[Train epoch 50/50] loss=0.022022, train_rmse=0.150232\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13976344279701458\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 91 | labelled size = 930 | pool size = 59070 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.210556, train_rmse=0.298269\n",
      "[Train epoch 5/50] loss=0.071879, train_rmse=0.251874\n",
      "[Train epoch 10/50] loss=0.055307, train_rmse=0.215124\n",
      "[Train epoch 15/50] loss=0.042921, train_rmse=0.188434\n",
      "[Train epoch 20/50] loss=0.035546, train_rmse=0.177210\n",
      "[Train epoch 25/50] loss=0.031496, train_rmse=0.171263\n",
      "[Train epoch 30/50] loss=0.026105, train_rmse=0.165111\n",
      "[Train epoch 35/50] loss=0.023379, train_rmse=0.157776\n",
      "[Train epoch 40/50] loss=0.022774, train_rmse=0.152209\n",
      "[Train epoch 45/50] loss=0.021534, train_rmse=0.155570\n",
      "[Train epoch 50/50] loss=0.019223, train_rmse=0.150160\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13817023581274804\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 92 | labelled size = 940 | pool size = 59060 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.219311, train_rmse=0.301159\n",
      "[Train epoch 5/50] loss=0.074400, train_rmse=0.261903\n",
      "[Train epoch 10/50] loss=0.056778, train_rmse=0.216971\n",
      "[Train epoch 15/50] loss=0.043748, train_rmse=0.190770\n",
      "[Train epoch 20/50] loss=0.038058, train_rmse=0.176293\n",
      "[Train epoch 25/50] loss=0.031617, train_rmse=0.172717\n",
      "[Train epoch 30/50] loss=0.028157, train_rmse=0.162400\n",
      "[Train epoch 35/50] loss=0.022818, train_rmse=0.156790\n",
      "[Train epoch 40/50] loss=0.022272, train_rmse=0.160936\n",
      "[Train epoch 45/50] loss=0.020113, train_rmse=0.158442\n",
      "[Train epoch 50/50] loss=0.019846, train_rmse=0.156101\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13725070720761395\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 93 | labelled size = 950 | pool size = 59050 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.221421, train_rmse=0.302155\n",
      "[Train epoch 5/50] loss=0.071719, train_rmse=0.250826\n",
      "[Train epoch 10/50] loss=0.053075, train_rmse=0.212042\n",
      "[Train epoch 15/50] loss=0.042152, train_rmse=0.184701\n",
      "[Train epoch 20/50] loss=0.034845, train_rmse=0.179549\n",
      "[Train epoch 25/50] loss=0.030544, train_rmse=0.167552\n",
      "[Train epoch 30/50] loss=0.026407, train_rmse=0.163359\n",
      "[Train epoch 35/50] loss=0.024107, train_rmse=0.152566\n",
      "[Train epoch 40/50] loss=0.022997, train_rmse=0.157714\n",
      "[Train epoch 45/50] loss=0.020550, train_rmse=0.156404\n",
      "[Train epoch 50/50] loss=0.019496, train_rmse=0.156848\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1335673463394675\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 94 | labelled size = 960 | pool size = 59040 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.230306, train_rmse=0.300056\n",
      "[Train epoch 5/50] loss=0.073331, train_rmse=0.258162\n",
      "[Train epoch 10/50] loss=0.058503, train_rmse=0.226171\n",
      "[Train epoch 15/50] loss=0.047768, train_rmse=0.198201\n",
      "[Train epoch 20/50] loss=0.038608, train_rmse=0.183363\n",
      "[Train epoch 25/50] loss=0.033079, train_rmse=0.169341\n",
      "[Train epoch 30/50] loss=0.027388, train_rmse=0.156885\n",
      "[Train epoch 35/50] loss=0.024563, train_rmse=0.157580\n",
      "[Train epoch 40/50] loss=0.020321, train_rmse=0.150625\n",
      "[Train epoch 45/50] loss=0.020226, train_rmse=0.157730\n",
      "[Train epoch 50/50] loss=0.020028, train_rmse=0.150827\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13658248221815128\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 95 | labelled size = 970 | pool size = 59030 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.222795, train_rmse=0.303219\n",
      "[Train epoch 5/50] loss=0.076308, train_rmse=0.264574\n",
      "[Train epoch 10/50] loss=0.060809, train_rmse=0.226631\n",
      "[Train epoch 15/50] loss=0.048997, train_rmse=0.204837\n",
      "[Train epoch 20/50] loss=0.041241, train_rmse=0.181722\n",
      "[Train epoch 25/50] loss=0.037159, train_rmse=0.182823\n",
      "[Train epoch 30/50] loss=0.031758, train_rmse=0.170117\n",
      "[Train epoch 35/50] loss=0.026463, train_rmse=0.160120\n",
      "[Train epoch 40/50] loss=0.026246, train_rmse=0.164749\n",
      "[Train epoch 45/50] loss=0.021962, train_rmse=0.152739\n",
      "[Train epoch 50/50] loss=0.020546, train_rmse=0.155888\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13739812604752072\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 96 | labelled size = 980 | pool size = 59020 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.206898, train_rmse=0.298971\n",
      "[Train epoch 5/50] loss=0.074054, train_rmse=0.256320\n",
      "[Train epoch 10/50] loss=0.058324, train_rmse=0.220829\n",
      "[Train epoch 15/50] loss=0.044750, train_rmse=0.191640\n",
      "[Train epoch 20/50] loss=0.037883, train_rmse=0.177136\n",
      "[Train epoch 25/50] loss=0.033337, train_rmse=0.173547\n",
      "[Train epoch 30/50] loss=0.028789, train_rmse=0.160972\n",
      "[Train epoch 35/50] loss=0.025838, train_rmse=0.158251\n",
      "[Train epoch 40/50] loss=0.024019, train_rmse=0.161821\n",
      "[Train epoch 45/50] loss=0.022252, train_rmse=0.163142\n",
      "[Train epoch 50/50] loss=0.020761, train_rmse=0.155025\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13570434919825225\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 97 | labelled size = 990 | pool size = 59010 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.255941, train_rmse=0.300926\n",
      "[Train epoch 5/50] loss=0.076768, train_rmse=0.264734\n",
      "[Train epoch 10/50] loss=0.060443, train_rmse=0.226464\n",
      "[Train epoch 15/50] loss=0.049215, train_rmse=0.205384\n",
      "[Train epoch 20/50] loss=0.041956, train_rmse=0.190993\n",
      "[Train epoch 25/50] loss=0.036327, train_rmse=0.172924\n",
      "[Train epoch 30/50] loss=0.031631, train_rmse=0.169897\n",
      "[Train epoch 35/50] loss=0.028193, train_rmse=0.159074\n",
      "[Train epoch 40/50] loss=0.026070, train_rmse=0.163492\n",
      "[Train epoch 45/50] loss=0.024222, train_rmse=0.156569\n",
      "[Train epoch 50/50] loss=0.022868, train_rmse=0.158620\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.14144733175307583\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 98 | labelled size = 1000 | pool size = 59000 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.252055, train_rmse=0.302586\n",
      "[Train epoch 5/50] loss=0.077808, train_rmse=0.267672\n",
      "[Train epoch 10/50] loss=0.062139, train_rmse=0.233184\n",
      "[Train epoch 15/50] loss=0.053083, train_rmse=0.211988\n",
      "[Train epoch 20/50] loss=0.044839, train_rmse=0.192551\n",
      "[Train epoch 25/50] loss=0.036718, train_rmse=0.175950\n",
      "[Train epoch 30/50] loss=0.031869, train_rmse=0.169199\n",
      "[Train epoch 35/50] loss=0.029150, train_rmse=0.159355\n",
      "[Train epoch 40/50] loss=0.026558, train_rmse=0.160089\n",
      "[Train epoch 45/50] loss=0.023266, train_rmse=0.156282\n",
      "[Train epoch 50/50] loss=0.022652, train_rmse=0.157437\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13914086954736826\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 99 | labelled size = 1010 | pool size = 58990 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.208871, train_rmse=0.298310\n",
      "[Train epoch 5/50] loss=0.073321, train_rmse=0.257799\n",
      "[Train epoch 10/50] loss=0.056629, train_rmse=0.219151\n",
      "[Train epoch 15/50] loss=0.046514, train_rmse=0.200714\n",
      "[Train epoch 20/50] loss=0.039376, train_rmse=0.182214\n",
      "[Train epoch 25/50] loss=0.033175, train_rmse=0.177128\n",
      "[Train epoch 30/50] loss=0.027920, train_rmse=0.159574\n",
      "[Train epoch 35/50] loss=0.025155, train_rmse=0.157673\n",
      "[Train epoch 40/50] loss=0.023552, train_rmse=0.158348\n",
      "[Train epoch 45/50] loss=0.021823, train_rmse=0.154377\n",
      "[Train epoch 50/50] loss=0.020354, train_rmse=0.154907\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.1375143199486404\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 100 | labelled size = 1020 | pool size = 58980 ===\n",
      "Computing W_SSL (linear probe ridge)...\n",
      "W_ssl shape: torch.Size([256, 10])\n",
      "[Train epoch 1/50] loss=0.202542, train_rmse=0.295813\n",
      "[Train epoch 5/50] loss=0.075811, train_rmse=0.263309\n",
      "[Train epoch 10/50] loss=0.056971, train_rmse=0.217830\n",
      "[Train epoch 15/50] loss=0.045363, train_rmse=0.193178\n",
      "[Train epoch 20/50] loss=0.036984, train_rmse=0.175607\n",
      "[Train epoch 25/50] loss=0.032225, train_rmse=0.166642\n",
      "[Train epoch 30/50] loss=0.028241, train_rmse=0.155130\n",
      "[Train epoch 35/50] loss=0.025187, train_rmse=0.153869\n",
      "[Train epoch 40/50] loss=0.023146, train_rmse=0.152409\n",
      "[Train epoch 45/50] loss=0.022043, train_rmse=0.156343\n",
      "[Train epoch 50/50] loss=0.020168, train_rmse=0.150597\n",
      "Using Pretrained Prior Weight M0!\n",
      "M_post shape torch.Size([256, 10])\n",
      "U_post shape torch.Size([256, 256])\n",
      "Sigma shape torch.Size([10, 10])\n",
      "Final test RMSE: 0.13360063755060306\n",
      "Results saved to outputs/bnn_ssl/history_BNN_Analytical_PredCovariance_Run5.json\n"
     ]
    }
   ],
   "source": [
    "#@title Run all acquisition functions\n",
    "for idx, acq_function in enumerate(acq_functions):\n",
    "    for seed in seeds:\n",
    "        acq_name = acq_names[idx]\n",
    "        print(f\"\\n\\n========== Running {acq_name} Seed {seed} ==========\")\n",
    "\n",
    "        pretrained_model, _ = pretrain_model(seed, hidden_sizes)\n",
    "        init_idxs = sample_balanced_seed(train_dataset_to_use, n_per_class=2, seed=seed)\n",
    "\n",
    "        history = active_learning_loop(\n",
    "            pretrained_model=pretrained_model,\n",
    "            model_ctor=make_model,\n",
    "            train_dataset=train_dataset_to_use,\n",
    "            test_dataset=test_dataset_to_use,\n",
    "            initial_labeled_idxs=init_idxs,\n",
    "            candidate_pool_size=candidate_pool_size, # subsample size\n",
    "            n_acq_per_iter=10,    \n",
    "            n_iterations=n_iterations,# number of AL rounds\n",
    "            epochs_per_round=epochs_per_round,  \n",
    "            lr=1e-3,\n",
    "            weight_decay=1e-4,     \n",
    "            T_acq=T_acq,   \n",
    "            batch_train=64,\n",
    "            batch_pool=256,\n",
    "            prior_s=prior_s,\n",
    "            reset_model=True,   \n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            is_bayesian=True,\n",
    "            acquisition_fn=acq_function,\n",
    "            acquisition_kwargs={'device': device}\n",
    "        )\n",
    "\n",
    "        # Save history to a json file\n",
    "        file_name = output_dir + f'history_{model_names[idx]}_{acq_name}_Run{seed}.json'\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(history, f)\n",
    "        print(f\"Results saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0AvY8UKBFFB"
   },
   "source": [
    "## 4.4 Visualising Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1767464522961,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "MJgMko1tBFFB",
    "outputId": "6ca52c6f-022c-4235-9eb3-f52aa3e4f933"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title plot_active_learning_curves()\n",
    "def plot_active_learning_curves(history_list, labels=None, ylim = None,\n",
    "                                title=\"Bayesian NN Active Learning (MNIST)\",\n",
    "                                xlabel=\"Number of labeled training examples\",\n",
    "                                ylabel=\"RMSE values\",\n",
    "                                xfield=\"labelled_set_sizes\",\n",
    "                                yfield=\"test_rmse\",\n",
    "                                marker=\"\",\n",
    "                                linestyle=\"-\"):\n",
    "    if labels is not None:\n",
    "        assert len(labels) == len(history_list), \"Labels must have same length as history_list.\"\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for idx, history in enumerate(history_list):\n",
    "        x = history[xfield]\n",
    "        y = history[yfield]\n",
    "        label = labels[idx] if labels is not None else None\n",
    "\n",
    "        assert len(x) == len(y), \"Label sizes and accuracies must have same length.\"\n",
    "        plt.plot(x, y, marker=marker, linestyle=linestyle, label=label)\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    if labels is not None:\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_active_learning_curves([history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1767464762994,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "Yak5fjkrtHjW",
    "outputId": "4454b25c-2ed2-4545-cc6c-3dc19c76cb2f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = [\"BNN_Analytical\", \"BNN_SSL\"]\n",
    "\n",
    "file_names = ['outputs/bnn_analytical/history_BNN_Analytical_PredCovariance_AVG_STATS.json',\n",
    "              'outputs/bnn_ssl/history_BNN_Analytical_PredCovariance_AVG_STATS.json']\n",
    "history_list = []\n",
    "for file_name in file_names:\n",
    "    with open(file_name, 'r') as f:\n",
    "        history = json.load(f)\n",
    "        history_list.append(history)\n",
    "\n",
    "plot_active_learning_curves(history_list, labels=model_names,\n",
    "                            title=f\"Bayesian VS Deterministic NN RMSE\",\n",
    "                            yfield=\"test_rmse_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns8Pz-TdGuhl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hLnVuAgnKl2v",
    "JUq-ghjqMtee",
    "JyPDYU7x0lhu",
    "wBC2xaSJ1Au_",
    "ipv8n5U__XN0",
    "fmQEXitp_mu1",
    "vKUkow4-_rof",
    "zyBnpvgsBFFA",
    "-6BzMA5qBFFB"
   ],
   "provenance": [
    {
     "file_id": "1_Ywoood-Sm6sZJRCgJTGcc6OALNgOiUK",
     "timestamp": 1767366610650
    },
    {
     "file_id": "1IhJdG2w1pws7LZ7V_baeyHDCd33kz216",
     "timestamp": 1767278679249
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
