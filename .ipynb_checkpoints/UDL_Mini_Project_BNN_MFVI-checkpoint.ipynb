{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22223,
     "status": "ok",
     "timestamp": 1767371113136,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "o883yfJrKAzJ",
    "outputId": "a76a4418-b886-4c5f-d247-49166ecb42cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/Colab Notebooks/UDL Mini Project\n"
     ]
    }
   ],
   "source": [
    "# Mount on drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/UDL Mini Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12049,
     "status": "ok",
     "timestamp": 1767371125196,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "gZcItpDJKY2Y",
    "outputId": "be2b0262-231a-4245-cf00-ffd6f761e65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "import heapq\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvcLJGz1L-np"
   },
   "source": [
    "# 1. Input Processing\n",
    "\n",
    "## 1.1 Load all the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2501,
     "status": "ok",
     "timestamp": 1767371127699,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "pqIuPfaTKj2P"
   },
   "outputs": [],
   "source": [
    "def get_mnist_data(batch_train=64, batch_eval=256, root='./data'):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    train = datasets.MNIST(root=root, train=True, download=True, transform=transform)\n",
    "    test  = datasets.MNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader_full = DataLoader(train, batch_size=batch_train, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_eval, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train, train_loader_full, test, test_loader\n",
    "\n",
    "train_dataset, train_loader_full, test_dataset, test_loader = get_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUq-ghjqMtee"
   },
   "source": [
    "## 1.2 Take out subsets of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1767371127804,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "A850N6c9kW63"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1767371127806,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "eYPpOfPuktCF"
   },
   "outputs": [],
   "source": [
    "def sample_balanced_seed(full_dataset: Dataset, n_per_class=2, num_classes=10, seed=0):\n",
    "\n",
    "    set_seed(seed)\n",
    "    indices_by_class = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(full_dataset):\n",
    "        indices_by_class[int(label)].append(idx)\n",
    "    seed_indices = []\n",
    "    for c in range(num_classes):\n",
    "        choices = random.sample(indices_by_class[c], k=n_per_class)\n",
    "        seed_indices.extend(choices)\n",
    "    random.shuffle(seed_indices)\n",
    "    return seed_indices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14508,
     "status": "ok",
     "timestamp": 1767371142315,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "x_I7_oXV-CDQ",
    "outputId": "0870ea89-d287-4a5f-ca35-3a0a1569f449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Take out 20 images, 2 per class\n",
    "seed_idx = sample_balanced_seed(train_dataset, n_per_class=100, seed=seed)\n",
    "train_dataset_small = Subset(train_dataset, seed_idx)\n",
    "train_loader_small = DataLoader(train_dataset_small, batch_size=64, shuffle=True)\n",
    "print(len(train_dataset_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdHHs_3YTLIG"
   },
   "source": [
    "# 2. Model for BNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAt-p6nNp7-f"
   },
   "source": [
    "## 2.1 Simple BNN MVFVI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1767371142318,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "8rzlDTn8BFE_"
   },
   "outputs": [],
   "source": [
    "def stable_inv(mat, jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Numerically stable inverse: try Cholesky, fall back to adding jitter.\n",
    "    mat: symmetric (d x d) torch tensor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        L = torch.linalg.cholesky(mat, upper=False)\n",
    "        invL = torch.inverse(L)\n",
    "        inv = invL.t() @ invL\n",
    "        return inv\n",
    "    except Exception:\n",
    "        d = mat.shape[0]\n",
    "        mat_j = mat + jitter * torch.eye(d, device=mat.device, dtype=mat.dtype)\n",
    "        return torch.inverse(mat_j)\n",
    "\n",
    "def bijective_softplus(x, eps=1e-8):\n",
    "    # stable softplus for positive params\n",
    "    return F.softplus(x) + eps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1767371142345,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "lrRwMiWsTh9O"
   },
   "outputs": [],
   "source": [
    "class MFVILastLayerRegressorSimple(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=28*28, hidden_sizes=[512,256], output_dim=10, dropout=0.5, device='cpu'):\n",
    "        print(\"Initializing BNN MFVI MLPRegressor Simple...\")\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            if dropout and dropout > 0:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "            in_dim = h\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.output_dim = output_dim\n",
    "        self.feature_dim = in_dim  # K\n",
    "\n",
    "        # variational parameters (initialized small)\n",
    "        K = self.feature_dim\n",
    "        C = self.output_dim\n",
    "        self.M = nn.Parameter(0.01 * torch.randn(K, C, device=self.device))\n",
    "        # log-params for u (K,) and v (C,)\n",
    "        self.log_u = nn.Parameter(-5.0 * torch.ones(K, device=self.device))  # initial small variance\n",
    "        self.log_v = nn.Parameter(-5.0 * torch.ones(C, device=self.device))\n",
    "        self.log_sigma_y2 = nn.Parameter(torch.log(torch.tensor(0.1, device=self.device)))  # can be learned or fixed\n",
    "        self.prior_s = 1.0\n",
    "\n",
    "        # initialize feature extractor weights small\n",
    "        self._init_weights()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.feature_extractor.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "       \n",
    "        if x.dim() == 4:\n",
    "            x_flat = x.view(x.size(0), -1)\n",
    "        else:\n",
    "            x_flat = x\n",
    "        feats = self.feature_extractor(x_flat.to(self.device))\n",
    "        mu = feats @ self.M   # predictive mean\n",
    "        if return_features:\n",
    "            return mu, feats\n",
    "        return mu\n",
    "\n",
    "    # ELBO & related computation\n",
    "    def elbo(self, Phi, Y, prior_s=None, sigma_y2=None):\n",
    "        \"\"\"\n",
    "        Compute ELBO = E_q[log p(Y|Phi, W)] - KL(q||p) for the diagonal-Kronecker MFVI q.\n",
    "        Inputs:\n",
    "          - Phi: (N, K) features (torch tensor on same device)\n",
    "          - Y:   (N, C) targets (one-hot float)\n",
    "          - prior_s: scalar prior precision; if None uses self.prior_s\n",
    "          - sigma_y2: observation noise variance; if None uses exp(self.log_sigma_y2)\n",
    "        Returns:\n",
    "          - elbo scalar (torch)\n",
    "          - components: (expected_log_like, kl)\n",
    "        \"\"\"\n",
    "        device = self.device\n",
    "        Phi = Phi.to(device)\n",
    "        Y = Y.to(device)\n",
    "        N, K = Phi.shape\n",
    "        _, C = Y.shape\n",
    "\n",
    "        if prior_s is None:\n",
    "            prior_s = float(self.prior_s)\n",
    "        if sigma_y2 is None:\n",
    "            sigma_y2 = torch.exp(self.log_sigma_y2)\n",
    "\n",
    "        # Variational params\n",
    "        M = self.M  # (K, C)\n",
    "        u = bijective_softplus(self.log_u)  # (K,)\n",
    "        v = bijective_softplus(self.log_v)  # (C,)\n",
    "        # compute expected-data-fit term:\n",
    "        # E_q[||Y - Phi W||^2_F] = ||Y - Phi M||^2_F + sum_{k} (sum_i Phi_{i,k}^2) * sum_j (u_k * v_j)\n",
    "        PhiM = Phi @ M # (N, C)\n",
    "        residual = Y - PhiM\n",
    "        sqerr_term = (residual ** 2).sum()  # scalar\n",
    "\n",
    "        phi_sq_sum = (Phi ** 2).sum(dim=0)  # (K,)\n",
    "        sum_v = v.sum()  # scalar\n",
    "        extra = (phi_sq_sum * u).sum() * sum_v  # scalar\n",
    "\n",
    "        expected_sqerr = sqerr_term + extra  # scalar\n",
    "\n",
    "        # expected log-likelihood (Gaussian)\n",
    "        # log p(Y|Phi,W) = -N*C/2 * log(2πσ^2) - 1/(2σ^2) * E_q[||Y - Phi W||^2_F]\n",
    "        expected_log_like = -0.5 * (N * C) * torch.log(2 * torch.tensor(np.pi, device=device) * sigma_y2) \\\n",
    "                            - 0.5 / sigma_y2 * expected_sqerr\n",
    "\n",
    "        # KL(q||p): \n",
    "        prior_var = sigma_y2 / prior_s\n",
    "        M2 = (M ** 2)  # (K, C)\n",
    "        q_var = u.unsqueeze(1) * v.unsqueeze(0)  # (K, C)\n",
    "\n",
    "        # KL(N(m, s2_q) || N(0, s2_p)) = 0.5*( log(s2_p/s2_q) + (s2_q + m^2)/s2_p - 1 )\n",
    "        term1 = 0.5 * (torch.log(prior_var) - torch.log(q_var)).sum()\n",
    "        term2 = 0.5 * ((q_var + M2) / prior_var).sum()\n",
    "        kl = term1 + term2 - 0.5 * (K * C)\n",
    "\n",
    "        elbo = expected_log_like - kl\n",
    "\n",
    "        return elbo, expected_log_like, kl\n",
    "\n",
    "    # Variational optimizer (fit variational params)\n",
    "    def fit_variational(self,\n",
    "                        labeled_loader,\n",
    "                        prior_s=1.0,\n",
    "                        sigma_y2=None,\n",
    "                        lr=1e-3,\n",
    "                        n_epochs=200,\n",
    "                        batch_update=False,\n",
    "                        verbose=True):\n",
    "        \n",
    "        self.prior_s = prior_s\n",
    "        device = self.device\n",
    "\n",
    "        if not batch_update:\n",
    "            feats_list = []\n",
    "            y_list = []\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                for x, y in labeled_loader:\n",
    "                    x = x.to(device)\n",
    "                    if x.dim() == 4:\n",
    "                        x_flat = x.view(x.size(0), -1)\n",
    "                    else:\n",
    "                        x_flat = x\n",
    "                    feats = self.feature_extractor(x_flat)   # [B, K]\n",
    "                    feats_list.append(feats.cpu())\n",
    "                    y_list.append(F.one_hot(y, num_classes=self.output_dim).float())\n",
    "            Phi = torch.cat(feats_list, dim=0).to(device)\n",
    "            Y = torch.cat(y_list, dim=0).to(device)\n",
    "        else:\n",
    "            Phi = None\n",
    "            Y = None\n",
    "\n",
    "        # optimizer for variational params\n",
    "        params = [self.M, self.log_u, self.log_v]\n",
    "        if sigma_y2 is None:\n",
    "            params.append(self.log_sigma_y2)\n",
    "        opt = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "        history = {'elbo': [], 'expected_log_like': [], 'kl': []}\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            opt.zero_grad()\n",
    "            if not batch_update:\n",
    "                elbo_val, ell, kl = self.elbo(Phi, Y, prior_s=prior_s, sigma_y2=sigma_y2)\n",
    "                loss = -elbo_val\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            else:\n",
    "                total_expected_loglike = 0.0\n",
    "                total_N = 0\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    pass\n",
    "                raise NotImplementedError(\"batch_update=True not implemented; use full-batch mode with labeled_loader capturing entire set.\")\n",
    "            history['elbo'].append(elbo_val.item())\n",
    "            history['expected_log_like'].append(ell.item())\n",
    "            history['kl'].append(kl.item())\n",
    "            if verbose and (epoch % 100 == 0 or epoch == 1 or epoch == n_epochs):\n",
    "                print(f\"[VI epoch {epoch:03d}] ELBO={elbo_val.item():.4f} | E_log_like={ell.item():.4f} | KL={kl.item():.4f}\")\n",
    "        return history\n",
    "\n",
    "    # Utility: predictive mean & predictive variance factor q(x)\n",
    "    @torch.no_grad()\n",
    "    def predictive_mean_and_q(self, x):\n",
    "       \n",
    "        self.eval()\n",
    "        if x.dim() == 4:\n",
    "            x_flat = x.view(x.size(0), -1)\n",
    "        else:\n",
    "            x_flat = x\n",
    "        feats = self.feature_extractor(x_flat.to(self.device))  # (B, K)\n",
    "        mean = feats @ self.M  # (B, C)\n",
    "        u = bijective_softplus(self.log_u)  # (K,)\n",
    "        v = bijective_softplus(self.log_v)  # (C,)\n",
    "        phi_sq = feats ** 2  # (B, K)\n",
    "        phi_u = (phi_sq * u.unsqueeze(0)).sum(dim=1)  # (B,)\n",
    "        scalar_uncert = phi_u * v.sum()\n",
    "        return mean, scalar_uncert  # mean (B,C), scalar_uncert (B,)\n",
    "\n",
    "    # Sampling W from variational q\n",
    "    def sample_W(self, n_samples=1):\n",
    "        \"\"\"\n",
    "        Sample W from q: elementwise normal independent with mean M and variance u_k * v_j.\n",
    "        Returns tensor shaped (n_samples, K, C)\n",
    "        \"\"\"\n",
    "        u = bijective_softplus(self.log_u).detach()\n",
    "        v = bijective_softplus(self.log_v).detach()\n",
    "        K, C = self.M.shape\n",
    "        qvar = (u.unsqueeze(1) * v.unsqueeze(0)).to(self.device)  # (K, C)\n",
    "        samples = []\n",
    "        for _ in range(n_samples):\n",
    "            eps = torch.randn_like(self.M, device=self.device)\n",
    "            W_samp = self.M + torch.sqrt(qvar) * eps\n",
    "            samples.append(W_samp.unsqueeze(0))\n",
    "        return torch.cat(samples, dim=0)  # (n_samples, K, C)\n",
    "\n",
    "    def freeze_features(self):\n",
    "        for p in self.feature_extractor.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def unfreeze_features(self):\n",
    "        for p in self.feature_extractor.parameters():\n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPW8LxMhqBIw"
   },
   "source": [
    "## 2.2 Full BNN MFVI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1767371142556,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "iGZKu9EPqO6T"
   },
   "outputs": [],
   "source": [
    "def jitter_eye(d, jitter, device=None, dtype=torch.float32):\n",
    "    return (jitter * torch.eye(d, device=device, dtype=dtype))\n",
    "\n",
    "def cholesky_with_jitter(A, jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Return lower-triangular L s.t. A + jitter*I = L L^T\n",
    "    \"\"\"\n",
    "    try:\n",
    "        L = torch.linalg.cholesky(A)\n",
    "        return L\n",
    "    except Exception:\n",
    "        d = A.shape[0]\n",
    "        A_j = A + jitter * torch.eye(d, device=A.device, dtype=A.dtype)\n",
    "        return torch.linalg.cholesky(A_j)\n",
    "\n",
    "def stable_slogdet(A, jitter=1e-12):\n",
    "    # torch.linalg.slogdet returns (sign, logabsdet)\n",
    "    sign, logabsdet = torch.linalg.slogdet(A)\n",
    "    # if sign <= 0 maybe ill-conditioned; add jitter\n",
    "    if (sign <= 0).any():\n",
    "        A_j = A + jitter * torch.eye(A.shape[0], device=A.device, dtype=A.dtype)\n",
    "        sign, logabsdet = torch.linalg.slogdet(A_j)\n",
    "    return sign, logabsdet\n",
    "\n",
    "def mat_trace(A):\n",
    "    return torch.trace(A)\n",
    "\n",
    "def safe_inv(A, jitter=1e-6):\n",
    "    try:\n",
    "        invA = torch.inverse(A)\n",
    "        return invA\n",
    "    except Exception:\n",
    "        A_j = A + jitter * torch.eye(A.shape[0], device=A.device, dtype=A.dtype)\n",
    "        return torch.inverse(A_j)\n",
    "\n",
    "\n",
    "def build_lower_triangular(raw, diag_transform=torch.exp):\n",
    "    \"\"\"\n",
    "    raw: a flat tensor containing the lower-triangular entries in row-major order excluding upper part,\n",
    "         or alternately a (d,d) matrix where we will force upper triangle to zero and apply transform to diag.\n",
    "    We'll accept a (d,d) raw matrix and produce L with transformed diagonal guaranteed positive.\n",
    "    diag_transform: function to map raw diag to positive (exp or softplus).\n",
    "    \"\"\"\n",
    "    # raw: (d,d) tensor\n",
    "    d = raw.shape[0]\n",
    "    L = torch.tril(raw, diagonal=-0)  # include diagonal\n",
    "    # apply transformation to diagonal entries to make positive\n",
    "    diag = torch.diag(L)\n",
    "    diag_t = diag_transform(diag)\n",
    "    L = L - torch.diag(diag) + torch.diag(diag_t)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1767371142921,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "b3UIx4x2qEko"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FullMNVariationalLastLayer():\n",
    "\n",
    "    def __init__(self, K, C, device='cpu', init_scale=1e-2, diag_init=1e-2):\n",
    "        print(\"Initialising Full Matrix Normal VI Model for Final Layer...\")\n",
    "        self.device = torch.device(device if isinstance(device, str) else ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        self.K = K\n",
    "        self.C = C\n",
    "\n",
    "        # variational parameters (torch.nn.Parameter-like but we hold them here)\n",
    "        # mean M (K x C)\n",
    "        self.M = nn.Parameter(init_scale * torch.randn(K, C, device=self.device))\n",
    "\n",
    "        # raw lower-triangular matrices for U and V\n",
    "        self.Lu_raw = nn.Parameter(torch.randn(K, K, device=self.device) * diag_init)\n",
    "        self.Lv_raw = nn.Parameter(torch.randn(C, C, device=self.device) * diag_init)\n",
    "\n",
    "        self.log_sigma_y2 = nn.Parameter(torch.log(torch.tensor(1.0, device=self.device)))  # scalar variance if needed\n",
    "\n",
    "        # keep track of built PD matrices cached optionally\n",
    "        self._U_q = None\n",
    "        self._V_q = None\n",
    "\n",
    "    def to(self, device):\n",
    "        self.device = torch.device(device)\n",
    "        self.M = nn.Parameter(self.M.to(self.device))\n",
    "        self.Lu_raw = nn.Parameter(self.Lu_raw.to(self.device))\n",
    "        self.Lv_raw = nn.Parameter(self.Lv_raw.to(self.device))\n",
    "        self.log_sigma_y2 = nn.Parameter(self.log_sigma_y2.to(self.device))\n",
    "\n",
    "    def build_Uq(self):\n",
    "        L_u = build_lower_triangular(self.Lu_raw, diag_transform=torch.exp)\n",
    "        U_q = L_u @ L_u.t()\n",
    "        self._U_q = U_q\n",
    "        return U_q\n",
    "\n",
    "    def build_Vq(self):\n",
    "        L_v = build_lower_triangular(self.Lv_raw, diag_transform=torch.exp)\n",
    "        V_q = L_v @ L_v.t()\n",
    "        self._V_q = V_q\n",
    "        return V_q\n",
    "\n",
    "    def unpack_prior(self, prior):\n",
    "        M0 = prior.get('M0', torch.zeros(self.K, self.C, device=self.device))\n",
    "        U0 = prior.get('U0', None)\n",
    "        V0 = prior.get('V0', None)\n",
    "        Sigma = prior.get('Sigma', None)\n",
    "        s = prior.get('s', None)\n",
    "        if U0 is None:\n",
    "            if s is None:\n",
    "                s = 1.0\n",
    "            U0 = (1.0 / float(s)) * torch.eye(self.K, device=self.device)\n",
    "        if V0 is None:\n",
    "            if Sigma is not None:\n",
    "                V0 = Sigma.to(self.device)\n",
    "            else:\n",
    "                V0 = torch.eye(self.C, device=self.device)\n",
    "        if Sigma is None:\n",
    "            Sigma = torch.eye(self.C, device=self.device)  # default likelihood cov\n",
    "        # ensure tensors on device\n",
    "        return M0.to(self.device), U0.to(self.device), V0.to(self.device), Sigma.to(self.device)\n",
    "\n",
    "    # ELBO components\n",
    "    def expected_log_likelihood(self, Phi, Y, Sigma):\n",
    "        \"\"\"\n",
    "        Compute E_q[ log p(Y | Phi, W) ] for q = MN(M, U_q, V_q)\n",
    "        With p(Y|Phi,W) = MN(Phi W, I_N, Sigma)\n",
    "        Formula:\n",
    "          E = const - 0.5 * tr[ Sigma^{-1} (Y - Phi M)^T (Y - Phi M) ] - 0.5 * tr(Phi^T Phi U_q) * tr(Sigma^{-1} V_q)\n",
    "        Return scalar (torch)\n",
    "        \"\"\"\n",
    "        Phi = Phi.to(self.device)\n",
    "        Y = Y.to(self.device)\n",
    "        Sigma = Sigma.to(self.device)\n",
    "\n",
    "        N = Phi.shape[0]\n",
    "        C = self.C\n",
    "\n",
    "        U_q = self.build_Uq()\n",
    "        V_q = self.build_Vq()\n",
    "\n",
    "        try:\n",
    "            L_S = cholesky_with_jitter(Sigma)\n",
    "            Sigma_inv = torch.cholesky_inverse(L_S)\n",
    "        except Exception:\n",
    "            Sigma_inv = safe_inv(Sigma)\n",
    "\n",
    "        # first term: tr[ Sigma^{-1} (Y - Phi M)^T (Y - Phi M) ]\n",
    "        Resid = Y - Phi @ self.M  # N x C\n",
    "        # compute S1 = Resid^T Resid (C x C), then tr(Sigma_inv @ S1)\n",
    "        S1 = Resid.t() @ Resid  # C x C\n",
    "        term1 = torch.trace(Sigma_inv @ S1)  # scalar\n",
    "\n",
    "        # second term: tr(Phi^T Phi U_q) * tr(Sigma^{-1} V_q)\n",
    "        A = Phi.t() @ Phi  # K x K\n",
    "        tr_A_U = torch.trace(A @ U_q)  # scalar\n",
    "\n",
    "        tr_Sinv_V = torch.trace(Sigma_inv @ V_q)  # scalar\n",
    "\n",
    "        term2 = tr_A_U * tr_Sinv_V\n",
    "\n",
    "        # constant term: - (N*C / 2) * log(2π) - (N/2) * log|Sigma|  (log|Sigma| part inside)\n",
    "        sign, logabsdetSigma = stable_slogdet(Sigma)\n",
    "\n",
    "        const = -0.5 * N * C * torch.log(2.0 * torch.tensor(np.pi, device=self.device)) - 0.5 * N * logabsdetSigma\n",
    "\n",
    "        expected_loglike = const - 0.5 * (term1 + term2)\n",
    "        return expected_loglike\n",
    "\n",
    "    def kl_matrix_normal(self, M0, U0, V0):\n",
    "\n",
    "        M = self.M.to(self.device)\n",
    "        U_q = self.build_Uq()\n",
    "        V_q = self.build_Vq()\n",
    "        K = self.K\n",
    "        C = self.C\n",
    "\n",
    "        try:\n",
    "            L_U0 = cholesky_with_jitter(U0)\n",
    "            U0_inv = torch.cholesky_inverse(L_U0)\n",
    "        except Exception:\n",
    "            U0_inv = safe_inv(U0)\n",
    "        try:\n",
    "            L_V0 = cholesky_with_jitter(V0)\n",
    "            V0_inv = torch.cholesky_inverse(L_V0)\n",
    "        except Exception:\n",
    "            V0_inv = safe_inv(V0)\n",
    "\n",
    "        # traces\n",
    "        tr_V0inv_Vq = torch.trace(V0_inv @ V_q)\n",
    "        tr_U0inv_Uq = torch.trace(U0_inv @ U_q)\n",
    "        trace_term = tr_V0inv_Vq * tr_U0inv_Uq\n",
    "\n",
    "        # quadratic term\n",
    "        D = M - M0  # K x C\n",
    "        quad = torch.trace(V0_inv @ (D.t() @ (U0_inv @ D)))  # equals vec(D)^T (V0^{-1} ⊗ U0^{-1}) vec(D)\n",
    "\n",
    "        # log-determinants\n",
    "        signU0, logdetU0 = stable_slogdet(U0)\n",
    "        signV0, logdetV0 = stable_slogdet(V0)\n",
    "        signUq, logdetUq = stable_slogdet(U_q)\n",
    "        signVq, logdetVq = stable_slogdet(V_q)\n",
    "\n",
    "        # assemble\n",
    "        log_ratio = (K * logdetV0 + C * logdetU0) - (K * logdetVq + C * logdetUq)\n",
    "        KL = 0.5 * (log_ratio - K * C + trace_term + quad)\n",
    "        return KL\n",
    "\n",
    "    # ELBO = expected_log_likelihood - KL\n",
    "    def elbo(self, Phi, Y, prior):\n",
    "        \"\"\"\n",
    "        Compute full ELBO value given Phi (N,K), Y (N,C), and prior dict.\n",
    "        prior must supply M0, U0, V0, Sigma\n",
    "        \"\"\"\n",
    "        M0, U0, V0, Sigma = self.unpack_prior(prior)\n",
    "        exp_loglike = self.expected_log_likelihood(Phi, Y, Sigma)\n",
    "        kl = self.kl_matrix_normal(M0, U0, V0)\n",
    "        elbo_val = exp_loglike - kl\n",
    "        return elbo_val, exp_loglike, kl\n",
    "\n",
    "    # Fit variational parameters via gradient ascent on ELBO (or descent on negative ELBO)\n",
    "    def fit_variational(self, Phi, Y, prior=None, lr=1e-3, n_iters=1000, verbose=True, jitter=1e-6):\n",
    "        \"\"\"\n",
    "        Optimize ELBO with Adam on parameters M, Lu_raw, Lv_raw (and optionally log_sigma_y2 if you'd like).\n",
    "        Phi: (N, K) torch\n",
    "        Y:   (N, C) torch\n",
    "        prior: dict with M0, U0, V0, Sigma (or None -> defaults)\n",
    "        \"\"\"\n",
    "        Phi = Phi.to(self.device)\n",
    "        Y = Y.to(self.device)\n",
    "        if prior is None:\n",
    "            prior = {}\n",
    "        M0, U0, V0, Sigma = self.unpack_prior(prior)\n",
    "\n",
    "        params = [self.M, self.Lu_raw, self.Lv_raw, self.log_sigma_y2]\n",
    "        optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "        history = {'elbo': [], 'exp_loglike': [], 'kl': []}\n",
    "        for it in range(1, n_iters + 1):\n",
    "            optimizer.zero_grad()\n",
    "            elbo_val, expo, kl = self.elbo(Phi, Y, prior)\n",
    "            loss = -elbo_val\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if verbose and (it % max(1, n_iters // 10) == 0 or it == 1):\n",
    "                print(f\"[VI iter {it}/{n_iters}] ELBO={elbo_val.item():.4f} exp_ll={expo.item():.4f} KL={kl.item():.4f}\")\n",
    "            history['elbo'].append(elbo_val.item())\n",
    "            history['exp_loglike'].append(expo.item())\n",
    "            history['kl'].append(kl.item())\n",
    "        return history\n",
    "\n",
    "    # Predictive analytic mean and covariance for new features\n",
    "    def predict_mean_and_cov(self, Phi_star, prior=None):\n",
    "        \"\"\"\n",
    "        Given Phi_star (N*, K), compute predictive mean (N*, C) and predictive covariance factorization:\n",
    "          E[y*] = Phi_star M  (N* x C)\n",
    "          Cov[y*] = Sigma + tr(Phi_star^T Phi_star U_q) * V_q   ??? Careful: need per-sample\n",
    "        More generally per sample i:\n",
    "          E[y_i] = M^T phi_i\n",
    "          Cov[y_i] = Sigma + (phi_i^T U_q phi_i) * V_q\n",
    "        Return:\n",
    "          means: (N*, C) torch\n",
    "          cov_factors: (N*,) q_i = phi_i^T U_q phi_i  (so full cov for i is Sigma + q_i * V_q)\n",
    "          V_q, Sigma tensors as returned for constructing full CxC cov if needed\n",
    "        \"\"\"\n",
    "        Phi_star = Phi_star.to(self.device)\n",
    "        U_q = self.build_Uq()\n",
    "        V_q = self.build_Vq()\n",
    "        means = Phi_star @ self.M  # (N*, C)\n",
    "        temp = (U_q @ Phi_star.t()).t()    # (N*, K)\n",
    "        q_vec = (Phi_star * temp).sum(dim=1)  # (N*,)\n",
    "        return means, q_vec, V_q\n",
    "\n",
    "    # Sample W ~ MN(M, U_q, V_q)\n",
    "    def sample_W(self, n_samples=1, jitter=1e-8):\n",
    "        \"\"\"\n",
    "        Draw n_samples of W: shape (n_samples, K, C)\n",
    "        Use: W = M + L_u @ Z @ L_v^T, with Z ~ N(0, I_{KxC})\n",
    "        \"\"\"\n",
    "        U_q = self.build_Uq()\n",
    "        V_q = self.build_Vq()\n",
    "        L_u = build_lower_triangular(self.Lu_raw, diag_transform=torch.exp).to(self.device)\n",
    "        L_v = build_lower_triangular(self.Lv_raw, diag_transform=torch.exp).to(self.device)\n",
    "        samples = []\n",
    "        for _ in range(n_samples):\n",
    "            Z = torch.randn(self.K, self.C, device=self.device)\n",
    "            W_s = self.M + L_u @ Z @ L_v.t()\n",
    "            samples.append(W_s.unsqueeze(0))\n",
    "        return torch.cat(samples, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKztnAHR_LMa"
   },
   "source": [
    "# 3. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1767371142924,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "UmQY0EhBTJ5d"
   },
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes=10, device='cpu', dtype=torch.float32):\n",
    "    # labels: Tensor long shape [N]\n",
    "    return F.one_hot(labels.long(), num_classes=num_classes).to(dtype=dtype).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipv8n5U__XN0"
   },
   "source": [
    "## 3.1 Training for one Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1767371142925,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "Q9BMINoITyk1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_onehot = one_hot(y, num_classes=10, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)  # shape [B,10]\n",
    "        loss = F.mse_loss(outputs, y_onehot, reduction='mean')  # mean over batch and outputs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_size = x.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "    return running_loss / total_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmQEXitp_mu1"
   },
   "source": [
    "## 3.2 Evaluation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vud0lKJLuYfm"
   },
   "source": [
    "### 3.2.1 Evaluating Simple Model RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1767371142927,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "-gCsZElD_l7S"
   },
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_rmse(model, dataloader, use_VI=False, device='cpu'):\n",
    "\n",
    "    model.eval()\n",
    "    sqerr_sum = 0.0\n",
    "    total = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_onehot = one_hot(y, num_classes=10, device=device)\n",
    "\n",
    "        if use_VI:\n",
    "            outputs, _ = model.predictive_mean_and_q(x)\n",
    "        else:\n",
    "            outputs = model.forward(x, return_features=False)\n",
    "\n",
    "        sqerr = (outputs - y_onehot).pow(2).sum().item()  # sum over output dims and batch\n",
    "        sqerr_sum += sqerr\n",
    "        total += x.size(0) * 10  # total number of scalar targets counted\n",
    "    mse = sqerr_sum / total\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKNcWoHBudCn"
   },
   "source": [
    "### 3.2.2 Evaluating Full Matrix Normal VI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1767371142928,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "IfJomJYRp8GJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def full_matrix_normal_VI(feature_model, labeled_loader, prior_s=1.0, Sigma=None, vi_lr=1e-3, vi_epochs=500, device='cpu'):\n",
    "    # feature_model: pre-trained MLP. Obtain feature matrix Phi(X)\n",
    "    feats_list = []\n",
    "    Y_list = []\n",
    "    feature_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in labeled_loader:\n",
    "            x = x.to(device)\n",
    "            _, feats = feature_model.forward(x, return_features=True)\n",
    "            feats_list.append(feats.cpu())\n",
    "            Y_list.append(F.one_hot(y, num_classes=10).float())\n",
    "    Phi = torch.cat(feats_list, dim=0).to(device)  # (N, K)\n",
    "    Y = torch.cat(Y_list, dim=0).to(device)        # (N, C)\n",
    "\n",
    "    # Construct the full-MN variational object and fit\n",
    "    K = Phi.shape[1]\n",
    "    C = Y.shape[1]\n",
    "    vm = FullMNVariationalLastLayer(K, C, device=device)\n",
    "    prior = {'M0': torch.zeros(K,C, device=device),\n",
    "            'U0': (1.0/prior_s) * torch.eye(K, device=device),\n",
    "            'V0': torch.eye(C, device=device),\n",
    "            'Sigma': torch.eye(C, device=device) if Sigma is None else Sigma}  # likelihood cov, if known\n",
    "\n",
    "    history = vm.fit_variational(Phi, Y, prior=prior, lr=vi_lr, n_iters=vi_epochs, verbose=True)\n",
    "    return vm, history\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_full_vm_rmse(feature_model, vm, dataloader, use_VI=False, device='cpu'):\n",
    "    feature_model.eval()\n",
    "    sqerr_sum = 0.0\n",
    "    total = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_onehot = one_hot(y, num_classes=10, device=device)\n",
    "\n",
    "        if use_VI:\n",
    "            _, Phi_test = feature_model.forward(x, return_features=True)\n",
    "            outputs, _, _ = vm.predict_mean_and_cov(Phi_test)\n",
    "        else:\n",
    "            outputs = feature_model.forward(x, return_features=False)\n",
    "\n",
    "        sqerr = (outputs - y_onehot).pow(2).sum().item()  # sum over output dims and batch\n",
    "        sqerr_sum += sqerr\n",
    "        total += x.size(0) * 10  # total number of scalar targets counted\n",
    "    mse = sqerr_sum / total\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKUkow4-_rof"
   },
   "source": [
    "## 3.3 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 33520,
     "status": "ok",
     "timestamp": 1767371176449,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "s7f0fcVwT7hL",
    "outputId": "924c5a91-08fe-4dc6-bcf0-9dbd88dfa4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BNN MFVI MLPRegressor Simple...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] train MSE loss=0.109063 | test RMSE = 0.261308\n",
      "[Epoch 05] train MSE loss=0.044326 | test RMSE = 0.188941\n",
      "[Epoch 10] train MSE loss=0.029933 | test RMSE = 0.164581\n",
      "[Epoch 15] train MSE loss=0.024833 | test RMSE = 0.158956\n",
      "[Epoch 20] train MSE loss=0.021116 | test RMSE = 0.155387\n",
      "[Epoch 25] train MSE loss=0.018944 | test RMSE = 0.147996\n",
      "[Epoch 30] train MSE loss=0.016908 | test RMSE = 0.153424\n",
      "[VI epoch 001] ELBO=-6775.4023 | E_log_like=1807.2141 | KL=8582.6162\n",
      "[VI epoch 100] ELBO=-2778.9832 | E_log_like=4017.6794 | KL=6796.6626\n",
      "[VI epoch 200] ELBO=-137.7334 | E_log_like=5618.2910 | KL=5756.0244\n",
      "[VI epoch 300] ELBO=1984.4253 | E_log_like=7473.4048 | KL=5488.9795\n",
      "[VI epoch 400] ELBO=3997.1558 | E_log_like=9431.6494 | KL=5434.4937\n",
      "[VI epoch 500] ELBO=5797.8389 | E_log_like=11237.7520 | KL=5439.9131\n",
      "[VI epoch 600] ELBO=7301.3091 | E_log_like=12777.7598 | KL=5476.4507\n",
      "[VI epoch 700] ELBO=8538.0732 | E_log_like=14067.9863 | KL=5529.9131\n",
      "[VI epoch 800] ELBO=9447.7656 | E_log_like=15042.1240 | KL=5594.3589\n",
      "Final test RMSE: 0.13882237884359294\n"
     ]
    }
   ],
   "source": [
    "#@title Example: Training Loop for Simple Model\n",
    "def train_mlp_baseline(seed=0,\n",
    "                       epochs=20,\n",
    "                       lr=1e-3,\n",
    "                       weight_decay=0.0,\n",
    "                       hidden_sizes=[512,256],\n",
    "                       freeze_features=False,\n",
    "                       batch_train=128,\n",
    "                       batch_eval=256):\n",
    "    set_seed(seed)\n",
    "    #train_dataset, train_loader, test_dataset, test_loader = get_mnist_data(batch_train=batch_train, batch_eval=batch_eval)\n",
    "    train_loader = train_loader_small\n",
    "    model = MFVILastLayerRegressorSimple(input_dim=28*28, hidden_sizes=hidden_sizes, output_dim=10, dropout=0.5, device=device)\n",
    "    \"\"\"if freeze_features:\n",
    "        model.freeze_features()\n",
    "        print(\"Features frozen: only head parameters will be trained.\")\"\"\"\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            rmse = evaluate_rmse(model, test_loader, use_VI=False, device=model.device)\n",
    "            print(f\"[Epoch {epoch:02d}] train MSE loss={loss:.6f} | test RMSE = {rmse:.6f}\")\n",
    "\n",
    "    # Infer model predictive and compute rmse\n",
    "    model.freeze_features()\n",
    "    model.fit_variational(train_loader, prior_s=1.0, sigma_y2=None, lr=5e-3, n_epochs=800)\n",
    "    final_rmse = evaluate_rmse(model, test_loader, use_VI=True, device=model.device)\n",
    "    print(\"Final test RMSE:\", final_rmse)\n",
    "    return model, final_rmse\n",
    "\n",
    "model, rmse = train_mlp_baseline(seed=0, epochs=30, lr=1e-3, weight_decay=0.0,\n",
    "                                 freeze_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 50043,
     "status": "ok",
     "timestamp": 1767371226491,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "ez7e_bvboVZv",
    "outputId": "fcc879e4-f2a2-454b-cd37-d7c0f4b95a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "Training simple feature model:\n",
      "[Epoch 01] train MSE loss=0.109063 | test RMSE = 0.261308\n",
      "[Epoch 05] train MSE loss=0.044326 | test RMSE = 0.188941\n",
      "[Epoch 10] train MSE loss=0.029933 | test RMSE = 0.164581\n",
      "[Epoch 15] train MSE loss=0.024833 | test RMSE = 0.158956\n",
      "[Epoch 20] train MSE loss=0.021116 | test RMSE = 0.155387\n",
      "[Epoch 25] train MSE loss=0.018944 | test RMSE = 0.147996\n",
      "[Epoch 30] train MSE loss=0.016908 | test RMSE = 0.153424\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-363415.4375 exp_ll=-363397.8750 KL=17.5710\n",
      "[VI iter 80/800] ELBO=-95114.5547 exp_ll=-94974.7734 KL=139.7808\n",
      "[VI iter 160/800] ELBO=-60924.0859 exp_ll=-60683.2188 KL=240.8664\n",
      "[VI iter 240/800] ELBO=-47605.7930 exp_ll=-47285.4375 KL=320.3543\n",
      "[VI iter 320/800] ELBO=-40101.3789 exp_ll=-39710.9258 KL=390.4538\n",
      "[VI iter 400/800] ELBO=-35157.6406 exp_ll=-34701.5391 KL=456.1006\n",
      "[VI iter 480/800] ELBO=-31611.6074 exp_ll=-31092.2090 KL=519.3982\n",
      "[VI iter 560/800] ELBO=-28927.9688 exp_ll=-28346.6797 KL=581.2896\n",
      "[VI iter 640/800] ELBO=-26820.6934 exp_ll=-26178.5020 KL=642.1908\n",
      "[VI iter 720/800] ELBO=-25120.5234 exp_ll=-24418.2539 KL=702.2704\n",
      "[VI iter 800/800] ELBO=-23719.8281 exp_ll=-22958.2461 KL=761.5822\n",
      "Final test RMSE: 0.1381055113995065\n"
     ]
    }
   ],
   "source": [
    "#@title Example: Training Loop for Full Matrix Normal VI\n",
    "def train_full_MNVI(seed=0,\n",
    "                    epochs=20,\n",
    "                    lr=1e-3,\n",
    "                    weight_decay=0.0,\n",
    "                    hidden_sizes=[512,256],\n",
    "                    freeze_features=False,\n",
    "                    batch_train=128,\n",
    "                    batch_eval=256):\n",
    "    set_seed(seed)\n",
    "    #train_dataset, train_loader, test_dataset, test_loader = get_mnist_data(batch_train=batch_train, batch_eval=batch_eval)\n",
    "    train_loader = train_loader_small\n",
    "    feature_model = MFVILastLayerRegressorSimple(input_dim=28*28, hidden_sizes=hidden_sizes, output_dim=10, dropout=0.5, device=device)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, feature_model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    print(\"Training simple feature model:\")\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss = train_one_epoch(feature_model, train_loader, optimizer, device)\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            rmse = evaluate_rmse(feature_model, test_loader, use_VI=False, device=feature_model.device)\n",
    "            print(f\"[Epoch {epoch:02d}] train MSE loss={loss:.6f} | test RMSE = {rmse:.6f}\")\n",
    "\n",
    "    # Infer full Variational Matrix Normal posterior approximate\n",
    "    feature_model.freeze_features()\n",
    "    vm, _ = full_matrix_normal_VI(feature_model, train_loader, prior_s=1.0,\n",
    "                                  vi_lr=1e-3, vi_epochs=800, device=feature_model.device)\n",
    "\n",
    "    final_rmse = evaluate_full_vm_rmse(feature_model, vm, test_loader, use_VI=True, device=feature_model.device)\n",
    "    print(\"Final test RMSE:\", final_rmse)\n",
    "    return feature_model, vm, final_rmse\n",
    "\n",
    "feature_model, vm, rmse = train_full_MNVI(seed=0, epochs=30, lr=1e-3, weight_decay=0.0,\n",
    "                                          freeze_features=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyBnpvgsBFFA"
   },
   "source": [
    "### 3.3.3 check accuracy of NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1767371226493,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "b6fab433"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy_from_probs(probs, labels):\n",
    "    preds = probs.argmax(dim=1)   # take the maximum in predicted prob\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_accuracy(model, dataloader, use_VI=False, device='cpu'):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if use_VI:\n",
    "            outputs, _ = model.predictive_mean_and_q(x)\n",
    "        else:\n",
    "            outputs = model.forward(x, return_features=False)\n",
    "\n",
    "        total_correct += (outputs.argmax(dim=1) == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    return total_correct / total_samples\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_full_vm_accuracy(feature_model, vm, dataloader, use_VI=False, device='cpu'):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        if use_VI:\n",
    "            _, Phi_test = feature_model.forward(x, return_features=True)\n",
    "            outputs, _, _ = vm.predict_mean_and_cov(Phi_test)\n",
    "        else:\n",
    "            outputs = feature_model.forward(x, return_features=False)\n",
    "\n",
    "        total_correct += (outputs.argmax(dim=1) == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    return total_correct / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2629,
     "status": "ok",
     "timestamp": 1767371229122,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "7464a133",
    "outputId": "29532aa8-252e-4195-a72a-07961109b7fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9169\n"
     ]
    }
   ],
   "source": [
    "#accuracy = evaluate_accuracy(model, test_loader, use_VI=True, device=model.device)\n",
    "accuracy = evaluate_full_vm_accuracy(feature_model, vm, test_loader, use_VI=True, device=model.device)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFM-TVUEBFFB"
   },
   "source": [
    "# 4. Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6BzMA5qBFFB"
   },
   "source": [
    "## 4.1 Acquisition Function: Predictive Covariance Factor\n",
    "\n",
    "Predictive Covariance is given by $\\Sigma + φ(x^*)^\\top U_q φ(x^*) V_q$. To preserve ranking for acquisition function, we only need to take the scalar q_factor value produced by $φ(x^*)^\\top U_q φ(x^*)\\text{tr}(V_q)$ if $V_q$ is diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1767371229149,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "xPWsMHVZBFFB"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predictive_covar_acquisition(model: nn.Module, pool_dataset: Dataset, pool_indices: list,\n",
    "                                 use_VI=True, batch_size=256, device='cpu', score_type='q'):\n",
    "    \n",
    "    model.eval()\n",
    "    pool_subset = Subset(pool_dataset, pool_indices)\n",
    "    pool_loader = DataLoader(pool_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    qs = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in pool_loader:\n",
    "            x = x.to(device)\n",
    "\n",
    "            if use_VI:\n",
    "                _, q_factor = model.predictive_mean_and_q(x)\n",
    "            else:\n",
    "                q_factor = torch.rand(x.size(0), device=device)\n",
    "\n",
    "            qs.append(q_factor.cpu())\n",
    "    qs = torch.cat(qs, dim=0).numpy()  # shape (len(pool_indices),)\n",
    "\n",
    "    if score_type == 'q':\n",
    "        scores = qs\n",
    "    elif score_type == 'log1p':\n",
    "        scores = np.log1p(qs)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown score_type\")\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuqTGB2M2VpF"
   },
   "source": [
    "### 4.1.2 Full MN VI acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1767371229165,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "6hk6L42y2Z57"
   },
   "outputs": [],
   "source": [
    "def full_mn_predictive_covar_acquisition(feature_model, vm, pool_dataset, pool_indices, use_VI=True,\n",
    "                                         batch_size=256, device=None, score_type='q'):\n",
    "    device = device or vm.device\n",
    "    vm.to(device)\n",
    "    feature_model.eval()\n",
    "    U_q = vm.build_Uq().to(device)\n",
    "    V_q = vm.build_Vq().to(device)\n",
    "    pool_subset = Subset(pool_dataset, pool_indices)\n",
    "    pool_loader = DataLoader(pool_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # compute q for pool in batches\n",
    "    qs = []\n",
    "    with torch.no_grad():\n",
    "        for x,_ in pool_loader:\n",
    "            x = x.to(device)\n",
    "\n",
    "            if use_VI:\n",
    "                _, feats = feature_model.forward(x, return_features=True)\n",
    "                temp = (U_q @ feats.t()).t()\n",
    "                q_factor = (feats * temp).sum(dim=1)  # (B,)\n",
    "            else:\n",
    "                q_factor = torch.rand(x.size(0), device=device)\n",
    "\n",
    "            qs.append(q_factor.cpu())\n",
    "    qs = torch.cat(qs).numpy()\n",
    "    if score_type == 'q':\n",
    "        scores = qs\n",
    "    elif score_type == 'log1p':\n",
    "        scores = np.log1p(qs)\n",
    "    elif score_type == 'logdet':\n",
    "        # compute logdet((1+q)*V_q + Sigma) per sample (heavy)\n",
    "        scores = []\n",
    "        #Sigma = prior['Sigma'].to(device)  # need prior in scope\n",
    "        Sigma = torch.eye(10, device=device) # temporary fixed Sigma\n",
    "        for qi in qs:\n",
    "            cov = Sigma + float(qi) * V_q\n",
    "            sign, ldet = stable_slogdet(cov)\n",
    "            scores.append(ldet.item())\n",
    "        scores = np.array(scores)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weWkBMDKBFFB"
   },
   "source": [
    "## 4.2 Main AL Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1767371277335,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "ToVkljFqO7Vz"
   },
   "outputs": [],
   "source": [
    "# @title Main AL Loop\n",
    "\n",
    "def active_learning_loop(model_ctor,          \n",
    "                         train_dataset,     \n",
    "                         test_dataset,         \n",
    "                         initial_labeled_idxs, \n",
    "                         val_indices=None,    \n",
    "                         pool_subset=None,    \n",
    "                         candidate_pool_size=None,\n",
    "                         n_acq_per_iter=10,\n",
    "                         n_iterations=10,     \n",
    "                         epochs_per_round=50,\n",
    "                         lr=1e-3,\n",
    "                         weight_decay=1e-4,\n",
    "                         T_acq=20,            \n",
    "                         vi_lr=5e-3,\n",
    "                         vi_epochs=800,\n",
    "                         use_VI=True,\n",
    "                         use_full_mn_VI=False,\n",
    "                         batch_train=64,\n",
    "                         batch_pool=256,\n",
    "                         reset_model=True,\n",
    "                         device='cpu',\n",
    "                         seed=0,\n",
    "                         acquisition_fn=predictive_covar_acquisition,\n",
    "                         acquisition_kwargs=None):\n",
    "   \n",
    "    print(\"Training dataset size:\", len(train_dataset))\n",
    "    print(\"Test dataset size:\", len(test_dataset))\n",
    "    print(\"Initial Labelled set size:\", len(initial_labeled_idxs))\n",
    "\n",
    "    set_seed(seed)\n",
    "    acquisition_kwargs = acquisition_kwargs or {}\n",
    "\n",
    "    # L: labelled set (list of indices)\n",
    "    L = list(initial_labeled_idxs[:])\n",
    "    # U: pool indices\n",
    "    all_indices = list(range(len(train_dataset)))\n",
    "    U = [i for i in all_indices if i not in set(L)]\n",
    "    if pool_subset is not None:\n",
    "        U = [i for i in U if i in set(pool_subset)]\n",
    "\n",
    "    model = model_ctor().to(device)\n",
    "    init_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    history = {\n",
    "        'labelled_set_sizes': [len(L)],\n",
    "        'selected_indices_each_iter': [],\n",
    "        'test_rmse': [],\n",
    "        'is_bayesian': True,\n",
    "    }\n",
    "\n",
    "    # main loop \n",
    "    for it in range(n_iterations + 1):\n",
    "        print(f\"\\n=== Acquisition iteration {it} | labelled size = {len(L)} | pool size = {len(U)} ===\")\n",
    "\n",
    "        # 1) Prepare labelled DataLoader\n",
    "        labeled_subset = Subset(train_dataset, L)\n",
    "        labeled_loader = DataLoader(labeled_subset, batch_size=batch_train, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "        # 2) Initialize / reset model\n",
    "        model = model_ctor().to(device)\n",
    "        if reset_model:\n",
    "            model.load_state_dict(init_state)  # ensures same init every round\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        # 3) Train the model on current labelled set\n",
    "        for epoch in range(epochs_per_round):\n",
    "            loss = train_one_epoch(model, labeled_loader, optimizer, device)\n",
    "\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "                rmse = evaluate_rmse(model, test_loader, use_VI=False, device=model.device)\n",
    "                print(f\"[Train epoch {epoch+1}/{epochs_per_round}] loss={loss:.6f}, train_rmse={rmse:.6f}\")\n",
    "\n",
    "\n",
    "        # 4) Evaluate on test set using appropriate method\n",
    "        if use_VI:\n",
    "            if use_full_mn_VI:\n",
    "                model.freeze_features()\n",
    "                vm, _ = full_matrix_normal_VI(model, labeled_loader, prior_s=1e-3,\n",
    "                                              vi_lr=vi_lr, vi_epochs=vi_epochs, device=model.device)\n",
    "            else:\n",
    "                # Infer model predictive and compute rmse\n",
    "                model.freeze_features()\n",
    "                model.fit_variational(labeled_loader, prior_s=1.0, sigma_y2=None, lr=vi_lr, n_epochs=vi_epochs)\n",
    "\n",
    "        final_rmse = evaluate_rmse(model, test_loader, use_VI=use_VI, device=model.device)\n",
    "        print(\"Final test RMSE:\", final_rmse)\n",
    "\n",
    "        history['test_rmse'].append(final_rmse)\n",
    "\n",
    "        # Stop condition\n",
    "        if it == n_iterations:\n",
    "            break\n",
    "\n",
    "        # 5) Compute acquisition scores on pool U using passed-in acquisition function\n",
    "        print(f\"Computing acquisition scores on pool (subsample size: {candidate_pool_size})\")\n",
    "\n",
    "        if candidate_pool_size is None or candidate_pool_size >= len(U):\n",
    "            candidate_indices = list(U)   # score full pool (fallback)\n",
    "        else:\n",
    "            # sample uniformly from U (reproducible controlled by set_seed(seed) earlier)\n",
    "            candidate_indices = random.sample(U, k=min(candidate_pool_size, len(U)))\n",
    "\n",
    "        # call acquisition on the candidate subset only (indices refer to full dataset)\n",
    "        if use_full_mn_VI:\n",
    "            scores_on_candidates = full_mn_predictive_covar_acquisition(model, vm, train_dataset, pool_indices=candidate_indices, use_VI=use_VI, **acquisition_kwargs)\n",
    "        else:\n",
    "            scores_on_candidates = acquisition_fn(model, train_dataset, pool_indices=candidate_indices, use_VI=use_VI, **acquisition_kwargs)\n",
    "        scores_on_candidates = np.asarray(scores_on_candidates)\n",
    "        # Now pick top-k from candidates\n",
    "        k = min(n_acq_per_iter, len(candidate_indices))\n",
    "        topk_idx_in_candidates = np.argpartition(-scores_on_candidates, k-1)[:k]\n",
    "        topk_sorted = topk_idx_in_candidates[np.argsort(-scores_on_candidates[topk_idx_in_candidates])]\n",
    "        selected_indices = [candidate_indices[i] for i in topk_sorted.tolist()]\n",
    "\n",
    "        # 6) Update sets: move selected from U -> L\n",
    "        for s in selected_indices:\n",
    "            L.append(s)\n",
    "            U.remove(s)\n",
    "\n",
    "        history['labelled_set_sizes'].append(len(L))\n",
    "        history['selected_indices_each_iter'].append(selected_indices)\n",
    "\n",
    "        with open('outputs/history_BNN_intermediate.json', 'w') as f:\n",
    "            json.dump(history, f)\n",
    "\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1767371694435,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "tX4kIDdkBFFB"
   },
   "outputs": [],
   "source": [
    "#@title Config for BNN MFVI\n",
    "def make_model():\n",
    "    return MFVILastLayerRegressorSimple(input_dim=28*28, hidden_sizes=[512, 256], output_dim=10, dropout=0.5, device=device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "acq_functions = [full_mn_predictive_covar_acquisition]\n",
    "acq_names = [\"PredCovariance\"]\n",
    "model_names = [\"BNN_MFVI_full\"]\n",
    "output_dir = \"outputs/bnn_mfvi/\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset, train_loader_full, test_dataset, test_loader = get_mnist_data()\n",
    "#train_dataset_small = Subset(train_dataset, range(1000))\n",
    "#test_dataset_small = Subset(test_dataset, range(1000))\n",
    "train_dataset_to_use = train_dataset\n",
    "test_dataset_to_use = test_dataset\n",
    "\n",
    "# Training Hyperparameters\n",
    "n_iterations = 100  # Number of AL runs\n",
    "T_acq = 20   \n",
    "vi_lr = 5e-3\n",
    "vi_epochs = 800\n",
    "epochs_per_round = 50\n",
    "score_type = 'q'\n",
    "use_VI = True\n",
    "use_full_mn_VI = True\n",
    "candidate_pool_size = 2000  \n",
    "seeds = [0, 1, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19250979,
     "status": "ok",
     "timestamp": 1767390947530,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "-w6Om2mxBFFB",
    "outputId": "724fa5fa-1c1c-4f65-ef48-8faf3259a2ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========== Running PredCovariance Seed 0 ==========\n",
      "Training dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "Initial Labelled set size: 20\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "\n",
      "=== Acquisition iteration 0 | labelled size = 20 | pool size = 59980 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "[VI iter 320/800] ELBO=-13301.1055 exp_ll=-4177.7021 KL=9123.4033\n",
      "[VI iter 400/800] ELBO=-13125.4551 exp_ll=-3932.2720 KL=9193.1836\n",
      "[VI iter 480/800] ELBO=-13010.1006 exp_ll=-3780.6650 KL=9229.4355\n",
      "[VI iter 560/800] ELBO=-12926.3730 exp_ll=-3683.8794 KL=9242.4932\n",
      "[VI iter 640/800] ELBO=-12860.9971 exp_ll=-3621.2529 KL=9239.7441\n",
      "[VI iter 720/800] ELBO=-12807.2402 exp_ll=-3580.7012 KL=9226.5391\n",
      "[VI iter 800/800] ELBO=-12761.3926 exp_ll=-3554.6555 KL=9206.7373\n",
      "Final test RMSE: 0.19826628771783972\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 24 | labelled size = 260 | pool size = 59740 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.173662, train_rmse=0.293519\n",
      "[Train epoch 5/50] loss=0.072308, train_rmse=0.272184\n",
      "[Train epoch 10/50] loss=0.054456, train_rmse=0.252084\n",
      "[Train epoch 15/50] loss=0.045722, train_rmse=0.235663\n",
      "[Train epoch 20/50] loss=0.040420, train_rmse=0.224443\n",
      "[Train epoch 25/50] loss=0.033169, train_rmse=0.218907\n",
      "[Train epoch 30/50] loss=0.031533, train_rmse=0.215623\n",
      "[Train epoch 35/50] loss=0.026675, train_rmse=0.205941\n",
      "[Train epoch 40/50] loss=0.026099, train_rmse=0.213226\n",
      "[Train epoch 45/50] loss=0.022668, train_rmse=0.201007\n",
      "[Train epoch 50/50] loss=0.023262, train_rmse=0.207305\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-82960.1719 exp_ll=-75389.0703 KL=7571.1011\n",
      "[VI iter 80/800] ELBO=-16583.3867 exp_ll=-8047.2368 KL=8536.1494\n",
      "[VI iter 160/800] ELBO=-14584.9805 exp_ll=-5727.4922 KL=8857.4883\n",
      "[VI iter 240/800] ELBO=-13895.3711 exp_ll=-4851.6934 KL=9043.6777\n",
      "[VI iter 320/800] ELBO=-13560.0957 exp_ll=-4400.2539 KL=9159.8418\n",
      "[VI iter 400/800] ELBO=-13367.4297 exp_ll=-4135.6782 KL=9231.7520\n",
      "[VI iter 480/800] ELBO=-13243.6367 exp_ll=-3969.5139 KL=9274.1230\n",
      "[VI iter 560/800] ELBO=-13157.2471 exp_ll=-3860.8135 KL=9296.4336\n",
      "[VI iter 640/800] ELBO=-13092.9775 exp_ll=-3787.8955 KL=9305.0820\n",
      "[VI iter 720/800] ELBO=-13042.8105 exp_ll=-3738.3088 KL=9304.5020\n",
      "[VI iter 800/800] ELBO=-13002.2002 exp_ll=-3704.3948 KL=9297.8057\n",
      "Final test RMSE: 0.20730485805794135\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 25 | labelled size = 270 | pool size = 59730 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.171918, train_rmse=0.291796\n",
      "[Train epoch 5/50] loss=0.070269, train_rmse=0.267961\n",
      "[Train epoch 10/50] loss=0.050745, train_rmse=0.237818\n",
      "[Train epoch 15/50] loss=0.039904, train_rmse=0.222803\n",
      "[Train epoch 20/50] loss=0.032235, train_rmse=0.212012\n",
      "[Train epoch 25/50] loss=0.027797, train_rmse=0.205261\n",
      "[Train epoch 30/50] loss=0.023694, train_rmse=0.202375\n",
      "[Train epoch 35/50] loss=0.020141, train_rmse=0.201824\n",
      "[Train epoch 40/50] loss=0.019965, train_rmse=0.203252\n",
      "[Train epoch 45/50] loss=0.018889, train_rmse=0.206807\n",
      "[Train epoch 50/50] loss=0.014607, train_rmse=0.200799\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-87333.1797 exp_ll=-79777.1797 KL=7556.0020\n",
      "[VI iter 80/800] ELBO=-16142.7197 exp_ll=-7634.6025 KL=8508.1172\n",
      "[VI iter 160/800] ELBO=-14375.8271 exp_ll=-5516.9912 KL=8858.8359\n",
      "[VI iter 240/800] ELBO=-13802.7578 exp_ll=-4733.1543 KL=9069.6035\n",
      "[VI iter 320/800] ELBO=-13538.5469 exp_ll=-4336.5337 KL=9202.0137\n",
      "[VI iter 400/800] ELBO=-13391.0527 exp_ll=-4107.3003 KL=9283.7520\n",
      "[VI iter 480/800] ELBO=-13296.5645 exp_ll=-3965.3906 KL=9331.1738\n",
      "[VI iter 560/800] ELBO=-13229.1865 exp_ll=-3874.1895 KL=9354.9971\n",
      "[VI iter 640/800] ELBO=-13177.4141 exp_ll=-3814.7837 KL=9362.6309\n",
      "[VI iter 720/800] ELBO=-13135.4541 exp_ll=-3776.0911 KL=9359.3633\n",
      "[VI iter 800/800] ELBO=-13100.1270 exp_ll=-3751.1196 KL=9349.0068\n",
      "Final test RMSE: 0.2007988992852746\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 26 | labelled size = 280 | pool size = 59720 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.176161, train_rmse=0.293883\n",
      "[Train epoch 5/50] loss=0.068958, train_rmse=0.269895\n",
      "[Train epoch 10/50] loss=0.051455, train_rmse=0.238272\n",
      "[Train epoch 15/50] loss=0.036682, train_rmse=0.220184\n",
      "[Train epoch 20/50] loss=0.031801, train_rmse=0.209589\n",
      "[Train epoch 25/50] loss=0.024985, train_rmse=0.205153\n",
      "[Train epoch 30/50] loss=0.020632, train_rmse=0.197124\n",
      "[Train epoch 35/50] loss=0.020788, train_rmse=0.198771\n",
      "[Train epoch 40/50] loss=0.018893, train_rmse=0.200189\n",
      "[Train epoch 45/50] loss=0.017292, train_rmse=0.195743\n",
      "[Train epoch 50/50] loss=0.017168, train_rmse=0.200822\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-95547.9062 exp_ll=-87985.6406 KL=7562.2671\n",
      "[VI iter 80/800] ELBO=-16865.8438 exp_ll=-8369.6504 KL=8496.1943\n",
      "[VI iter 160/800] ELBO=-14833.3945 exp_ll=-5990.3906 KL=8843.0039\n",
      "[VI iter 240/800] ELBO=-14130.5518 exp_ll=-5079.1484 KL=9051.4033\n",
      "[VI iter 320/800] ELBO=-13792.0225 exp_ll=-4607.8174 KL=9184.2051\n",
      "[VI iter 400/800] ELBO=-13599.5273 exp_ll=-4330.6812 KL=9268.8457\n",
      "[VI iter 480/800] ELBO=-13476.9893 exp_ll=-4156.1279 KL=9320.8613\n",
      "[VI iter 560/800] ELBO=-13391.8682 exp_ll=-4041.6768 KL=9350.1914\n",
      "[VI iter 640/800] ELBO=-13328.5332 exp_ll=-3964.9126 KL=9363.6201\n",
      "[VI iter 720/800] ELBO=-13279.0039 exp_ll=-3913.0259 KL=9365.9775\n",
      "[VI iter 800/800] ELBO=-13238.7676 exp_ll=-3877.9829 KL=9360.7842\n",
      "Final test RMSE: 0.20082154166426633\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 27 | labelled size = 290 | pool size = 59710 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.169243, train_rmse=0.292840\n",
      "[Train epoch 5/50] loss=0.067645, train_rmse=0.262927\n",
      "[Train epoch 10/50] loss=0.048227, train_rmse=0.228011\n",
      "[Train epoch 15/50] loss=0.036645, train_rmse=0.212664\n",
      "[Train epoch 20/50] loss=0.028392, train_rmse=0.200532\n",
      "[Train epoch 25/50] loss=0.025322, train_rmse=0.196230\n",
      "[Train epoch 30/50] loss=0.020624, train_rmse=0.193080\n",
      "[Train epoch 35/50] loss=0.019920, train_rmse=0.194615\n",
      "[Train epoch 40/50] loss=0.020013, train_rmse=0.191854\n",
      "[Train epoch 45/50] loss=0.017916, train_rmse=0.194000\n",
      "[Train epoch 50/50] loss=0.015320, train_rmse=0.193312\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-94603.4062 exp_ll=-87034.4844 KL=7568.9204\n",
      "[VI iter 80/800] ELBO=-16558.0430 exp_ll=-8065.2256 KL=8492.8184\n",
      "[VI iter 160/800] ELBO=-14755.9805 exp_ll=-5912.8330 KL=8843.1475\n",
      "[VI iter 240/800] ELBO=-14127.7773 exp_ll=-5069.0737 KL=9058.7031\n",
      "[VI iter 320/800] ELBO=-13827.2012 exp_ll=-4630.1646 KL=9197.0361\n",
      "[VI iter 400/800] ELBO=-13657.8369 exp_ll=-4372.6299 KL=9285.2070\n",
      "[VI iter 480/800] ELBO=-13550.4980 exp_ll=-4211.4023 KL=9339.0957\n",
      "[VI iter 560/800] ELBO=-13475.9688 exp_ll=-4106.8647 KL=9369.1045\n",
      "[VI iter 640/800] ELBO=-13420.4082 exp_ll=-4037.9038 KL=9382.5049\n",
      "[VI iter 720/800] ELBO=-13376.6709 exp_ll=-3992.1279 KL=9384.5430\n",
      "[VI iter 800/800] ELBO=-13340.9824 exp_ll=-3961.9526 KL=9379.0303\n",
      "Final test RMSE: 0.1933116847803321\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 28 | labelled size = 300 | pool size = 59700 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.165898, train_rmse=0.289513\n",
      "[Train epoch 5/50] loss=0.067534, train_rmse=0.263506\n",
      "[Train epoch 10/50] loss=0.047834, train_rmse=0.226634\n",
      "[Train epoch 15/50] loss=0.036155, train_rmse=0.209562\n",
      "[Train epoch 20/50] loss=0.030294, train_rmse=0.199622\n",
      "[Train epoch 25/50] loss=0.024697, train_rmse=0.198304\n",
      "[Train epoch 30/50] loss=0.021905, train_rmse=0.197775\n",
      "[Train epoch 35/50] loss=0.019424, train_rmse=0.193790\n",
      "[Train epoch 40/50] loss=0.017271, train_rmse=0.191082\n",
      "[Train epoch 45/50] loss=0.015778, train_rmse=0.189765\n",
      "[Train epoch 50/50] loss=0.013711, train_rmse=0.194303\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-94558.3516 exp_ll=-87000.1094 KL=7558.2397\n",
      "[VI iter 80/800] ELBO=-16689.4922 exp_ll=-8205.7871 KL=8483.7061\n",
      "[VI iter 160/800] ELBO=-14853.1709 exp_ll=-6024.1484 KL=8829.0225\n",
      "[VI iter 240/800] ELBO=-14220.1758 exp_ll=-5176.2300 KL=9043.9453\n",
      "[VI iter 320/800] ELBO=-13919.7812 exp_ll=-4735.0371 KL=9184.7441\n",
      "[VI iter 400/800] ELBO=-13752.0918 exp_ll=-4475.4097 KL=9276.6816\n",
      "[VI iter 480/800] ELBO=-13646.7285 exp_ll=-4311.9155 KL=9334.8135\n",
      "[VI iter 560/800] ELBO=-13574.3945 exp_ll=-4205.1968 KL=9369.1982\n",
      "[VI iter 640/800] ELBO=-13520.9580 exp_ll=-4134.0889 KL=9386.8691\n",
      "[VI iter 720/800] ELBO=-13479.1855 exp_ll=-4086.3159 KL=9392.8691\n",
      "[VI iter 800/800] ELBO=-13445.2715 exp_ll=-4054.4138 KL=9390.8574\n",
      "Final test RMSE: 0.19430260902965873\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 29 | labelled size = 310 | pool size = 59690 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.169837, train_rmse=0.288811\n",
      "[Train epoch 5/50] loss=0.069291, train_rmse=0.261800\n",
      "[Train epoch 10/50] loss=0.048708, train_rmse=0.227822\n",
      "[Train epoch 15/50] loss=0.035663, train_rmse=0.207039\n",
      "[Train epoch 20/50] loss=0.028561, train_rmse=0.197519\n",
      "[Train epoch 25/50] loss=0.023645, train_rmse=0.195837\n",
      "[Train epoch 30/50] loss=0.019554, train_rmse=0.190692\n",
      "[Train epoch 35/50] loss=0.017909, train_rmse=0.191058\n",
      "[Train epoch 40/50] loss=0.015296, train_rmse=0.194904\n",
      "[Train epoch 45/50] loss=0.016976, train_rmse=0.192828\n",
      "[Train epoch 50/50] loss=0.014965, train_rmse=0.190522\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-98629.7656 exp_ll=-91073.6797 KL=7556.0840\n",
      "[VI iter 80/800] ELBO=-16878.9746 exp_ll=-8412.2520 KL=8466.7227\n",
      "[VI iter 160/800] ELBO=-15014.3027 exp_ll=-6197.3721 KL=8816.9307\n",
      "[VI iter 240/800] ELBO=-14378.7656 exp_ll=-5336.0854 KL=9042.6807\n",
      "[VI iter 320/800] ELBO=-14074.5527 exp_ll=-4880.6050 KL=9193.9473\n",
      "[VI iter 400/800] ELBO=-13903.3145 exp_ll=-4608.6299 KL=9294.6846\n",
      "[VI iter 480/800] ELBO=-13795.5918 exp_ll=-4435.8491 KL=9359.7432\n",
      "[VI iter 560/800] ELBO=-13721.6758 exp_ll=-4322.3608 KL=9399.3154\n",
      "[VI iter 640/800] ELBO=-13667.5488 exp_ll=-4246.7979 KL=9420.7510\n",
      "[VI iter 720/800] ELBO=-13625.3926 exp_ll=-4195.9243 KL=9429.4678\n",
      "[VI iter 800/800] ELBO=-13591.3535 exp_ll=-4161.8423 KL=9429.5107\n",
      "Final test RMSE: 0.19052197933808288\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 30 | labelled size = 320 | pool size = 59680 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.166751, train_rmse=0.295563\n",
      "[Train epoch 5/50] loss=0.067977, train_rmse=0.267430\n",
      "[Train epoch 10/50] loss=0.050204, train_rmse=0.230146\n",
      "[Train epoch 15/50] loss=0.036418, train_rmse=0.207456\n",
      "[Train epoch 20/50] loss=0.030270, train_rmse=0.200988\n",
      "[Train epoch 25/50] loss=0.024630, train_rmse=0.200191\n",
      "[Train epoch 30/50] loss=0.021776, train_rmse=0.199811\n",
      "[Train epoch 35/50] loss=0.018310, train_rmse=0.190417\n",
      "[Train epoch 40/50] loss=0.015749, train_rmse=0.189283\n",
      "[Train epoch 45/50] loss=0.016655, train_rmse=0.191202\n",
      "[Train epoch 50/50] loss=0.015083, train_rmse=0.190892\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-99841.2422 exp_ll=-92265.4922 KL=7575.7476\n",
      "[VI iter 80/800] ELBO=-17397.7227 exp_ll=-8888.6826 KL=8509.0400\n",
      "[VI iter 160/800] ELBO=-15299.3066 exp_ll=-6421.0791 KL=8878.2275\n",
      "[VI iter 240/800] ELBO=-14603.7070 exp_ll=-5490.5249 KL=9113.1826\n",
      "[VI iter 320/800] ELBO=-14281.3438 exp_ll=-5009.8477 KL=9271.4961\n",
      "[VI iter 400/800] ELBO=-14105.3018 exp_ll=-4726.5400 KL=9378.7617\n",
      "[VI iter 480/800] ELBO=-13997.3672 exp_ll=-4547.4668 KL=9449.9004\n",
      "[VI iter 560/800] ELBO=-13924.4766 exp_ll=-4429.6050 KL=9494.8711\n",
      "[VI iter 640/800] ELBO=-13871.5049 exp_ll=-4350.6562 KL=9520.8486\n",
      "[VI iter 720/800] ELBO=-13830.5742 exp_ll=-4297.3691 KL=9533.2051\n",
      "[VI iter 800/800] ELBO=-13797.5977 exp_ll=-4261.5684 KL=9536.0293\n",
      "Final test RMSE: 0.19089226988962463\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 31 | labelled size = 330 | pool size = 59670 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.166868, train_rmse=0.290211\n",
      "[Train epoch 5/50] loss=0.067611, train_rmse=0.259466\n",
      "[Train epoch 10/50] loss=0.052786, train_rmse=0.225891\n",
      "[Train epoch 15/50] loss=0.040118, train_rmse=0.211963\n",
      "[Train epoch 20/50] loss=0.032392, train_rmse=0.202392\n",
      "[Train epoch 25/50] loss=0.027909, train_rmse=0.198833\n",
      "[Train epoch 30/50] loss=0.024769, train_rmse=0.202049\n",
      "[Train epoch 35/50] loss=0.021167, train_rmse=0.189944\n",
      "[Train epoch 40/50] loss=0.020562, train_rmse=0.194367\n",
      "[Train epoch 45/50] loss=0.017958, train_rmse=0.192888\n",
      "[Train epoch 50/50] loss=0.016740, train_rmse=0.185822\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-111303.3750 exp_ll=-103740.6328 KL=7562.7383\n",
      "[VI iter 80/800] ELBO=-18205.3516 exp_ll=-9694.3711 KL=8510.9805\n",
      "[VI iter 160/800] ELBO=-15862.1699 exp_ll=-6972.0747 KL=8890.0957\n",
      "[VI iter 240/800] ELBO=-15043.6357 exp_ll=-5905.4639 KL=9138.1719\n",
      "[VI iter 320/800] ELBO=-14651.6406 exp_ll=-5341.5894 KL=9310.0508\n",
      "[VI iter 400/800] ELBO=-14433.9375 exp_ll=-5002.7231 KL=9431.2139\n",
      "[VI iter 480/800] ELBO=-14300.7900 exp_ll=-4784.0977 KL=9516.6924\n",
      "[VI iter 560/800] ELBO=-14213.1816 exp_ll=-4636.8525 KL=9576.3291\n",
      "[VI iter 640/800] ELBO=-14151.9531 exp_ll=-4534.9795 KL=9616.9736\n",
      "[VI iter 720/800] ELBO=-14107.1328 exp_ll=-4463.5425 KL=9643.5908\n",
      "[VI iter 800/800] ELBO=-14072.4170 exp_ll=-4412.5518 KL=9659.8652\n",
      "Final test RMSE: 0.18582240609542705\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 32 | labelled size = 340 | pool size = 59660 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.163640, train_rmse=0.292427\n",
      "[Train epoch 5/50] loss=0.069055, train_rmse=0.260454\n",
      "[Train epoch 10/50] loss=0.048623, train_rmse=0.225558\n",
      "[Train epoch 15/50] loss=0.036318, train_rmse=0.206051\n",
      "[Train epoch 20/50] loss=0.029219, train_rmse=0.198996\n",
      "[Train epoch 25/50] loss=0.024584, train_rmse=0.197522\n",
      "[Train epoch 30/50] loss=0.022405, train_rmse=0.198323\n",
      "[Train epoch 35/50] loss=0.019300, train_rmse=0.193132\n",
      "[Train epoch 40/50] loss=0.018396, train_rmse=0.191425\n",
      "[Train epoch 45/50] loss=0.017516, train_rmse=0.189012\n",
      "[Train epoch 50/50] loss=0.016272, train_rmse=0.193367\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-103929.8594 exp_ll=-96372.3984 KL=7557.4634\n",
      "[VI iter 80/800] ELBO=-17464.6797 exp_ll=-8970.2432 KL=8494.4365\n",
      "[VI iter 160/800] ELBO=-15478.7002 exp_ll=-6622.0742 KL=8856.6260\n",
      "[VI iter 240/800] ELBO=-14808.6309 exp_ll=-5719.1074 KL=9089.5234\n",
      "[VI iter 320/800] ELBO=-14490.6113 exp_ll=-5243.0850 KL=9247.5264\n",
      "[VI iter 400/800] ELBO=-14312.9414 exp_ll=-4957.5220 KL=9355.4199\n",
      "[VI iter 480/800] ELBO=-14202.3848 exp_ll=-4774.3506 KL=9428.0342\n",
      "[VI iter 560/800] ELBO=-14127.4824 exp_ll=-4652.1382 KL=9475.3438\n",
      "[VI iter 640/800] ELBO=-14073.4375 exp_ll=-4568.9600 KL=9504.4775\n",
      "[VI iter 720/800] ELBO=-14032.3848 exp_ll=-4511.7075 KL=9520.6777\n",
      "[VI iter 800/800] ELBO=-13999.9883 exp_ll=-4472.1519 KL=9527.8369\n",
      "Final test RMSE: 0.1933668951494936\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 33 | labelled size = 350 | pool size = 59650 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.159867, train_rmse=0.289013\n",
      "[Train epoch 5/50] loss=0.067865, train_rmse=0.257616\n",
      "[Train epoch 10/50] loss=0.049250, train_rmse=0.222078\n",
      "[Train epoch 15/50] loss=0.034037, train_rmse=0.205584\n",
      "[Train epoch 20/50] loss=0.029105, train_rmse=0.195538\n",
      "[Train epoch 25/50] loss=0.025356, train_rmse=0.197820\n",
      "[Train epoch 30/50] loss=0.019691, train_rmse=0.190416\n",
      "[Train epoch 35/50] loss=0.018270, train_rmse=0.192926\n",
      "[Train epoch 40/50] loss=0.016162, train_rmse=0.189265\n",
      "[Train epoch 45/50] loss=0.014989, train_rmse=0.184860\n",
      "[Train epoch 50/50] loss=0.016374, train_rmse=0.187006\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-109538.4922 exp_ll=-101978.1328 KL=7560.3604\n",
      "[VI iter 80/800] ELBO=-18011.7656 exp_ll=-9525.0381 KL=8486.7275\n",
      "[VI iter 160/800] ELBO=-15827.5488 exp_ll=-6967.6475 KL=8859.9014\n",
      "[VI iter 240/800] ELBO=-15077.9170 exp_ll=-5972.6650 KL=9105.2520\n",
      "[VI iter 320/800] ELBO=-14720.8320 exp_ll=-5445.2563 KL=9275.5762\n",
      "[VI iter 400/800] ELBO=-14522.1602 exp_ll=-5127.2798 KL=9394.8799\n",
      "[VI iter 480/800] ELBO=-14399.9707 exp_ll=-4922.2671 KL=9477.7031\n",
      "[VI iter 560/800] ELBO=-14318.9541 exp_ll=-4784.9717 KL=9533.9824\n",
      "[VI iter 640/800] ELBO=-14261.7314 exp_ll=-4690.8574 KL=9570.8740\n",
      "[VI iter 720/800] ELBO=-14219.1270 exp_ll=-4625.4712 KL=9593.6562\n",
      "[VI iter 800/800] ELBO=-14186.1465 exp_ll=-4579.8711 KL=9606.2754\n",
      "Final test RMSE: 0.18700591690983884\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 34 | labelled size = 360 | pool size = 59640 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.166021, train_rmse=0.291058\n",
      "[Train epoch 5/50] loss=0.066926, train_rmse=0.258030\n",
      "[Train epoch 10/50] loss=0.046495, train_rmse=0.220891\n",
      "[Train epoch 15/50] loss=0.035910, train_rmse=0.205247\n",
      "[Train epoch 20/50] loss=0.026361, train_rmse=0.194147\n",
      "[Train epoch 25/50] loss=0.022340, train_rmse=0.192957\n",
      "[Train epoch 30/50] loss=0.021581, train_rmse=0.186663\n",
      "[Train epoch 35/50] loss=0.018568, train_rmse=0.190472\n",
      "[Train epoch 40/50] loss=0.018124, train_rmse=0.190505\n",
      "[Train epoch 45/50] loss=0.016932, train_rmse=0.190074\n",
      "[Train epoch 50/50] loss=0.016953, train_rmse=0.192573\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-107960.0547 exp_ll=-100402.5625 KL=7557.4897\n",
      "[VI iter 80/800] ELBO=-18084.1602 exp_ll=-9592.5039 KL=8491.6553\n",
      "[VI iter 160/800] ELBO=-15897.1191 exp_ll=-7039.7715 KL=8857.3477\n",
      "[VI iter 240/800] ELBO=-15147.9219 exp_ll=-6052.8711 KL=9095.0508\n",
      "[VI iter 320/800] ELBO=-14789.1943 exp_ll=-5530.6533 KL=9258.5410\n",
      "[VI iter 400/800] ELBO=-14588.6914 exp_ll=-5216.6104 KL=9372.0811\n",
      "[VI iter 480/800] ELBO=-14464.6914 exp_ll=-5014.4858 KL=9450.2061\n",
      "[VI iter 560/800] ELBO=-14381.8145 exp_ll=-4879.1167 KL=9502.6973\n",
      "[VI iter 640/800] ELBO=-14322.5605 exp_ll=-4786.0498 KL=9536.5107\n",
      "[VI iter 720/800] ELBO=-14278.0967 exp_ll=-4721.3486 KL=9556.7480\n",
      "[VI iter 800/800] ELBO=-14243.2812 exp_ll=-4676.0664 KL=9567.2148\n",
      "Final test RMSE: 0.19257259657161152\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 35 | labelled size = 370 | pool size = 59630 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.154271, train_rmse=0.291071\n",
      "[Train epoch 5/50] loss=0.066319, train_rmse=0.255052\n",
      "[Train epoch 10/50] loss=0.048140, train_rmse=0.223098\n",
      "[Train epoch 15/50] loss=0.037425, train_rmse=0.209056\n",
      "[Train epoch 20/50] loss=0.027188, train_rmse=0.198150\n",
      "[Train epoch 25/50] loss=0.025589, train_rmse=0.191361\n",
      "[Train epoch 30/50] loss=0.022010, train_rmse=0.192333\n",
      "[Train epoch 35/50] loss=0.019954, train_rmse=0.189312\n",
      "[Train epoch 40/50] loss=0.017515, train_rmse=0.192790\n",
      "[Train epoch 45/50] loss=0.016466, train_rmse=0.185303\n",
      "[Train epoch 50/50] loss=0.016140, train_rmse=0.191809\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-109289.8750 exp_ll=-101709.9062 KL=7579.9678\n",
      "[VI iter 80/800] ELBO=-18443.6934 exp_ll=-9910.6797 KL=8533.0137\n",
      "[VI iter 160/800] ELBO=-16154.4639 exp_ll=-7231.3799 KL=8923.0840\n",
      "[VI iter 240/800] ELBO=-15365.9414 exp_ll=-6189.6934 KL=9176.2480\n",
      "[VI iter 320/800] ELBO=-14996.0117 exp_ll=-5646.3271 KL=9349.6846\n",
      "[VI iter 400/800] ELBO=-14794.3369 exp_ll=-5323.9453 KL=9470.3916\n",
      "[VI iter 480/800] ELBO=-14672.3691 exp_ll=-5118.0835 KL=9554.2861\n",
      "[VI iter 560/800] ELBO=-14592.2861 exp_ll=-4980.5732 KL=9611.7129\n",
      "[VI iter 640/800] ELBO=-14536.0879 exp_ll=-4886.2456 KL=9649.8418\n",
      "[VI iter 720/800] ELBO=-14494.5332 exp_ll=-4820.6577 KL=9673.8750\n",
      "[VI iter 800/800] ELBO=-14462.1660 exp_ll=-4774.4722 KL=9687.6934\n",
      "Final test RMSE: 0.19180887590143672\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 36 | labelled size = 380 | pool size = 59620 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.156684, train_rmse=0.289882\n",
      "[Train epoch 5/50] loss=0.069224, train_rmse=0.261397\n",
      "[Train epoch 10/50] loss=0.050060, train_rmse=0.224185\n",
      "[Train epoch 15/50] loss=0.035528, train_rmse=0.203992\n",
      "[Train epoch 20/50] loss=0.028127, train_rmse=0.197921\n",
      "[Train epoch 25/50] loss=0.022474, train_rmse=0.191534\n",
      "[Train epoch 30/50] loss=0.019964, train_rmse=0.183588\n",
      "[Train epoch 35/50] loss=0.018288, train_rmse=0.192541\n",
      "[Train epoch 40/50] loss=0.016753, train_rmse=0.185789\n",
      "[Train epoch 45/50] loss=0.014463, train_rmse=0.187853\n",
      "[Train epoch 50/50] loss=0.014275, train_rmse=0.188032\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-112199.7656 exp_ll=-104633.7266 KL=7566.0425\n",
      "[VI iter 80/800] ELBO=-18240.0430 exp_ll=-9751.0605 KL=8488.9824\n",
      "[VI iter 160/800] ELBO=-16109.5801 exp_ll=-7255.9326 KL=8853.6475\n",
      "[VI iter 240/800] ELBO=-15368.0137 exp_ll=-6270.9395 KL=9097.0742\n",
      "[VI iter 320/800] ELBO=-15015.6777 exp_ll=-5746.5293 KL=9269.1484\n",
      "[VI iter 400/800] ELBO=-14820.9873 exp_ll=-5428.5322 KL=9392.4551\n",
      "[VI iter 480/800] ELBO=-14702.5068 exp_ll=-5222.0234 KL=9480.4834\n",
      "[VI iter 560/800] ELBO=-14625.0020 exp_ll=-5082.5532 KL=9542.4482\n",
      "[VI iter 640/800] ELBO=-14570.9883 exp_ll=-4985.9380 KL=9585.0498\n",
      "[VI iter 720/800] ELBO=-14531.4922 exp_ll=-4918.1890 KL=9613.3027\n",
      "[VI iter 800/800] ELBO=-14501.3389 exp_ll=-4870.3320 KL=9631.0068\n",
      "Final test RMSE: 0.18803156868956916\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 37 | labelled size = 390 | pool size = 59610 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.147310, train_rmse=0.284973\n",
      "[Train epoch 5/50] loss=0.067881, train_rmse=0.253066\n",
      "[Train epoch 10/50] loss=0.052971, train_rmse=0.226121\n",
      "[Train epoch 15/50] loss=0.038157, train_rmse=0.202030\n",
      "[Train epoch 20/50] loss=0.034231, train_rmse=0.194685\n",
      "[Train epoch 25/50] loss=0.029234, train_rmse=0.197998\n",
      "[Train epoch 30/50] loss=0.024911, train_rmse=0.186468\n",
      "[Train epoch 35/50] loss=0.023882, train_rmse=0.183942\n",
      "[Train epoch 40/50] loss=0.021755, train_rmse=0.186605\n",
      "[Train epoch 45/50] loss=0.019333, train_rmse=0.185079\n",
      "[Train epoch 50/50] loss=0.021110, train_rmse=0.194984\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-109454.8047 exp_ll=-101886.8750 KL=7567.9302\n",
      "[VI iter 80/800] ELBO=-19291.6367 exp_ll=-10728.1299 KL=8563.5068\n",
      "[VI iter 160/800] ELBO=-16701.3730 exp_ll=-7730.7715 KL=8970.6016\n",
      "[VI iter 240/800] ELBO=-15833.8271 exp_ll=-6595.2178 KL=9238.6094\n",
      "[VI iter 320/800] ELBO=-15426.3750 exp_ll=-5998.3921 KL=9427.9834\n",
      "[VI iter 400/800] ELBO=-15203.6846 exp_ll=-5638.9883 KL=9564.6963\n",
      "[VI iter 480/800] ELBO=-15069.6660 exp_ll=-5406.0269 KL=9663.6396\n",
      "[VI iter 560/800] ELBO=-14982.9580 exp_ll=-5248.3438 KL=9734.6143\n",
      "[VI iter 640/800] ELBO=-14923.3066 exp_ll=-5138.6055 KL=9784.7012\n",
      "[VI iter 720/800] ELBO=-14880.1562 exp_ll=-5060.9243 KL=9819.2314\n",
      "[VI iter 800/800] ELBO=-14847.6211 exp_ll=-5005.3579 KL=9842.2637\n",
      "Final test RMSE: 0.19498351004153655\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 38 | labelled size = 400 | pool size = 59600 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.147775, train_rmse=0.287821\n",
      "[Train epoch 5/50] loss=0.064922, train_rmse=0.248144\n",
      "[Train epoch 10/50] loss=0.046975, train_rmse=0.220282\n",
      "[Train epoch 15/50] loss=0.036909, train_rmse=0.204895\n",
      "[Train epoch 20/50] loss=0.027670, train_rmse=0.196733\n",
      "[Train epoch 25/50] loss=0.024670, train_rmse=0.191363\n",
      "[Train epoch 30/50] loss=0.022079, train_rmse=0.192279\n",
      "[Train epoch 35/50] loss=0.020814, train_rmse=0.183483\n",
      "[Train epoch 40/50] loss=0.017723, train_rmse=0.184740\n",
      "[Train epoch 45/50] loss=0.016403, train_rmse=0.185857\n",
      "[Train epoch 50/50] loss=0.015997, train_rmse=0.178336\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-128972.0703 exp_ll=-121405.8516 KL=7566.2217\n",
      "[VI iter 80/800] ELBO=-20313.7734 exp_ll=-11776.3350 KL=8537.4395\n",
      "[VI iter 160/800] ELBO=-17293.6914 exp_ll=-8348.1895 KL=8945.5010\n",
      "[VI iter 240/800] ELBO=-16257.0908 exp_ll=-7035.1543 KL=9221.9365\n",
      "[VI iter 320/800] ELBO=-15763.1523 exp_ll=-6341.2363 KL=9421.9160\n",
      "[VI iter 400/800] ELBO=-15489.8721 exp_ll=-5920.2764 KL=9569.5957\n",
      "[VI iter 480/800] ELBO=-15324.0938 exp_ll=-5644.9043 KL=9679.1895\n",
      "[VI iter 560/800] ELBO=-15216.4629 exp_ll=-5456.1963 KL=9760.2666\n",
      "[VI iter 640/800] ELBO=-15142.6152 exp_ll=-5322.8813 KL=9819.7344\n",
      "[VI iter 720/800] ELBO=-15089.6377 exp_ll=-5226.8604 KL=9862.7773\n",
      "[VI iter 800/800] ELBO=-15050.0264 exp_ll=-5156.6680 KL=9893.3584\n",
      "Final test RMSE: 0.17833648322196502\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 39 | labelled size = 410 | pool size = 59590 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.152105, train_rmse=0.292036\n",
      "[Train epoch 5/50] loss=0.067149, train_rmse=0.253221\n",
      "[Train epoch 10/50] loss=0.045879, train_rmse=0.219478\n",
      "[Train epoch 15/50] loss=0.033714, train_rmse=0.203242\n",
      "[Train epoch 20/50] loss=0.028352, train_rmse=0.189310\n",
      "[Train epoch 25/50] loss=0.023958, train_rmse=0.182837\n",
      "[Train epoch 30/50] loss=0.021519, train_rmse=0.190937\n",
      "[Train epoch 35/50] loss=0.017971, train_rmse=0.182534\n",
      "[Train epoch 40/50] loss=0.017021, train_rmse=0.181924\n",
      "[Train epoch 45/50] loss=0.015280, train_rmse=0.185876\n",
      "[Train epoch 50/50] loss=0.015679, train_rmse=0.189626\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-113779.3984 exp_ll=-106198.3672 KL=7581.0322\n",
      "[VI iter 80/800] ELBO=-19220.5000 exp_ll=-10687.2480 KL=8533.2520\n",
      "[VI iter 160/800] ELBO=-16773.4180 exp_ll=-7846.8555 KL=8926.5615\n",
      "[VI iter 240/800] ELBO=-15919.3818 exp_ll=-6733.0693 KL=9186.3125\n",
      "[VI iter 320/800] ELBO=-15511.3320 exp_ll=-6143.6733 KL=9367.6582\n",
      "[VI iter 400/800] ELBO=-15286.0020 exp_ll=-5789.7456 KL=9496.2568\n",
      "[VI iter 480/800] ELBO=-15148.7129 exp_ll=-5561.2139 KL=9587.4990\n",
      "[VI iter 560/800] ELBO=-15058.9766 exp_ll=-5407.3403 KL=9651.6357\n",
      "[VI iter 640/800] ELBO=-14996.3779 exp_ll=-5300.5078 KL=9695.8701\n",
      "[VI iter 720/800] ELBO=-14950.6982 exp_ll=-5225.2695 KL=9725.4287\n",
      "[VI iter 800/800] ELBO=-14915.9570 exp_ll=-5171.7593 KL=9744.1973\n",
      "Final test RMSE: 0.18962590434513188\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 40 | labelled size = 420 | pool size = 59580 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.155188, train_rmse=0.291710\n",
      "[Train epoch 5/50] loss=0.065597, train_rmse=0.250526\n",
      "[Train epoch 10/50] loss=0.047895, train_rmse=0.214501\n",
      "[Train epoch 15/50] loss=0.034278, train_rmse=0.198479\n",
      "[Train epoch 20/50] loss=0.026894, train_rmse=0.186179\n",
      "[Train epoch 25/50] loss=0.022108, train_rmse=0.187873\n",
      "[Train epoch 30/50] loss=0.019545, train_rmse=0.182665\n",
      "[Train epoch 35/50] loss=0.017623, train_rmse=0.181971\n",
      "[Train epoch 40/50] loss=0.016093, train_rmse=0.181307\n",
      "[Train epoch 45/50] loss=0.016259, train_rmse=0.186104\n",
      "[Train epoch 50/50] loss=0.014927, train_rmse=0.177424\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-127980.8203 exp_ll=-120425.6641 KL=7555.1548\n",
      "[VI iter 80/800] ELBO=-19655.6094 exp_ll=-11161.6582 KL=8493.9521\n",
      "[VI iter 160/800] ELBO=-17060.9004 exp_ll=-8190.7969 KL=8870.1035\n",
      "[VI iter 240/800] ELBO=-16144.2910 exp_ll=-7016.6626 KL=9127.6279\n",
      "[VI iter 320/800] ELBO=-15699.4199 exp_ll=-6384.5845 KL=9314.8359\n",
      "[VI iter 400/800] ELBO=-15451.7822 exp_ll=-5998.4365 KL=9453.3457\n",
      "[VI iter 480/800] ELBO=-15301.5664 exp_ll=-5745.3794 KL=9556.1875\n",
      "[VI iter 560/800] ELBO=-15204.2734 exp_ll=-5572.1001 KL=9632.1738\n",
      "[VI iter 640/800] ELBO=-15137.7305 exp_ll=-5450.0859 KL=9687.6445\n",
      "[VI iter 720/800] ELBO=-15089.7031 exp_ll=-5362.3452 KL=9727.3574\n",
      "[VI iter 800/800] ELBO=-15053.7178 exp_ll=-5298.7412 KL=9754.9766\n",
      "Final test RMSE: 0.17742379236970005\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 41 | labelled size = 430 | pool size = 59570 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.150162, train_rmse=0.286832\n",
      "[Train epoch 5/50] loss=0.064860, train_rmse=0.252480\n",
      "[Train epoch 10/50] loss=0.046774, train_rmse=0.216375\n",
      "[Train epoch 15/50] loss=0.034780, train_rmse=0.199488\n",
      "[Train epoch 20/50] loss=0.027224, train_rmse=0.189599\n",
      "[Train epoch 25/50] loss=0.023696, train_rmse=0.183965\n",
      "[Train epoch 30/50] loss=0.019723, train_rmse=0.186778\n",
      "[Train epoch 35/50] loss=0.018521, train_rmse=0.178954\n",
      "[Train epoch 40/50] loss=0.015771, train_rmse=0.180782\n",
      "[Train epoch 45/50] loss=0.017370, train_rmse=0.178683\n",
      "[Train epoch 50/50] loss=0.014712, train_rmse=0.179145\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-119293.4688 exp_ll=-111718.6719 KL=7574.7959\n",
      "[VI iter 80/800] ELBO=-19500.8906 exp_ll=-10971.4531 KL=8529.4385\n",
      "[VI iter 160/800] ELBO=-17010.7734 exp_ll=-8093.8154 KL=8916.9580\n",
      "[VI iter 240/800] ELBO=-16157.3027 exp_ll=-6980.9878 KL=9176.3154\n",
      "[VI iter 320/800] ELBO=-15749.9336 exp_ll=-6389.2808 KL=9360.6523\n",
      "[VI iter 400/800] ELBO=-15523.2217 exp_ll=-6028.9512 KL=9494.2705\n",
      "[VI iter 480/800] ELBO=-15384.7480 exp_ll=-5793.1636 KL=9591.5850\n",
      "[VI iter 560/800] ELBO=-15294.2744 exp_ll=-5632.1045 KL=9662.1699\n",
      "[VI iter 640/800] ELBO=-15232.0488 exp_ll=-5519.2544 KL=9712.7939\n",
      "[VI iter 720/800] ELBO=-15186.7490 exp_ll=-5438.3281 KL=9748.4209\n",
      "[VI iter 800/800] ELBO=-15152.8135 exp_ll=-5380.0439 KL=9772.7695\n",
      "Final test RMSE: 0.1791447473410201\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 42 | labelled size = 440 | pool size = 59560 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.149492, train_rmse=0.289213\n",
      "[Train epoch 5/50] loss=0.067409, train_rmse=0.255514\n",
      "[Train epoch 10/50] loss=0.047170, train_rmse=0.216040\n",
      "[Train epoch 15/50] loss=0.036053, train_rmse=0.199897\n",
      "[Train epoch 20/50] loss=0.027160, train_rmse=0.188776\n",
      "[Train epoch 25/50] loss=0.022739, train_rmse=0.182740\n",
      "[Train epoch 30/50] loss=0.020968, train_rmse=0.180122\n",
      "[Train epoch 35/50] loss=0.018191, train_rmse=0.173339\n",
      "[Train epoch 40/50] loss=0.016182, train_rmse=0.176955\n",
      "[Train epoch 45/50] loss=0.015818, train_rmse=0.176273\n",
      "[Train epoch 50/50] loss=0.014886, train_rmse=0.180433\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-119578.5469 exp_ll=-112014.0469 KL=7564.5000\n",
      "[VI iter 80/800] ELBO=-19350.9961 exp_ll=-10852.6406 KL=8498.3555\n",
      "[VI iter 160/800] ELBO=-16959.5938 exp_ll=-8081.9434 KL=8877.6494\n",
      "[VI iter 240/800] ELBO=-16140.6094 exp_ll=-7009.1753 KL=9131.4346\n",
      "[VI iter 320/800] ELBO=-15750.4004 exp_ll=-6438.0317 KL=9312.3682\n",
      "[VI iter 400/800] ELBO=-15533.4102 exp_ll=-6089.2778 KL=9444.1328\n",
      "[VI iter 480/800] ELBO=-15400.8594 exp_ll=-5860.3174 KL=9540.5420\n",
      "[VI iter 560/800] ELBO=-15314.1875 exp_ll=-5703.4971 KL=9610.6904\n",
      "[VI iter 640/800] ELBO=-15254.2803 exp_ll=-5593.2715 KL=9661.0088\n",
      "[VI iter 720/800] ELBO=-15210.8242 exp_ll=-5514.5605 KL=9696.2637\n",
      "[VI iter 800/800] ELBO=-15177.9688 exp_ll=-5457.8662 KL=9720.1025\n",
      "Final test RMSE: 0.18043281325518962\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 43 | labelled size = 450 | pool size = 59550 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.141904, train_rmse=0.290454\n",
      "[Train epoch 5/50] loss=0.067222, train_rmse=0.251990\n",
      "[Train epoch 10/50] loss=0.053140, train_rmse=0.225054\n",
      "[Train epoch 15/50] loss=0.043543, train_rmse=0.206993\n",
      "[Train epoch 20/50] loss=0.037973, train_rmse=0.202080\n",
      "[Train epoch 25/50] loss=0.033842, train_rmse=0.197304\n",
      "[Train epoch 30/50] loss=0.030413, train_rmse=0.200409\n",
      "[Train epoch 35/50] loss=0.026394, train_rmse=0.191272\n",
      "[Train epoch 40/50] loss=0.028841, train_rmse=0.189148\n",
      "[Train epoch 45/50] loss=0.023514, train_rmse=0.187501\n",
      "[Train epoch 50/50] loss=0.020985, train_rmse=0.185433\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-124504.2500 exp_ll=-116931.5312 KL=7572.7158\n",
      "[VI iter 80/800] ELBO=-21028.0039 exp_ll=-12428.1621 KL=8599.8418\n",
      "[VI iter 160/800] ELBO=-17978.0352 exp_ll=-8953.8232 KL=9024.2129\n",
      "[VI iter 240/800] ELBO=-16925.7305 exp_ll=-7616.2412 KL=9309.4893\n",
      "[VI iter 320/800] ELBO=-16417.7090 exp_ll=-6901.0264 KL=9516.6826\n",
      "[VI iter 400/800] ELBO=-16135.5889 exp_ll=-6464.4385 KL=9671.1504\n",
      "[VI iter 480/800] ELBO=-15965.1934 exp_ll=-6177.4561 KL=9787.7373\n",
      "[VI iter 560/800] ELBO=-15855.8779 exp_ll=-5979.6055 KL=9876.2725\n",
      "[VI iter 640/800] ELBO=-15782.3496 exp_ll=-5838.6958 KL=9943.6543\n",
      "[VI iter 720/800] ELBO=-15730.8213 exp_ll=-5735.9287 KL=9994.8926\n",
      "[VI iter 800/800] ELBO=-15693.5332 exp_ll=-5659.8237 KL=10033.7090\n",
      "Final test RMSE: 0.18543315667394222\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 44 | labelled size = 460 | pool size = 59540 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.151015, train_rmse=0.290509\n",
      "[Train epoch 5/50] loss=0.067119, train_rmse=0.250111\n",
      "[Train epoch 10/50] loss=0.049738, train_rmse=0.214565\n",
      "[Train epoch 15/50] loss=0.036780, train_rmse=0.197861\n",
      "[Train epoch 20/50] loss=0.030095, train_rmse=0.187199\n",
      "[Train epoch 25/50] loss=0.025009, train_rmse=0.187095\n",
      "[Train epoch 30/50] loss=0.022086, train_rmse=0.182801\n",
      "[Train epoch 35/50] loss=0.021694, train_rmse=0.182614\n",
      "[Train epoch 40/50] loss=0.019287, train_rmse=0.177451\n",
      "[Train epoch 45/50] loss=0.018333, train_rmse=0.180095\n",
      "[Train epoch 50/50] loss=0.017236, train_rmse=0.176831\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-135765.8906 exp_ll=-128194.2188 KL=7571.6738\n",
      "[VI iter 80/800] ELBO=-20975.4062 exp_ll=-12452.1660 KL=8523.2402\n",
      "[VI iter 160/800] ELBO=-17978.1914 exp_ll=-9055.3281 KL=8922.8643\n",
      "[VI iter 240/800] ELBO=-16911.3867 exp_ll=-7712.4648 KL=9198.9219\n",
      "[VI iter 320/800] ELBO=-16393.8984 exp_ll=-6991.4297 KL=9402.4678\n",
      "[VI iter 400/800] ELBO=-16105.3477 exp_ll=-6549.3706 KL=9555.9766\n",
      "[VI iter 480/800] ELBO=-15929.9424 exp_ll=-6257.4062 KL=9672.5361\n",
      "[VI iter 560/800] ELBO=-15816.3828 exp_ll=-6055.4771 KL=9760.9062\n",
      "[VI iter 640/800] ELBO=-15738.9199 exp_ll=-5911.5078 KL=9827.4121\n",
      "[VI iter 720/800] ELBO=-15683.6201 exp_ll=-5806.7812 KL=9876.8389\n",
      "[VI iter 800/800] ELBO=-15642.5283 exp_ll=-5729.6201 KL=9912.9082\n",
      "Final test RMSE: 0.1768312139467994\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 45 | labelled size = 470 | pool size = 59530 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.141476, train_rmse=0.291113\n",
      "[Train epoch 5/50] loss=0.064326, train_rmse=0.247092\n",
      "[Train epoch 10/50] loss=0.046495, train_rmse=0.214741\n",
      "[Train epoch 15/50] loss=0.034026, train_rmse=0.197644\n",
      "[Train epoch 20/50] loss=0.027119, train_rmse=0.185245\n",
      "[Train epoch 25/50] loss=0.023655, train_rmse=0.176380\n",
      "[Train epoch 30/50] loss=0.020814, train_rmse=0.180717\n",
      "[Train epoch 35/50] loss=0.019355, train_rmse=0.184094\n",
      "[Train epoch 40/50] loss=0.018020, train_rmse=0.171448\n",
      "[Train epoch 45/50] loss=0.017018, train_rmse=0.176297\n",
      "[Train epoch 50/50] loss=0.016618, train_rmse=0.175549\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-141189.6250 exp_ll=-133627.0469 KL=7562.5820\n",
      "[VI iter 80/800] ELBO=-20731.3633 exp_ll=-12235.0605 KL=8496.3027\n",
      "[VI iter 160/800] ELBO=-17813.1953 exp_ll=-8932.2012 KL=8880.9941\n",
      "[VI iter 240/800] ELBO=-16803.7344 exp_ll=-7658.6592 KL=9145.0752\n",
      "[VI iter 320/800] ELBO=-16320.0977 exp_ll=-6981.9316 KL=9338.1660\n",
      "[VI iter 400/800] ELBO=-16051.0205 exp_ll=-6568.5225 KL=9482.4980\n",
      "[VI iter 480/800] ELBO=-15886.7578 exp_ll=-6295.5635 KL=9591.1943\n",
      "[VI iter 560/800] ELBO=-15779.5488 exp_ll=-6106.5239 KL=9673.0244\n",
      "[VI iter 640/800] ELBO=-15705.8613 exp_ll=-5971.5972 KL=9734.2637\n",
      "[VI iter 720/800] ELBO=-15652.9258 exp_ll=-5873.3379 KL=9779.5879\n",
      "[VI iter 800/800] ELBO=-15613.3281 exp_ll=-5800.7622 KL=9812.5654\n",
      "Final test RMSE: 0.17554861560700485\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 46 | labelled size = 480 | pool size = 59520 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.144645, train_rmse=0.288897\n",
      "[Train epoch 5/50] loss=0.063686, train_rmse=0.249449\n",
      "[Train epoch 10/50] loss=0.045174, train_rmse=0.212055\n",
      "[Train epoch 15/50] loss=0.033273, train_rmse=0.193181\n",
      "[Train epoch 20/50] loss=0.026405, train_rmse=0.186946\n",
      "[Train epoch 25/50] loss=0.020747, train_rmse=0.181404\n",
      "[Train epoch 30/50] loss=0.019502, train_rmse=0.177501\n",
      "[Train epoch 35/50] loss=0.018443, train_rmse=0.178052\n",
      "[Train epoch 40/50] loss=0.015915, train_rmse=0.176352\n",
      "[Train epoch 45/50] loss=0.016231, train_rmse=0.172805\n",
      "[Train epoch 50/50] loss=0.015795, train_rmse=0.174087\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-137588.9062 exp_ll=-130024.0000 KL=7564.8984\n",
      "[VI iter 80/800] ELBO=-20618.2793 exp_ll=-12133.4609 KL=8484.8184\n",
      "[VI iter 160/800] ELBO=-17871.9570 exp_ll=-8997.1484 KL=8874.8076\n",
      "[VI iter 240/800] ELBO=-16891.2734 exp_ll=-7743.5762 KL=9147.6982\n",
      "[VI iter 320/800] ELBO=-16418.9883 exp_ll=-7068.6895 KL=9350.2988\n",
      "[VI iter 400/800] ELBO=-16157.5166 exp_ll=-6653.5186 KL=9503.9980\n",
      "[VI iter 480/800] ELBO=-15999.8398 exp_ll=-6378.5264 KL=9621.3135\n",
      "[VI iter 560/800] ELBO=-15898.7412 exp_ll=-6188.0586 KL=9710.6826\n",
      "[VI iter 640/800] ELBO=-15830.5625 exp_ll=-6052.3149 KL=9778.2480\n",
      "[VI iter 720/800] ELBO=-15782.3643 exp_ll=-5953.6758 KL=9828.6885\n",
      "[VI iter 800/800] ELBO=-15747.0352 exp_ll=-5881.3525 KL=9865.6826\n",
      "Final test RMSE: 0.17408734341201648\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 47 | labelled size = 490 | pool size = 59510 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.143023, train_rmse=0.288793\n",
      "[Train epoch 5/50] loss=0.065624, train_rmse=0.246273\n",
      "[Train epoch 10/50] loss=0.046338, train_rmse=0.210084\n",
      "[Train epoch 15/50] loss=0.034298, train_rmse=0.187757\n",
      "[Train epoch 20/50] loss=0.026862, train_rmse=0.185320\n",
      "[Train epoch 25/50] loss=0.022811, train_rmse=0.175241\n",
      "[Train epoch 30/50] loss=0.019286, train_rmse=0.175907\n",
      "[Train epoch 35/50] loss=0.017008, train_rmse=0.175433\n",
      "[Train epoch 40/50] loss=0.017930, train_rmse=0.179972\n",
      "[Train epoch 45/50] loss=0.015658, train_rmse=0.172707\n",
      "[Train epoch 50/50] loss=0.015061, train_rmse=0.177894\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-133318.0781 exp_ll=-125758.4062 KL=7559.6699\n",
      "[VI iter 80/800] ELBO=-20582.6562 exp_ll=-12077.2432 KL=8505.4131\n",
      "[VI iter 160/800] ELBO=-17834.4062 exp_ll=-8937.8057 KL=8896.6016\n",
      "[VI iter 240/800] ELBO=-16889.8516 exp_ll=-7725.2822 KL=9164.5684\n",
      "[VI iter 320/800] ELBO=-16437.0508 exp_ll=-7076.9004 KL=9360.1504\n",
      "[VI iter 400/800] ELBO=-16185.7119 exp_ll=-6679.9131 KL=9505.7988\n",
      "[VI iter 480/800] ELBO=-16033.5342 exp_ll=-6418.7646 KL=9614.7695\n",
      "[VI iter 560/800] ELBO=-15934.9570 exp_ll=-6238.9692 KL=9695.9883\n",
      "[VI iter 640/800] ELBO=-15867.8145 exp_ll=-6111.8867 KL=9755.9277\n",
      "[VI iter 720/800] ELBO=-15819.8154 exp_ll=-6020.3369 KL=9799.4785\n",
      "[VI iter 800/800] ELBO=-15784.0273 exp_ll=-5953.6064 KL=9830.4209\n",
      "Final test RMSE: 0.1778943348239332\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 48 | labelled size = 500 | pool size = 59500 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.145952, train_rmse=0.291707\n",
      "[Train epoch 5/50] loss=0.066808, train_rmse=0.249893\n",
      "[Train epoch 10/50] loss=0.045888, train_rmse=0.208524\n",
      "[Train epoch 15/50] loss=0.034689, train_rmse=0.184714\n",
      "[Train epoch 20/50] loss=0.027207, train_rmse=0.180760\n",
      "[Train epoch 25/50] loss=0.022271, train_rmse=0.178842\n",
      "[Train epoch 30/50] loss=0.019406, train_rmse=0.179501\n",
      "[Train epoch 35/50] loss=0.018154, train_rmse=0.179497\n",
      "[Train epoch 40/50] loss=0.019063, train_rmse=0.179360\n",
      "[Train epoch 45/50] loss=0.016331, train_rmse=0.173338\n",
      "[Train epoch 50/50] loss=0.015186, train_rmse=0.170788\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-142272.9219 exp_ll=-134698.7969 KL=7574.1182\n",
      "[VI iter 80/800] ELBO=-21290.0703 exp_ll=-12765.0059 KL=8525.0654\n",
      "[VI iter 160/800] ELBO=-18289.7305 exp_ll=-9370.3965 KL=8919.3350\n",
      "[VI iter 240/800] ELBO=-17244.7285 exp_ll=-8053.3105 KL=9191.4180\n",
      "[VI iter 320/800] ELBO=-16735.3672 exp_ll=-7343.4536 KL=9391.9141\n",
      "[VI iter 400/800] ELBO=-16449.4336 exp_ll=-6906.3008 KL=9543.1328\n",
      "[VI iter 480/800] ELBO=-16275.3086 exp_ll=-6617.1133 KL=9658.1953\n",
      "[VI iter 560/800] ELBO=-16162.6436 exp_ll=-6416.8145 KL=9745.8291\n",
      "[VI iter 640/800] ELBO=-16086.2725 exp_ll=-6274.0176 KL=9812.2549\n",
      "[VI iter 720/800] ELBO=-16032.2393 exp_ll=-6170.1289 KL=9862.1104\n",
      "[VI iter 800/800] ELBO=-15992.4482 exp_ll=-6093.4746 KL=9898.9736\n",
      "Final test RMSE: 0.17078785396836035\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 49 | labelled size = 510 | pool size = 59490 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.141582, train_rmse=0.291966\n",
      "[Train epoch 5/50] loss=0.065699, train_rmse=0.249195\n",
      "[Train epoch 10/50] loss=0.046110, train_rmse=0.213217\n",
      "[Train epoch 15/50] loss=0.035102, train_rmse=0.191635\n",
      "[Train epoch 20/50] loss=0.027227, train_rmse=0.188338\n",
      "[Train epoch 25/50] loss=0.023621, train_rmse=0.183892\n",
      "[Train epoch 30/50] loss=0.021068, train_rmse=0.178539\n",
      "[Train epoch 35/50] loss=0.018151, train_rmse=0.169087\n",
      "[Train epoch 40/50] loss=0.017259, train_rmse=0.170706\n",
      "[Train epoch 45/50] loss=0.015985, train_rmse=0.172799\n",
      "[Train epoch 50/50] loss=0.015954, train_rmse=0.170431\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-141663.9531 exp_ll=-134092.4375 KL=7571.5132\n",
      "[VI iter 80/800] ELBO=-21650.9766 exp_ll=-13128.4766 KL=8522.5010\n",
      "[VI iter 160/800] ELBO=-18541.9023 exp_ll=-9606.1084 KL=8935.7930\n",
      "[VI iter 240/800] ELBO=-17448.1953 exp_ll=-8224.9678 KL=9223.2266\n",
      "[VI iter 320/800] ELBO=-16919.5820 exp_ll=-7484.1851 KL=9435.3975\n",
      "[VI iter 400/800] ELBO=-16625.4707 exp_ll=-7030.1558 KL=9595.3145\n",
      "[VI iter 480/800] ELBO=-16447.0977 exp_ll=-6730.4463 KL=9716.6523\n",
      "[VI iter 560/800] ELBO=-16332.0811 exp_ll=-6523.4893 KL=9808.5918\n",
      "[VI iter 640/800] ELBO=-16253.7715 exp_ll=-6375.9902 KL=9877.7812\n",
      "[VI iter 720/800] ELBO=-16198.2520 exp_ll=-6268.9995 KL=9929.2520\n",
      "[VI iter 800/800] ELBO=-16157.3047 exp_ll=-6190.3848 KL=9966.9199\n",
      "Final test RMSE: 0.17043079632737845\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 50 | labelled size = 520 | pool size = 59480 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.136511, train_rmse=0.288884\n",
      "[Train epoch 5/50] loss=0.066584, train_rmse=0.245753\n",
      "[Train epoch 10/50] loss=0.047265, train_rmse=0.213078\n",
      "[Train epoch 15/50] loss=0.039665, train_rmse=0.194387\n",
      "[Train epoch 20/50] loss=0.031061, train_rmse=0.186734\n",
      "[Train epoch 25/50] loss=0.025281, train_rmse=0.184297\n",
      "[Train epoch 30/50] loss=0.023714, train_rmse=0.186611\n",
      "[Train epoch 35/50] loss=0.021078, train_rmse=0.175942\n",
      "[Train epoch 40/50] loss=0.019297, train_rmse=0.172033\n",
      "[Train epoch 45/50] loss=0.018251, train_rmse=0.175795\n",
      "[Train epoch 50/50] loss=0.017034, train_rmse=0.168068\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-158433.2969 exp_ll=-150871.6562 KL=7561.6450\n",
      "[VI iter 80/800] ELBO=-22425.1758 exp_ll=-13917.0840 KL=8508.0918\n",
      "[VI iter 160/800] ELBO=-19110.9766 exp_ll=-10195.1484 KL=8915.8281\n",
      "[VI iter 240/800] ELBO=-17903.3906 exp_ll=-8695.3535 KL=9208.0361\n",
      "[VI iter 320/800] ELBO=-17301.4492 exp_ll=-7871.8135 KL=9429.6357\n",
      "[VI iter 400/800] ELBO=-16959.8574 exp_ll=-7358.5151 KL=9601.3418\n",
      "[VI iter 480/800] ELBO=-16750.6738 exp_ll=-7014.9199 KL=9735.7539\n",
      "[VI iter 560/800] ELBO=-16615.4844 exp_ll=-6774.0879 KL=9841.3975\n",
      "[VI iter 640/800] ELBO=-16524.2812 exp_ll=-6599.8589 KL=9924.4229\n",
      "[VI iter 720/800] ELBO=-16460.4141 exp_ll=-6470.9478 KL=9989.4668\n",
      "[VI iter 800/800] ELBO=-16414.0703 exp_ll=-6373.9424 KL=10040.1289\n",
      "Final test RMSE: 0.1680677759144645\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 51 | labelled size = 530 | pool size = 59470 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.134986, train_rmse=0.291504\n",
      "[Train epoch 5/50] loss=0.066089, train_rmse=0.247037\n",
      "[Train epoch 10/50] loss=0.045702, train_rmse=0.208094\n",
      "[Train epoch 15/50] loss=0.035644, train_rmse=0.192225\n",
      "[Train epoch 20/50] loss=0.028250, train_rmse=0.183648\n",
      "[Train epoch 25/50] loss=0.024410, train_rmse=0.181344\n",
      "[Train epoch 30/50] loss=0.021767, train_rmse=0.175057\n",
      "[Train epoch 35/50] loss=0.020452, train_rmse=0.179926\n",
      "[Train epoch 40/50] loss=0.017847, train_rmse=0.170129\n",
      "[Train epoch 45/50] loss=0.017515, train_rmse=0.172123\n",
      "[Train epoch 50/50] loss=0.016137, train_rmse=0.171112\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-150067.4688 exp_ll=-142505.2656 KL=7562.2095\n",
      "[VI iter 80/800] ELBO=-21957.7031 exp_ll=-13450.8555 KL=8506.8477\n",
      "[VI iter 160/800] ELBO=-18837.1094 exp_ll=-9932.1328 KL=8904.9766\n",
      "[VI iter 240/800] ELBO=-17713.6582 exp_ll=-8529.9590 KL=9183.6992\n",
      "[VI iter 320/800] ELBO=-17159.7930 exp_ll=-7769.0703 KL=9390.7227\n",
      "[VI iter 400/800] ELBO=-16846.6602 exp_ll=-7298.8281 KL=9547.8330\n",
      "[VI iter 480/800] ELBO=-16654.3223 exp_ll=-6986.2314 KL=9668.0908\n",
      "[VI iter 560/800] ELBO=-16528.8574 exp_ll=-6768.6006 KL=9760.2568\n",
      "[VI iter 640/800] ELBO=-16443.0938 exp_ll=-6612.4492 KL=9830.6455\n",
      "[VI iter 720/800] ELBO=-16382.0723 exp_ll=-6498.0513 KL=9884.0205\n",
      "[VI iter 800/800] ELBO=-16336.9629 exp_ll=-6412.8916 KL=9924.0713\n",
      "Final test RMSE: 0.17111233682919358\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 52 | labelled size = 540 | pool size = 59460 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.134027, train_rmse=0.285575\n",
      "[Train epoch 5/50] loss=0.063873, train_rmse=0.243222\n",
      "[Train epoch 10/50] loss=0.044373, train_rmse=0.203835\n",
      "[Train epoch 15/50] loss=0.031927, train_rmse=0.184715\n",
      "[Train epoch 20/50] loss=0.026832, train_rmse=0.178945\n",
      "[Train epoch 25/50] loss=0.023231, train_rmse=0.176175\n",
      "[Train epoch 30/50] loss=0.021653, train_rmse=0.175875\n",
      "[Train epoch 35/50] loss=0.018168, train_rmse=0.177020\n",
      "[Train epoch 40/50] loss=0.018188, train_rmse=0.175661\n",
      "[Train epoch 45/50] loss=0.016906, train_rmse=0.174319\n",
      "[Train epoch 50/50] loss=0.016782, train_rmse=0.172266\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-144751.6406 exp_ll=-137195.2812 KL=7556.3594\n",
      "[VI iter 80/800] ELBO=-21343.0664 exp_ll=-12872.9395 KL=8470.1279\n",
      "[VI iter 160/800] ELBO=-18555.4336 exp_ll=-9700.7480 KL=8854.6855\n",
      "[VI iter 240/800] ELBO=-17540.7754 exp_ll=-8411.9258 KL=9128.8496\n",
      "[VI iter 320/800] ELBO=-17042.5977 exp_ll=-7708.7559 KL=9333.8428\n",
      "[VI iter 400/800] ELBO=-16763.0312 exp_ll=-7273.2666 KL=9489.7637\n",
      "[VI iter 480/800] ELBO=-16592.7930 exp_ll=-6983.7251 KL=9609.0674\n",
      "[VI iter 560/800] ELBO=-16482.8770 exp_ll=-6782.5781 KL=9700.2988\n",
      "[VI iter 640/800] ELBO=-16408.3750 exp_ll=-6638.6943 KL=9769.6807\n",
      "[VI iter 720/800] ELBO=-16355.7627 exp_ll=-6533.8350 KL=9821.9277\n",
      "[VI iter 800/800] ELBO=-16317.1387 exp_ll=-6456.4341 KL=9860.7041\n",
      "Final test RMSE: 0.17226636388365046\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 53 | labelled size = 550 | pool size = 59450 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.136433, train_rmse=0.286512\n",
      "[Train epoch 5/50] loss=0.062984, train_rmse=0.240129\n",
      "[Train epoch 10/50] loss=0.042914, train_rmse=0.204225\n",
      "[Train epoch 15/50] loss=0.033415, train_rmse=0.189715\n",
      "[Train epoch 20/50] loss=0.025070, train_rmse=0.180223\n",
      "[Train epoch 25/50] loss=0.021848, train_rmse=0.175981\n",
      "[Train epoch 30/50] loss=0.020909, train_rmse=0.176790\n",
      "[Train epoch 35/50] loss=0.018249, train_rmse=0.173751\n",
      "[Train epoch 40/50] loss=0.018594, train_rmse=0.176330\n",
      "[Train epoch 45/50] loss=0.016528, train_rmse=0.177555\n",
      "[Train epoch 50/50] loss=0.014866, train_rmse=0.166156\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-156974.3594 exp_ll=-149410.8125 KL=7563.5449\n",
      "[VI iter 80/800] ELBO=-22601.6875 exp_ll=-14100.3008 KL=8501.3867\n",
      "[VI iter 160/800] ELBO=-19174.6523 exp_ll=-10283.2920 KL=8891.3613\n",
      "[VI iter 240/800] ELBO=-17971.4648 exp_ll=-8807.3408 KL=9164.1250\n",
      "[VI iter 320/800] ELBO=-17386.1875 exp_ll=-8017.9917 KL=9368.1963\n",
      "[VI iter 400/800] ELBO=-17056.8711 exp_ll=-7531.8574 KL=9525.0127\n",
      "[VI iter 480/800] ELBO=-16855.3750 exp_ll=-7208.4985 KL=9646.8760\n",
      "[VI iter 560/800] ELBO=-16724.5664 exp_ll=-6982.8398 KL=9741.7275\n",
      "[VI iter 640/800] ELBO=-16635.4902 exp_ll=-6820.2349 KL=9815.2559\n",
      "[VI iter 720/800] ELBO=-16572.3047 exp_ll=-6700.4873 KL=9871.8164\n",
      "[VI iter 800/800] ELBO=-16525.9785 exp_ll=-6611.1475 KL=9914.8311\n",
      "Final test RMSE: 0.16615561744636975\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 54 | labelled size = 560 | pool size = 59440 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.136075, train_rmse=0.288185\n",
      "[Train epoch 5/50] loss=0.065103, train_rmse=0.244346\n",
      "[Train epoch 10/50] loss=0.045800, train_rmse=0.209888\n",
      "[Train epoch 15/50] loss=0.032683, train_rmse=0.189642\n",
      "[Train epoch 20/50] loss=0.026179, train_rmse=0.180393\n",
      "[Train epoch 25/50] loss=0.021662, train_rmse=0.174672\n",
      "[Train epoch 30/50] loss=0.021472, train_rmse=0.177801\n",
      "[Train epoch 35/50] loss=0.018224, train_rmse=0.176932\n",
      "[Train epoch 40/50] loss=0.018318, train_rmse=0.177116\n",
      "[Train epoch 45/50] loss=0.016472, train_rmse=0.169612\n",
      "[Train epoch 50/50] loss=0.015503, train_rmse=0.164992\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-149234.0156 exp_ll=-141677.6875 KL=7556.3237\n",
      "[VI iter 80/800] ELBO=-22365.1816 exp_ll=-13873.8193 KL=8491.3623\n",
      "[VI iter 160/800] ELBO=-19157.1973 exp_ll=-10263.8867 KL=8893.3105\n",
      "[VI iter 240/800] ELBO=-18012.4922 exp_ll=-8834.4268 KL=9178.0654\n",
      "[VI iter 320/800] ELBO=-17450.8457 exp_ll=-8058.9673 KL=9391.8789\n",
      "[VI iter 400/800] ELBO=-17135.2734 exp_ll=-7579.6113 KL=9555.6631\n",
      "[VI iter 480/800] ELBO=-16942.9961 exp_ll=-7261.1064 KL=9681.8906\n",
      "[VI iter 560/800] ELBO=-16818.7246 exp_ll=-7039.6890 KL=9779.0361\n",
      "[VI iter 640/800] ELBO=-16734.4238 exp_ll=-6881.1182 KL=9853.3057\n",
      "[VI iter 720/800] ELBO=-16674.7500 exp_ll=-6765.2788 KL=9909.4707\n",
      "[VI iter 800/800] ELBO=-16630.8633 exp_ll=-6679.5571 KL=9951.3066\n",
      "Final test RMSE: 0.16499232447718\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 55 | labelled size = 570 | pool size = 59430 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.133186, train_rmse=0.288411\n",
      "[Train epoch 5/50] loss=0.064635, train_rmse=0.244572\n",
      "[Train epoch 10/50] loss=0.046894, train_rmse=0.210663\n",
      "[Train epoch 15/50] loss=0.032788, train_rmse=0.191434\n",
      "[Train epoch 20/50] loss=0.027081, train_rmse=0.181409\n",
      "[Train epoch 25/50] loss=0.022467, train_rmse=0.181930\n",
      "[Train epoch 30/50] loss=0.020458, train_rmse=0.174692\n",
      "[Train epoch 35/50] loss=0.019652, train_rmse=0.181812\n",
      "[Train epoch 40/50] loss=0.016803, train_rmse=0.174825\n",
      "[Train epoch 45/50] loss=0.015986, train_rmse=0.167651\n",
      "[Train epoch 50/50] loss=0.017872, train_rmse=0.170600\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-148634.7031 exp_ll=-141068.3594 KL=7566.3398\n",
      "[VI iter 80/800] ELBO=-22332.5547 exp_ll=-13820.9668 KL=8511.5879\n",
      "[VI iter 160/800] ELBO=-19211.0957 exp_ll=-10290.0137 KL=8921.0820\n",
      "[VI iter 240/800] ELBO=-18086.0273 exp_ll=-8877.7148 KL=9208.3135\n",
      "[VI iter 320/800] ELBO=-17535.1914 exp_ll=-8113.8101 KL=9421.3809\n",
      "[VI iter 400/800] ELBO=-17226.3242 exp_ll=-7643.3994 KL=9582.9248\n",
      "[VI iter 480/800] ELBO=-17038.4102 exp_ll=-7331.9312 KL=9706.4785\n",
      "[VI iter 560/800] ELBO=-16917.1738 exp_ll=-7116.0889 KL=9801.0850\n",
      "[VI iter 640/800] ELBO=-16835.1406 exp_ll=-6961.9038 KL=9873.2363\n",
      "[VI iter 720/800] ELBO=-16777.3262 exp_ll=-6849.5034 KL=9927.8223\n",
      "[VI iter 800/800] ELBO=-16735.1289 exp_ll=-6766.4824 KL=9968.6465\n",
      "Final test RMSE: 0.17059959581613457\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 56 | labelled size = 580 | pool size = 59420 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.136817, train_rmse=0.288903\n",
      "[Train epoch 5/50] loss=0.067233, train_rmse=0.248331\n",
      "[Train epoch 10/50] loss=0.050992, train_rmse=0.216915\n",
      "[Train epoch 15/50] loss=0.040575, train_rmse=0.196463\n",
      "[Train epoch 20/50] loss=0.032015, train_rmse=0.185507\n",
      "[Train epoch 25/50] loss=0.028417, train_rmse=0.178027\n",
      "[Train epoch 30/50] loss=0.025790, train_rmse=0.182549\n",
      "[Train epoch 35/50] loss=0.024050, train_rmse=0.181482\n",
      "[Train epoch 40/50] loss=0.021902, train_rmse=0.172600\n",
      "[Train epoch 45/50] loss=0.021053, train_rmse=0.176077\n",
      "[Train epoch 50/50] loss=0.021765, train_rmse=0.173847\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-148747.1562 exp_ll=-141167.1562 KL=7580.0078\n",
      "[VI iter 80/800] ELBO=-24081.6211 exp_ll=-15496.6719 KL=8584.9482\n",
      "[VI iter 160/800] ELBO=-20237.1094 exp_ll=-11202.5586 KL=9034.5518\n",
      "[VI iter 240/800] ELBO=-18835.1094 exp_ll=-9486.1855 KL=9348.9229\n",
      "[VI iter 320/800] ELBO=-18148.5859 exp_ll=-8566.2969 KL=9582.2881\n",
      "[VI iter 400/800] ELBO=-17765.1465 exp_ll=-8005.3252 KL=9759.8213\n",
      "[VI iter 480/800] ELBO=-17532.5312 exp_ll=-7635.8740 KL=9896.6562\n",
      "[VI iter 560/800] ELBO=-17382.7520 exp_ll=-7379.9199 KL=10002.8320\n",
      "[VI iter 640/800] ELBO=-17281.5547 exp_ll=-7196.1426 KL=10085.4121\n",
      "[VI iter 720/800] ELBO=-17210.5332 exp_ll=-7060.9468 KL=10149.5869\n",
      "[VI iter 800/800] ELBO=-17159.0137 exp_ll=-6959.7241 KL=10199.2900\n",
      "Final test RMSE: 0.1738467645488345\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 57 | labelled size = 590 | pool size = 59410 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.134242, train_rmse=0.288255\n",
      "[Train epoch 5/50] loss=0.064413, train_rmse=0.240065\n",
      "[Train epoch 10/50] loss=0.046133, train_rmse=0.208243\n",
      "[Train epoch 15/50] loss=0.034286, train_rmse=0.188145\n",
      "[Train epoch 20/50] loss=0.027940, train_rmse=0.184427\n",
      "[Train epoch 25/50] loss=0.024779, train_rmse=0.178084\n",
      "[Train epoch 30/50] loss=0.020692, train_rmse=0.178363\n",
      "[Train epoch 35/50] loss=0.021109, train_rmse=0.177225\n",
      "[Train epoch 40/50] loss=0.020292, train_rmse=0.177546\n",
      "[Train epoch 45/50] loss=0.017487, train_rmse=0.171014\n",
      "[Train epoch 50/50] loss=0.016597, train_rmse=0.169306\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-157436.3750 exp_ll=-149883.2500 KL=7553.1245\n",
      "[VI iter 80/800] ELBO=-22926.4531 exp_ll=-14423.0479 KL=8503.4053\n",
      "[VI iter 160/800] ELBO=-19626.9219 exp_ll=-10718.5703 KL=8908.3516\n",
      "[VI iter 240/800] ELBO=-18440.9277 exp_ll=-9248.3818 KL=9192.5459\n",
      "[VI iter 320/800] ELBO=-17852.9570 exp_ll=-8447.8428 KL=9405.1152\n",
      "[VI iter 400/800] ELBO=-17519.1074 exp_ll=-7950.7759 KL=9568.3320\n",
      "[VI iter 480/800] ELBO=-17314.1641 exp_ll=-7618.8594 KL=9695.3037\n",
      "[VI iter 560/800] ELBO=-17181.3105 exp_ll=-7386.6646 KL=9794.6455\n",
      "[VI iter 640/800] ELBO=-17091.3320 exp_ll=-7218.9121 KL=9872.4209\n",
      "[VI iter 720/800] ELBO=-17028.1445 exp_ll=-7095.0283 KL=9933.1162\n",
      "[VI iter 800/800] ELBO=-16982.3457 exp_ll=-7002.1675 KL=9980.1777\n",
      "Final test RMSE: 0.16930567850795694\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 58 | labelled size = 600 | pool size = 59400 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.134881, train_rmse=0.289207\n",
      "[Train epoch 5/50] loss=0.063403, train_rmse=0.244014\n",
      "[Train epoch 10/50] loss=0.044205, train_rmse=0.208277\n",
      "[Train epoch 15/50] loss=0.034733, train_rmse=0.189973\n",
      "[Train epoch 20/50] loss=0.028753, train_rmse=0.178614\n",
      "[Train epoch 25/50] loss=0.023043, train_rmse=0.180659\n",
      "[Train epoch 30/50] loss=0.019938, train_rmse=0.175915\n",
      "[Train epoch 35/50] loss=0.019330, train_rmse=0.176155\n",
      "[Train epoch 40/50] loss=0.017639, train_rmse=0.181030\n",
      "[Train epoch 45/50] loss=0.015621, train_rmse=0.169418\n",
      "[Train epoch 50/50] loss=0.015178, train_rmse=0.170906\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-158914.5625 exp_ll=-151352.1250 KL=7562.4385\n",
      "[VI iter 80/800] ELBO=-23073.4805 exp_ll=-14565.1562 KL=8508.3252\n",
      "[VI iter 160/800] ELBO=-19722.2520 exp_ll=-10815.4551 KL=8906.7969\n",
      "[VI iter 240/800] ELBO=-18521.7500 exp_ll=-9334.0059 KL=9187.7441\n",
      "[VI iter 320/800] ELBO=-17928.7090 exp_ll=-8529.8535 KL=9398.8555\n",
      "[VI iter 400/800] ELBO=-17593.2090 exp_ll=-8031.9849 KL=9561.2246\n",
      "[VI iter 480/800] ELBO=-17387.3359 exp_ll=-7699.9678 KL=9687.3682\n",
      "[VI iter 560/800] ELBO=-17253.7285 exp_ll=-7468.0688 KL=9785.6602\n",
      "[VI iter 640/800] ELBO=-17162.9453 exp_ll=-7300.8408 KL=9862.1055\n",
      "[VI iter 720/800] ELBO=-17098.6953 exp_ll=-7177.4829 KL=9921.2119\n",
      "[VI iter 800/800] ELBO=-17051.5762 exp_ll=-7085.1021 KL=9966.4746\n",
      "Final test RMSE: 0.17090563307954393\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 59 | labelled size = 610 | pool size = 59390 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.134119, train_rmse=0.288602\n",
      "[Train epoch 5/50] loss=0.062726, train_rmse=0.244340\n",
      "[Train epoch 10/50] loss=0.043203, train_rmse=0.201839\n",
      "[Train epoch 15/50] loss=0.033740, train_rmse=0.188798\n",
      "[Train epoch 20/50] loss=0.025971, train_rmse=0.179756\n",
      "[Train epoch 25/50] loss=0.022506, train_rmse=0.177218\n",
      "[Train epoch 30/50] loss=0.020037, train_rmse=0.177863\n",
      "[Train epoch 35/50] loss=0.018894, train_rmse=0.167176\n",
      "[Train epoch 40/50] loss=0.016656, train_rmse=0.167495\n",
      "[Train epoch 45/50] loss=0.018510, train_rmse=0.175997\n",
      "[Train epoch 50/50] loss=0.016591, train_rmse=0.174148\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-156487.0312 exp_ll=-148915.0938 KL=7571.9380\n",
      "[VI iter 80/800] ELBO=-22959.3516 exp_ll=-14453.6172 KL=8505.7344\n",
      "[VI iter 160/800] ELBO=-19698.5312 exp_ll=-10792.1484 KL=8906.3838\n",
      "[VI iter 240/800] ELBO=-18523.4336 exp_ll=-9334.4844 KL=9188.9492\n",
      "[VI iter 320/800] ELBO=-17947.4355 exp_ll=-8547.3398 KL=9400.0957\n",
      "[VI iter 400/800] ELBO=-17623.8555 exp_ll=-8062.5850 KL=9561.2695\n",
      "[VI iter 480/800] ELBO=-17426.2070 exp_ll=-7740.9775 KL=9685.2305\n",
      "[VI iter 560/800] ELBO=-17297.9570 exp_ll=-7517.3984 KL=9780.5586\n",
      "[VI iter 640/800] ELBO=-17210.4883 exp_ll=-7357.0078 KL=9853.4814\n",
      "[VI iter 720/800] ELBO=-17148.2812 exp_ll=-7239.5200 KL=9908.7617\n",
      "[VI iter 800/800] ELBO=-17102.4434 exp_ll=-7152.3003 KL=9950.1436\n",
      "Final test RMSE: 0.1741478448794139\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 60 | labelled size = 620 | pool size = 59380 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.136560, train_rmse=0.288639\n",
      "[Train epoch 5/50] loss=0.064185, train_rmse=0.246137\n",
      "[Train epoch 10/50] loss=0.046191, train_rmse=0.207552\n",
      "[Train epoch 15/50] loss=0.033345, train_rmse=0.188722\n",
      "[Train epoch 20/50] loss=0.027382, train_rmse=0.178845\n",
      "[Train epoch 25/50] loss=0.021891, train_rmse=0.182559\n",
      "[Train epoch 30/50] loss=0.019994, train_rmse=0.176777\n",
      "[Train epoch 35/50] loss=0.019272, train_rmse=0.169081\n",
      "[Train epoch 40/50] loss=0.017705, train_rmse=0.176787\n",
      "[Train epoch 45/50] loss=0.016415, train_rmse=0.182189\n",
      "[Train epoch 50/50] loss=0.015986, train_rmse=0.166337\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-161142.4844 exp_ll=-153569.8906 KL=7572.5884\n",
      "[VI iter 80/800] ELBO=-23263.0977 exp_ll=-14746.5645 KL=8516.5342\n",
      "[VI iter 160/800] ELBO=-19923.4434 exp_ll=-11005.7461 KL=8917.6973\n",
      "[VI iter 240/800] ELBO=-18732.6191 exp_ll=-9529.5957 KL=9203.0234\n",
      "[VI iter 320/800] ELBO=-18141.6328 exp_ll=-8723.0566 KL=9418.5771\n",
      "[VI iter 400/800] ELBO=-17806.4766 exp_ll=-8221.4766 KL=9585.0000\n",
      "[VI iter 480/800] ELBO=-17601.3789 exp_ll=-7886.6279 KL=9714.7500\n",
      "[VI iter 560/800] ELBO=-17468.8984 exp_ll=-7652.6562 KL=9816.2422\n",
      "[VI iter 640/800] ELBO=-17379.5371 exp_ll=-7484.0054 KL=9895.5322\n",
      "[VI iter 720/800] ELBO=-17317.1094 exp_ll=-7359.9355 KL=9957.1729\n",
      "[VI iter 800/800] ELBO=-17271.5312 exp_ll=-7266.8325 KL=10004.6992\n",
      "Final test RMSE: 0.16633673967133353\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 61 | labelled size = 630 | pool size = 59370 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.128842, train_rmse=0.285850\n",
      "[Train epoch 5/50] loss=0.061322, train_rmse=0.238523\n",
      "[Train epoch 10/50] loss=0.042902, train_rmse=0.205372\n",
      "[Train epoch 15/50] loss=0.033247, train_rmse=0.183288\n",
      "[Train epoch 20/50] loss=0.025885, train_rmse=0.175741\n",
      "[Train epoch 25/50] loss=0.021698, train_rmse=0.178009\n",
      "[Train epoch 30/50] loss=0.018375, train_rmse=0.173970\n",
      "[Train epoch 35/50] loss=0.018697, train_rmse=0.176011\n",
      "[Train epoch 40/50] loss=0.017113, train_rmse=0.175500\n",
      "[Train epoch 45/50] loss=0.015876, train_rmse=0.167274\n",
      "[Train epoch 50/50] loss=0.015642, train_rmse=0.166278\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-162217.9375 exp_ll=-154638.0781 KL=7579.8579\n",
      "[VI iter 80/800] ELBO=-23346.9102 exp_ll=-14836.4023 KL=8510.5088\n",
      "[VI iter 160/800] ELBO=-19930.0352 exp_ll=-11021.8457 KL=8908.1904\n",
      "[VI iter 240/800] ELBO=-18725.5312 exp_ll=-9537.5176 KL=9188.0137\n",
      "[VI iter 320/800] ELBO=-18145.7188 exp_ll=-8747.6406 KL=9398.0791\n",
      "[VI iter 400/800] ELBO=-17822.1719 exp_ll=-8262.4072 KL=9559.7637\n",
      "[VI iter 480/800] ELBO=-17625.0234 exp_ll=-7939.6201 KL=9685.4033\n",
      "[VI iter 560/800] ELBO=-17497.3477 exp_ll=-7714.1865 KL=9783.1602\n",
      "[VI iter 640/800] ELBO=-17410.5703 exp_ll=-7551.6631 KL=9858.9062\n",
      "[VI iter 720/800] ELBO=-17349.0742 exp_ll=-7431.9639 KL=9917.1104\n",
      "[VI iter 800/800] ELBO=-17303.9043 exp_ll=-7342.6147 KL=9961.2900\n",
      "Final test RMSE: 0.1662783366698881\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 62 | labelled size = 640 | pool size = 59360 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.128074, train_rmse=0.284502\n",
      "[Train epoch 5/50] loss=0.062181, train_rmse=0.243216\n",
      "[Train epoch 10/50] loss=0.042091, train_rmse=0.204930\n",
      "[Train epoch 15/50] loss=0.032817, train_rmse=0.185658\n",
      "[Train epoch 20/50] loss=0.026355, train_rmse=0.178581\n",
      "[Train epoch 25/50] loss=0.022450, train_rmse=0.173123\n",
      "[Train epoch 30/50] loss=0.019411, train_rmse=0.167690\n",
      "[Train epoch 35/50] loss=0.017433, train_rmse=0.166088\n",
      "[Train epoch 40/50] loss=0.015776, train_rmse=0.167810\n",
      "[Train epoch 45/50] loss=0.016804, train_rmse=0.170656\n",
      "[Train epoch 50/50] loss=0.014634, train_rmse=0.170309\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-163840.2812 exp_ll=-156288.0781 KL=7552.1958\n",
      "[VI iter 80/800] ELBO=-23059.1758 exp_ll=-14592.8652 KL=8466.3096\n",
      "[VI iter 160/800] ELBO=-19938.0781 exp_ll=-11088.4854 KL=8849.5938\n",
      "[VI iter 240/800] ELBO=-18786.6719 exp_ll=-9661.5146 KL=9125.1582\n",
      "[VI iter 320/800] ELBO=-18208.0371 exp_ll=-8873.5137 KL=9334.5234\n",
      "[VI iter 400/800] ELBO=-17878.5430 exp_ll=-8381.9766 KL=9496.5654\n",
      "[VI iter 480/800] ELBO=-17676.0469 exp_ll=-8053.3164 KL=9622.7314\n",
      "[VI iter 560/800] ELBO=-17544.3027 exp_ll=-7823.3774 KL=9720.9248\n",
      "[VI iter 640/800] ELBO=-17454.4785 exp_ll=-7657.4482 KL=9797.0303\n",
      "[VI iter 720/800] ELBO=-17390.7070 exp_ll=-7535.1299 KL=9855.5781\n",
      "[VI iter 800/800] ELBO=-17343.8379 exp_ll=-7443.7031 KL=9900.1348\n",
      "Final test RMSE: 0.17030873631509647\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 63 | labelled size = 650 | pool size = 59350 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.135155, train_rmse=0.287004\n",
      "[Train epoch 5/50] loss=0.063429, train_rmse=0.242531\n",
      "[Train epoch 10/50] loss=0.045841, train_rmse=0.209226\n",
      "[Train epoch 15/50] loss=0.035026, train_rmse=0.191044\n",
      "[Train epoch 20/50] loss=0.028662, train_rmse=0.182089\n",
      "[Train epoch 25/50] loss=0.024667, train_rmse=0.177121\n",
      "[Train epoch 30/50] loss=0.020118, train_rmse=0.175686\n",
      "[Train epoch 35/50] loss=0.020192, train_rmse=0.171804\n",
      "[Train epoch 40/50] loss=0.018409, train_rmse=0.169239\n",
      "[Train epoch 45/50] loss=0.016959, train_rmse=0.170435\n",
      "[Train epoch 50/50] loss=0.016880, train_rmse=0.175668\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-166147.4531 exp_ll=-158577.2031 KL=7570.2495\n",
      "[VI iter 80/800] ELBO=-23972.4688 exp_ll=-15453.9277 KL=8518.5410\n",
      "[VI iter 160/800] ELBO=-20433.9570 exp_ll=-11509.8428 KL=8924.1133\n",
      "[VI iter 240/800] ELBO=-19165.4980 exp_ll=-9953.9863 KL=9211.5117\n",
      "[VI iter 320/800] ELBO=-18543.2578 exp_ll=-9115.2480 KL=9428.0098\n",
      "[VI iter 400/800] ELBO=-18189.9414 exp_ll=-8594.9775 KL=9594.9629\n",
      "[VI iter 480/800] ELBO=-17971.1973 exp_ll=-8246.2305 KL=9724.9668\n",
      "[VI iter 560/800] ELBO=-17827.5918 exp_ll=-8001.1108 KL=9826.4814\n",
      "[VI iter 640/800] ELBO=-17729.0137 exp_ll=-7823.3599 KL=9905.6533\n",
      "[VI iter 720/800] ELBO=-17658.7461 exp_ll=-7691.5942 KL=9967.1514\n",
      "[VI iter 800/800] ELBO=-17607.1094 exp_ll=-7592.4834 KL=10014.6260\n",
      "Final test RMSE: 0.17566806371134527\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 64 | labelled size = 660 | pool size = 59340 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.132983, train_rmse=0.289428\n",
      "[Train epoch 5/50] loss=0.061508, train_rmse=0.240094\n",
      "[Train epoch 10/50] loss=0.044853, train_rmse=0.202838\n",
      "[Train epoch 15/50] loss=0.033658, train_rmse=0.185227\n",
      "[Train epoch 20/50] loss=0.027674, train_rmse=0.182563\n",
      "[Train epoch 25/50] loss=0.022745, train_rmse=0.172155\n",
      "[Train epoch 30/50] loss=0.020609, train_rmse=0.169899\n",
      "[Train epoch 35/50] loss=0.018026, train_rmse=0.167380\n",
      "[Train epoch 40/50] loss=0.018576, train_rmse=0.168889\n",
      "[Train epoch 45/50] loss=0.016226, train_rmse=0.166250\n",
      "[Train epoch 50/50] loss=0.017392, train_rmse=0.172579\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-153874.2969 exp_ll=-146320.4062 KL=7553.8926\n",
      "[VI iter 80/800] ELBO=-23320.7812 exp_ll=-14827.8311 KL=8492.9512\n",
      "[VI iter 160/800] ELBO=-20056.7500 exp_ll=-11166.3945 KL=8890.3545\n",
      "[VI iter 240/800] ELBO=-18907.5586 exp_ll=-9737.5566 KL=9170.0029\n",
      "[VI iter 320/800] ELBO=-18347.1562 exp_ll=-8967.7510 KL=9379.4062\n",
      "[VI iter 400/800] ELBO=-18032.5039 exp_ll=-8492.8340 KL=9539.6699\n",
      "[VI iter 480/800] ELBO=-17840.7500 exp_ll=-8177.4697 KL=9663.2803\n",
      "[VI iter 560/800] ELBO=-17716.9180 exp_ll=-7958.2495 KL=9758.6689\n",
      "[VI iter 640/800] ELBO=-17632.9961 exp_ll=-7801.0444 KL=9831.9512\n",
      "[VI iter 720/800] ELBO=-17573.7812 exp_ll=-7686.0034 KL=9887.7773\n",
      "[VI iter 800/800] ELBO=-17530.3633 exp_ll=-7600.5889 KL=9929.7754\n",
      "Final test RMSE: 0.1725789970351741\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 65 | labelled size = 670 | pool size = 59330 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.129483, train_rmse=0.287614\n",
      "[Train epoch 5/50] loss=0.061638, train_rmse=0.239057\n",
      "[Train epoch 10/50] loss=0.043919, train_rmse=0.200004\n",
      "[Train epoch 15/50] loss=0.034069, train_rmse=0.185399\n",
      "[Train epoch 20/50] loss=0.027229, train_rmse=0.179640\n",
      "[Train epoch 25/50] loss=0.021982, train_rmse=0.171090\n",
      "[Train epoch 30/50] loss=0.019137, train_rmse=0.170405\n",
      "[Train epoch 35/50] loss=0.018469, train_rmse=0.170393\n",
      "[Train epoch 40/50] loss=0.017298, train_rmse=0.170429\n",
      "[Train epoch 45/50] loss=0.015467, train_rmse=0.168030\n",
      "[Train epoch 50/50] loss=0.013798, train_rmse=0.162622\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-173054.8438 exp_ll=-165491.5469 KL=7563.3008\n",
      "[VI iter 80/800] ELBO=-23791.8086 exp_ll=-15301.6895 KL=8490.1182\n",
      "[VI iter 160/800] ELBO=-20392.7773 exp_ll=-11515.2168 KL=8877.5596\n",
      "[VI iter 240/800] ELBO=-19202.3086 exp_ll=-10046.7471 KL=9155.5615\n",
      "[VI iter 320/800] ELBO=-18610.6523 exp_ll=-9242.0488 KL=9368.6025\n",
      "[VI iter 400/800] ELBO=-18273.0098 exp_ll=-8737.4180 KL=9535.5918\n",
      "[VI iter 480/800] ELBO=-18064.9336 exp_ll=-8397.1797 KL=9667.7549\n",
      "[VI iter 560/800] ELBO=-17929.7109 exp_ll=-8157.0234 KL=9772.6885\n",
      "[VI iter 640/800] ELBO=-17838.0820 exp_ll=-7982.1763 KL=9855.9053\n",
      "[VI iter 720/800] ELBO=-17773.7031 exp_ll=-7852.1113 KL=9921.5908\n",
      "[VI iter 800/800] ELBO=-17726.9297 exp_ll=-7753.9053 KL=9973.0254\n",
      "Final test RMSE: 0.16262184556075895\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 66 | labelled size = 680 | pool size = 59320 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.126559, train_rmse=0.282912\n",
      "[Train epoch 5/50] loss=0.061110, train_rmse=0.232899\n",
      "[Train epoch 10/50] loss=0.042417, train_rmse=0.200976\n",
      "[Train epoch 15/50] loss=0.032496, train_rmse=0.182567\n",
      "[Train epoch 20/50] loss=0.026914, train_rmse=0.173517\n",
      "[Train epoch 25/50] loss=0.023044, train_rmse=0.175059\n",
      "[Train epoch 30/50] loss=0.020204, train_rmse=0.175683\n",
      "[Train epoch 35/50] loss=0.017513, train_rmse=0.169297\n",
      "[Train epoch 40/50] loss=0.016869, train_rmse=0.159254\n",
      "[Train epoch 45/50] loss=0.016750, train_rmse=0.170742\n",
      "[Train epoch 50/50] loss=0.015582, train_rmse=0.161552\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-170786.8906 exp_ll=-163212.1094 KL=7574.7856\n",
      "[VI iter 80/800] ELBO=-24274.5430 exp_ll=-15778.9688 KL=8495.5742\n",
      "[VI iter 160/800] ELBO=-20743.0430 exp_ll=-11850.9844 KL=8892.0576\n",
      "[VI iter 240/800] ELBO=-19448.2266 exp_ll=-10270.7324 KL=9177.4941\n",
      "[VI iter 320/800] ELBO=-18803.3496 exp_ll=-9408.4297 KL=9394.9199\n",
      "[VI iter 400/800] ELBO=-18437.9336 exp_ll=-8873.7139 KL=9564.2188\n",
      "[VI iter 480/800] ELBO=-18213.9531 exp_ll=-8516.5918 KL=9697.3604\n",
      "[VI iter 560/800] ELBO=-18068.7344 exp_ll=-8266.3379 KL=9802.3975\n",
      "[VI iter 640/800] ELBO=-17970.4844 exp_ll=-8085.3389 KL=9885.1445\n",
      "[VI iter 720/800] ELBO=-17901.2461 exp_ll=-7951.2471 KL=9950.0000\n",
      "[VI iter 800/800] ELBO=-17851.0059 exp_ll=-7850.5894 KL=10000.4160\n",
      "Final test RMSE: 0.16155156972571746\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 67 | labelled size = 690 | pool size = 59310 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.131517, train_rmse=0.289215\n",
      "[Train epoch 5/50] loss=0.059922, train_rmse=0.238236\n",
      "[Train epoch 10/50] loss=0.043688, train_rmse=0.202635\n",
      "[Train epoch 15/50] loss=0.033004, train_rmse=0.183970\n",
      "[Train epoch 20/50] loss=0.026839, train_rmse=0.175925\n",
      "[Train epoch 25/50] loss=0.022187, train_rmse=0.174653\n",
      "[Train epoch 30/50] loss=0.021154, train_rmse=0.178523\n",
      "[Train epoch 35/50] loss=0.018136, train_rmse=0.170065\n",
      "[Train epoch 40/50] loss=0.016566, train_rmse=0.160521\n",
      "[Train epoch 45/50] loss=0.015683, train_rmse=0.169079\n",
      "[Train epoch 50/50] loss=0.014625, train_rmse=0.164916\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-169441.9844 exp_ll=-161884.4062 KL=7557.5854\n",
      "[VI iter 80/800] ELBO=-23985.6367 exp_ll=-15517.7324 KL=8467.9033\n",
      "[VI iter 160/800] ELBO=-20637.0332 exp_ll=-11777.0342 KL=8859.9990\n",
      "[VI iter 240/800] ELBO=-19404.3516 exp_ll=-10261.2529 KL=9143.0986\n",
      "[VI iter 320/800] ELBO=-18790.4062 exp_ll=-9431.8291 KL=9358.5781\n",
      "[VI iter 400/800] ELBO=-18440.8262 exp_ll=-8914.9512 KL=9525.8750\n",
      "[VI iter 480/800] ELBO=-18225.7090 exp_ll=-8568.9268 KL=9656.7822\n",
      "[VI iter 560/800] ELBO=-18085.8398 exp_ll=-8326.4932 KL=9759.3457\n",
      "[VI iter 640/800] ELBO=-17990.8008 exp_ll=-8151.3467 KL=9839.4531\n",
      "[VI iter 720/800] ELBO=-17923.6562 exp_ll=-8022.0498 KL=9901.6064\n",
      "[VI iter 800/800] ELBO=-17874.5156 exp_ll=-7925.1592 KL=9949.3555\n",
      "Final test RMSE: 0.16491592263485522\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 68 | labelled size = 700 | pool size = 59300 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.127365, train_rmse=0.284698\n",
      "[Train epoch 5/50] loss=0.061611, train_rmse=0.240250\n",
      "[Train epoch 10/50] loss=0.043244, train_rmse=0.199042\n",
      "[Train epoch 15/50] loss=0.031899, train_rmse=0.180575\n",
      "[Train epoch 20/50] loss=0.025787, train_rmse=0.178350\n",
      "[Train epoch 25/50] loss=0.021448, train_rmse=0.172364\n",
      "[Train epoch 30/50] loss=0.021072, train_rmse=0.174671\n",
      "[Train epoch 35/50] loss=0.017935, train_rmse=0.169487\n",
      "[Train epoch 40/50] loss=0.017783, train_rmse=0.171842\n",
      "[Train epoch 45/50] loss=0.016327, train_rmse=0.171425\n",
      "[Train epoch 50/50] loss=0.015851, train_rmse=0.165875\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-171363.2500 exp_ll=-163799.5000 KL=7563.7524\n",
      "[VI iter 80/800] ELBO=-23749.0332 exp_ll=-15284.2715 KL=8464.7617\n",
      "[VI iter 160/800] ELBO=-20537.5156 exp_ll=-11695.6055 KL=8841.9102\n",
      "[VI iter 240/800] ELBO=-19347.7109 exp_ll=-10233.5127 KL=9114.1992\n",
      "[VI iter 320/800] ELBO=-18754.8809 exp_ll=-9433.5674 KL=9321.3135\n",
      "[VI iter 400/800] ELBO=-18420.4922 exp_ll=-8938.4863 KL=9482.0068\n",
      "[VI iter 480/800] ELBO=-18216.4297 exp_ll=-8608.5938 KL=9607.8359\n",
      "[VI iter 560/800] ELBO=-18084.4766 exp_ll=-8377.8564 KL=9706.6201\n",
      "[VI iter 640/800] ELBO=-17995.1836 exp_ll=-8211.1855 KL=9783.9990\n",
      "[VI iter 720/800] ELBO=-17932.1406 exp_ll=-8087.9170 KL=9844.2236\n",
      "[VI iter 800/800] ELBO=-17886.1680 exp_ll=-7995.5469 KL=9890.6211\n",
      "Final test RMSE: 0.16587505192816926\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 69 | labelled size = 710 | pool size = 59290 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.124998, train_rmse=0.285020\n",
      "[Train epoch 5/50] loss=0.063374, train_rmse=0.238645\n",
      "[Train epoch 10/50] loss=0.044272, train_rmse=0.205136\n",
      "[Train epoch 15/50] loss=0.036670, train_rmse=0.186733\n",
      "[Train epoch 20/50] loss=0.031317, train_rmse=0.183525\n",
      "[Train epoch 25/50] loss=0.026314, train_rmse=0.171154\n",
      "[Train epoch 30/50] loss=0.021808, train_rmse=0.175501\n",
      "[Train epoch 35/50] loss=0.021729, train_rmse=0.170305\n",
      "[Train epoch 40/50] loss=0.021319, train_rmse=0.174591\n",
      "[Train epoch 45/50] loss=0.016115, train_rmse=0.165710\n",
      "[Train epoch 50/50] loss=0.017894, train_rmse=0.168448\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-174284.4688 exp_ll=-166721.1406 KL=7563.3257\n",
      "[VI iter 80/800] ELBO=-25955.4531 exp_ll=-17413.0801 KL=8542.3740\n",
      "[VI iter 160/800] ELBO=-21784.4590 exp_ll=-12814.7754 KL=8969.6836\n",
      "[VI iter 240/800] ELBO=-20271.2969 exp_ll=-10999.0195 KL=9272.2764\n",
      "[VI iter 320/800] ELBO=-19511.5801 exp_ll=-10010.0664 KL=9501.5137\n",
      "[VI iter 400/800] ELBO=-19077.4277 exp_ll=-9397.5840 KL=9679.8438\n",
      "[VI iter 480/800] ELBO=-18809.5898 exp_ll=-8989.1426 KL=9820.4463\n",
      "[VI iter 560/800] ELBO=-18635.1445 exp_ll=-8703.1064 KL=9932.0381\n",
      "[VI iter 640/800] ELBO=-18516.6211 exp_ll=-8495.8203 KL=10020.7998\n",
      "[VI iter 720/800] ELBO=-18433.2383 exp_ll=-8341.8877 KL=10091.3516\n",
      "[VI iter 800/800] ELBO=-18372.6602 exp_ll=-8225.3896 KL=10147.2705\n",
      "Final test RMSE: 0.16844846339454816\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 70 | labelled size = 720 | pool size = 59280 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.129386, train_rmse=0.287278\n",
      "[Train epoch 5/50] loss=0.062388, train_rmse=0.237244\n",
      "[Train epoch 10/50] loss=0.042921, train_rmse=0.201010\n",
      "[Train epoch 15/50] loss=0.032152, train_rmse=0.184028\n",
      "[Train epoch 20/50] loss=0.026508, train_rmse=0.175490\n",
      "[Train epoch 25/50] loss=0.021898, train_rmse=0.171156\n",
      "[Train epoch 30/50] loss=0.021267, train_rmse=0.176215\n",
      "[Train epoch 35/50] loss=0.020172, train_rmse=0.168305\n",
      "[Train epoch 40/50] loss=0.018090, train_rmse=0.164870\n",
      "[Train epoch 45/50] loss=0.017128, train_rmse=0.170330\n",
      "[Train epoch 50/50] loss=0.016517, train_rmse=0.166321\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-174407.8906 exp_ll=-166847.0625 KL=7560.8252\n",
      "[VI iter 80/800] ELBO=-25198.1016 exp_ll=-16679.4082 KL=8518.6934\n",
      "[VI iter 160/800] ELBO=-21420.9453 exp_ll=-12485.3340 KL=8935.6123\n",
      "[VI iter 240/800] ELBO=-20054.2754 exp_ll=-10820.7588 KL=9233.5166\n",
      "[VI iter 320/800] ELBO=-19378.3555 exp_ll=-9918.2812 KL=9460.0742\n",
      "[VI iter 400/800] ELBO=-18994.0566 exp_ll=-9357.3027 KL=9636.7539\n",
      "[VI iter 480/800] ELBO=-18757.0742 exp_ll=-8980.8818 KL=9776.1914\n",
      "[VI iter 560/800] ELBO=-18602.6016 exp_ll=-8715.7988 KL=9886.8027\n",
      "[VI iter 640/800] ELBO=-18497.6406 exp_ll=-8523.0303 KL=9974.6113\n",
      "[VI iter 720/800] ELBO=-18423.6230 exp_ll=-8379.4736 KL=10044.1494\n",
      "[VI iter 800/800] ELBO=-18369.6621 exp_ll=-8270.7139 KL=10098.9482\n",
      "Final test RMSE: 0.16632055463356213\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 71 | labelled size = 730 | pool size = 59270 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.123963, train_rmse=0.285059\n",
      "[Train epoch 5/50] loss=0.060889, train_rmse=0.237445\n",
      "[Train epoch 10/50] loss=0.041211, train_rmse=0.195467\n",
      "[Train epoch 15/50] loss=0.030770, train_rmse=0.177436\n",
      "[Train epoch 20/50] loss=0.025131, train_rmse=0.178652\n",
      "[Train epoch 25/50] loss=0.024754, train_rmse=0.180694\n",
      "[Train epoch 30/50] loss=0.021182, train_rmse=0.168348\n",
      "[Train epoch 35/50] loss=0.018501, train_rmse=0.168483\n",
      "[Train epoch 40/50] loss=0.018707, train_rmse=0.163480\n",
      "[Train epoch 45/50] loss=0.017587, train_rmse=0.163092\n",
      "[Train epoch 50/50] loss=0.015672, train_rmse=0.158432\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-170410.3750 exp_ll=-162843.5469 KL=7566.8340\n",
      "[VI iter 80/800] ELBO=-24334.8340 exp_ll=-15852.8828 KL=8481.9512\n",
      "[VI iter 160/800] ELBO=-20942.1855 exp_ll=-12080.5605 KL=8861.6250\n",
      "[VI iter 240/800] ELBO=-19742.5312 exp_ll=-10607.5195 KL=9135.0107\n",
      "[VI iter 320/800] ELBO=-19138.9531 exp_ll=-9794.3223 KL=9344.6318\n",
      "[VI iter 400/800] ELBO=-18791.9609 exp_ll=-9283.5332 KL=9508.4277\n",
      "[VI iter 480/800] ELBO=-18576.8164 exp_ll=-8939.5957 KL=9637.2217\n",
      "[VI iter 560/800] ELBO=-18436.0547 exp_ll=-8697.5557 KL=9738.4990\n",
      "[VI iter 640/800] ELBO=-18339.9922 exp_ll=-8522.1738 KL=9817.8193\n",
      "[VI iter 720/800] ELBO=-18271.6934 exp_ll=-8392.2100 KL=9879.4834\n",
      "[VI iter 800/800] ELBO=-18221.6172 exp_ll=-8294.7100 KL=9926.9072\n",
      "Final test RMSE: 0.15843223493055375\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 72 | labelled size = 740 | pool size = 59260 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.129296, train_rmse=0.288929\n",
      "[Train epoch 5/50] loss=0.061663, train_rmse=0.239516\n",
      "[Train epoch 10/50] loss=0.044084, train_rmse=0.203649\n",
      "[Train epoch 15/50] loss=0.031323, train_rmse=0.184134\n",
      "[Train epoch 20/50] loss=0.024683, train_rmse=0.171450\n",
      "[Train epoch 25/50] loss=0.021963, train_rmse=0.169972\n",
      "[Train epoch 30/50] loss=0.019769, train_rmse=0.172138\n",
      "[Train epoch 35/50] loss=0.018476, train_rmse=0.167946\n",
      "[Train epoch 40/50] loss=0.017293, train_rmse=0.169713\n",
      "[Train epoch 45/50] loss=0.015443, train_rmse=0.164221\n",
      "[Train epoch 50/50] loss=0.016029, train_rmse=0.166292\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-164740.0781 exp_ll=-157169.8594 KL=7570.2222\n",
      "[VI iter 80/800] ELBO=-24389.3086 exp_ll=-15894.2207 KL=8495.0879\n",
      "[VI iter 160/800] ELBO=-21122.5273 exp_ll=-12227.8066 KL=8894.7217\n",
      "[VI iter 240/800] ELBO=-19896.7656 exp_ll=-10712.3623 KL=9184.4043\n",
      "[VI iter 320/800] ELBO=-19289.8711 exp_ll=-9884.3574 KL=9405.5137\n",
      "[VI iter 400/800] ELBO=-18947.7500 exp_ll=-9369.8203 KL=9577.9297\n",
      "[VI iter 480/800] ELBO=-18739.1562 exp_ll=-9025.4531 KL=9713.7021\n",
      "[VI iter 560/800] ELBO=-18604.6934 exp_ll=-8783.7539 KL=9820.9395\n",
      "[VI iter 640/800] ELBO=-18514.1543 exp_ll=-8608.6826 KL=9905.4717\n",
      "[VI iter 720/800] ELBO=-18450.9238 exp_ll=-8479.2305 KL=9971.6934\n",
      "[VI iter 800/800] ELBO=-18404.8633 exp_ll=-8381.8193 KL=10023.0449\n",
      "Final test RMSE: 0.166291656581439\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 73 | labelled size = 750 | pool size = 59250 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.126838, train_rmse=0.286291\n",
      "[Train epoch 5/50] loss=0.060752, train_rmse=0.238292\n",
      "[Train epoch 10/50] loss=0.042420, train_rmse=0.201701\n",
      "[Train epoch 15/50] loss=0.031388, train_rmse=0.179514\n",
      "[Train epoch 20/50] loss=0.027249, train_rmse=0.175582\n",
      "[Train epoch 25/50] loss=0.021808, train_rmse=0.169360\n",
      "[Train epoch 30/50] loss=0.018862, train_rmse=0.171315\n",
      "[Train epoch 35/50] loss=0.017171, train_rmse=0.166721\n",
      "[Train epoch 40/50] loss=0.017155, train_rmse=0.164385\n",
      "[Train epoch 45/50] loss=0.016645, train_rmse=0.167981\n",
      "[Train epoch 50/50] loss=0.015478, train_rmse=0.165437\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-167034.4219 exp_ll=-159474.9375 KL=7559.4878\n",
      "[VI iter 80/800] ELBO=-24579.9062 exp_ll=-16101.0967 KL=8478.8086\n",
      "[VI iter 160/800] ELBO=-21109.4551 exp_ll=-12236.9590 KL=8872.4961\n",
      "[VI iter 240/800] ELBO=-19876.2227 exp_ll=-10723.1055 KL=9153.1172\n",
      "[VI iter 320/800] ELBO=-19281.9883 exp_ll=-9916.3770 KL=9365.6104\n",
      "[VI iter 400/800] ELBO=-18950.0449 exp_ll=-9419.4814 KL=9530.5635\n",
      "[VI iter 480/800] ELBO=-18747.6816 exp_ll=-9087.7012 KL=9659.9805\n",
      "[VI iter 560/800] ELBO=-18616.5391 exp_ll=-8854.7314 KL=9761.8076\n",
      "[VI iter 640/800] ELBO=-18527.6836 exp_ll=-8685.9346 KL=9841.7480\n",
      "[VI iter 720/800] ELBO=-18464.9277 exp_ll=-8560.8154 KL=9904.1123\n",
      "[VI iter 800/800] ELBO=-18419.1426 exp_ll=-8466.8672 KL=9952.2754\n",
      "Final test RMSE: 0.1654370378286768\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 74 | labelled size = 760 | pool size = 59240 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.125876, train_rmse=0.284874\n",
      "[Train epoch 5/50] loss=0.060085, train_rmse=0.235724\n",
      "[Train epoch 10/50] loss=0.041489, train_rmse=0.192400\n",
      "[Train epoch 15/50] loss=0.031730, train_rmse=0.179125\n",
      "[Train epoch 20/50] loss=0.025355, train_rmse=0.171022\n",
      "[Train epoch 25/50] loss=0.023691, train_rmse=0.171617\n",
      "[Train epoch 30/50] loss=0.019248, train_rmse=0.166262\n",
      "[Train epoch 35/50] loss=0.017851, train_rmse=0.169602\n",
      "[Train epoch 40/50] loss=0.016317, train_rmse=0.168463\n",
      "[Train epoch 45/50] loss=0.015091, train_rmse=0.157802\n",
      "[Train epoch 50/50] loss=0.014927, train_rmse=0.165589\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-167534.3125 exp_ll=-159960.5938 KL=7573.7134\n",
      "[VI iter 80/800] ELBO=-24384.0781 exp_ll=-15889.2891 KL=8494.7900\n",
      "[VI iter 160/800] ELBO=-21123.1660 exp_ll=-12241.8779 KL=8881.2881\n",
      "[VI iter 240/800] ELBO=-19961.0078 exp_ll=-10802.6504 KL=9158.3584\n",
      "[VI iter 320/800] ELBO=-19382.7539 exp_ll=-10013.1738 KL=9369.5791\n",
      "[VI iter 400/800] ELBO=-19052.3477 exp_ll=-9518.5273 KL=9533.8203\n",
      "[VI iter 480/800] ELBO=-18848.0156 exp_ll=-9185.5996 KL=9662.4160\n",
      "[VI iter 560/800] ELBO=-18714.5918 exp_ll=-8951.4619 KL=9763.1299\n",
      "[VI iter 640/800] ELBO=-18623.4258 exp_ll=-8781.7441 KL=9841.6816\n",
      "[VI iter 720/800] ELBO=-18558.7012 exp_ll=-8656.2227 KL=9902.4785\n",
      "[VI iter 800/800] ELBO=-18511.1074 exp_ll=-8562.0938 KL=9949.0137\n",
      "Final test RMSE: 0.16558884354849226\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 75 | labelled size = 770 | pool size = 59230 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.123339, train_rmse=0.285164\n",
      "[Train epoch 5/50] loss=0.063297, train_rmse=0.240920\n",
      "[Train epoch 10/50] loss=0.048847, train_rmse=0.209970\n",
      "[Train epoch 15/50] loss=0.038512, train_rmse=0.187966\n",
      "[Train epoch 20/50] loss=0.032024, train_rmse=0.177073\n",
      "[Train epoch 25/50] loss=0.027630, train_rmse=0.172453\n",
      "[Train epoch 30/50] loss=0.028640, train_rmse=0.177577\n",
      "[Train epoch 35/50] loss=0.024717, train_rmse=0.173199\n",
      "[Train epoch 40/50] loss=0.021343, train_rmse=0.170909\n",
      "[Train epoch 45/50] loss=0.021516, train_rmse=0.164344\n",
      "[Train epoch 50/50] loss=0.018920, train_rmse=0.165438\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-193605.4688 exp_ll=-186053.0000 KL=7552.4712\n",
      "[VI iter 80/800] ELBO=-28292.9297 exp_ll=-19748.2578 KL=8544.6719\n",
      "[VI iter 160/800] ELBO=-23295.3145 exp_ll=-14307.0547 KL=8988.2598\n",
      "[VI iter 240/800] ELBO=-21445.6094 exp_ll=-12142.5762 KL=9303.0322\n",
      "[VI iter 320/800] ELBO=-20528.5879 exp_ll=-10986.5254 KL=9542.0625\n",
      "[VI iter 400/800] ELBO=-20006.7773 exp_ll=-10277.1504 KL=9729.6270\n",
      "[VI iter 480/800] ELBO=-19683.8828 exp_ll=-9804.3281 KL=9879.5557\n",
      "[VI iter 560/800] ELBO=-19472.2324 exp_ll=-9471.5166 KL=10000.7158\n",
      "[VI iter 640/800] ELBO=-19327.6289 exp_ll=-9228.2988 KL=10099.3291\n",
      "[VI iter 720/800] ELBO=-19225.5742 exp_ll=-9045.4990 KL=10180.0762\n",
      "[VI iter 800/800] ELBO=-19152.0430 exp_ll=-8905.5264 KL=10246.5176\n",
      "Final test RMSE: 0.16543776335657456\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 76 | labelled size = 780 | pool size = 59220 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.127220, train_rmse=0.284752\n",
      "[Train epoch 5/50] loss=0.061082, train_rmse=0.236147\n",
      "[Train epoch 10/50] loss=0.042954, train_rmse=0.198443\n",
      "[Train epoch 15/50] loss=0.034506, train_rmse=0.185037\n",
      "[Train epoch 20/50] loss=0.027777, train_rmse=0.170912\n",
      "[Train epoch 25/50] loss=0.024395, train_rmse=0.170797\n",
      "[Train epoch 30/50] loss=0.020529, train_rmse=0.165919\n",
      "[Train epoch 35/50] loss=0.020685, train_rmse=0.171586\n",
      "[Train epoch 40/50] loss=0.018594, train_rmse=0.165012\n",
      "[Train epoch 45/50] loss=0.017502, train_rmse=0.162828\n",
      "[Train epoch 50/50] loss=0.017364, train_rmse=0.156246\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-196048.0000 exp_ll=-188492.1406 KL=7555.8535\n",
      "[VI iter 80/800] ELBO=-26859.3750 exp_ll=-18362.5938 KL=8496.7812\n",
      "[VI iter 160/800] ELBO=-22441.1094 exp_ll=-13530.0596 KL=8911.0498\n",
      "[VI iter 240/800] ELBO=-20880.0234 exp_ll=-11670.1660 KL=9209.8584\n",
      "[VI iter 320/800] ELBO=-20125.3574 exp_ll=-10685.0020 KL=9440.3555\n",
      "[VI iter 400/800] ELBO=-19700.2188 exp_ll=-10077.0850 KL=9623.1338\n",
      "[VI iter 480/800] ELBO=-19438.5820 exp_ll=-9668.5684 KL=9770.0137\n",
      "[VI iter 560/800] ELBO=-19268.1445 exp_ll=-9379.3652 KL=9888.7803\n",
      "[VI iter 640/800] ELBO=-19152.5938 exp_ll=-9167.5840 KL=9985.0098\n",
      "[VI iter 720/800] ELBO=-19071.6270 exp_ll=-9008.7168 KL=10062.9102\n",
      "[VI iter 800/800] ELBO=-19013.2031 exp_ll=-8887.4355 KL=10125.7686\n",
      "Final test RMSE: 0.15624646860328203\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 77 | labelled size = 790 | pool size = 59210 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122301, train_rmse=0.284223\n",
      "[Train epoch 5/50] loss=0.058147, train_rmse=0.231911\n",
      "[Train epoch 10/50] loss=0.041221, train_rmse=0.193016\n",
      "[Train epoch 15/50] loss=0.031733, train_rmse=0.182175\n",
      "[Train epoch 20/50] loss=0.026472, train_rmse=0.172527\n",
      "[Train epoch 25/50] loss=0.022849, train_rmse=0.163416\n",
      "[Train epoch 30/50] loss=0.020165, train_rmse=0.168905\n",
      "[Train epoch 35/50] loss=0.018044, train_rmse=0.161429\n",
      "[Train epoch 40/50] loss=0.017782, train_rmse=0.160559\n",
      "[Train epoch 45/50] loss=0.016404, train_rmse=0.161533\n",
      "[Train epoch 50/50] loss=0.015188, train_rmse=0.157025\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-184742.7812 exp_ll=-177185.5312 KL=7557.2563\n",
      "[VI iter 80/800] ELBO=-25787.4355 exp_ll=-17311.5664 KL=8475.8691\n",
      "[VI iter 160/800] ELBO=-22008.0762 exp_ll=-13136.6650 KL=8871.4111\n",
      "[VI iter 240/800] ELBO=-20631.3359 exp_ll=-11473.4609 KL=9157.8760\n",
      "[VI iter 320/800] ELBO=-19947.5820 exp_ll=-10569.4482 KL=9378.1338\n",
      "[VI iter 400/800] ELBO=-19557.4980 exp_ll=-10006.0586 KL=9551.4395\n",
      "[VI iter 480/800] ELBO=-19316.1797 exp_ll=-9627.0527 KL=9689.1279\n",
      "[VI iter 560/800] ELBO=-19158.3750 exp_ll=-9359.5547 KL=9798.8193\n",
      "[VI iter 640/800] ELBO=-19050.5703 exp_ll=-9164.5176 KL=9886.0537\n",
      "[VI iter 720/800] ELBO=-18974.1602 exp_ll=-9019.0918 KL=9955.0693\n",
      "[VI iter 800/800] ELBO=-18918.1719 exp_ll=-8908.9512 KL=10009.2197\n",
      "Final test RMSE: 0.1570254413953826\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 78 | labelled size = 800 | pool size = 59200 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.123505, train_rmse=0.287258\n",
      "[Train epoch 5/50] loss=0.059975, train_rmse=0.231787\n",
      "[Train epoch 10/50] loss=0.042092, train_rmse=0.201878\n",
      "[Train epoch 15/50] loss=0.032068, train_rmse=0.178805\n",
      "[Train epoch 20/50] loss=0.025178, train_rmse=0.170334\n",
      "[Train epoch 25/50] loss=0.023354, train_rmse=0.167020\n",
      "[Train epoch 30/50] loss=0.019189, train_rmse=0.164361\n",
      "[Train epoch 35/50] loss=0.019203, train_rmse=0.165065\n",
      "[Train epoch 40/50] loss=0.018107, train_rmse=0.161486\n",
      "[Train epoch 45/50] loss=0.015930, train_rmse=0.164673\n",
      "[Train epoch 50/50] loss=0.014778, train_rmse=0.157074\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-193138.4531 exp_ll=-185575.3438 KL=7563.1055\n",
      "[VI iter 80/800] ELBO=-26250.1289 exp_ll=-17774.6758 KL=8475.4541\n",
      "[VI iter 160/800] ELBO=-22415.2656 exp_ll=-13541.6162 KL=8873.6504\n",
      "[VI iter 240/800] ELBO=-20946.3574 exp_ll=-11779.5137 KL=9166.8438\n",
      "[VI iter 320/800] ELBO=-20201.6504 exp_ll=-10807.8330 KL=9393.8174\n",
      "[VI iter 400/800] ELBO=-19775.4336 exp_ll=-10202.2588 KL=9573.1748\n",
      "[VI iter 480/800] ELBO=-19512.8672 exp_ll=-9796.3984 KL=9716.4688\n",
      "[VI iter 560/800] ELBO=-19342.4473 exp_ll=-9510.9092 KL=9831.5381\n",
      "[VI iter 640/800] ELBO=-19227.2012 exp_ll=-9303.1895 KL=9924.0117\n",
      "[VI iter 720/800] ELBO=-19146.4629 exp_ll=-9148.3340 KL=9998.1289\n",
      "[VI iter 800/800] ELBO=-19088.2812 exp_ll=-9031.0781 KL=10057.2031\n",
      "Final test RMSE: 0.15707365572164572\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 79 | labelled size = 810 | pool size = 59190 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122393, train_rmse=0.284432\n",
      "[Train epoch 5/50] loss=0.060529, train_rmse=0.234570\n",
      "[Train epoch 10/50] loss=0.042442, train_rmse=0.198532\n",
      "[Train epoch 15/50] loss=0.032354, train_rmse=0.179821\n",
      "[Train epoch 20/50] loss=0.025778, train_rmse=0.177648\n",
      "[Train epoch 25/50] loss=0.021997, train_rmse=0.167150\n",
      "[Train epoch 30/50] loss=0.020527, train_rmse=0.168133\n",
      "[Train epoch 35/50] loss=0.017857, train_rmse=0.165852\n",
      "[Train epoch 40/50] loss=0.016995, train_rmse=0.162326\n",
      "[Train epoch 45/50] loss=0.016591, train_rmse=0.165496\n",
      "[Train epoch 50/50] loss=0.015201, train_rmse=0.152118\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-196344.0469 exp_ll=-188773.4531 KL=7570.5879\n",
      "[VI iter 80/800] ELBO=-26565.8887 exp_ll=-18078.9062 KL=8486.9824\n",
      "[VI iter 160/800] ELBO=-22553.3809 exp_ll=-13673.4180 KL=8879.9629\n",
      "[VI iter 240/800] ELBO=-21063.9688 exp_ll=-11895.8486 KL=9168.1211\n",
      "[VI iter 320/800] ELBO=-20314.6699 exp_ll=-10922.9102 KL=9391.7598\n",
      "[VI iter 400/800] ELBO=-19885.8535 exp_ll=-10316.7656 KL=9569.0879\n",
      "[VI iter 480/800] ELBO=-19620.8125 exp_ll=-9909.6318 KL=9711.1807\n",
      "[VI iter 560/800] ELBO=-19447.9141 exp_ll=-9622.3828 KL=9825.5312\n",
      "[VI iter 640/800] ELBO=-19330.3164 exp_ll=-9412.7480 KL=9917.5693\n",
      "[VI iter 720/800] ELBO=-19247.4375 exp_ll=-9256.0049 KL=9991.4326\n",
      "[VI iter 800/800] ELBO=-19187.3008 exp_ll=-9136.9150 KL=10050.3857\n",
      "Final test RMSE: 0.15211780619166074\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 80 | labelled size = 820 | pool size = 59180 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122264, train_rmse=0.286760\n",
      "[Train epoch 5/50] loss=0.060164, train_rmse=0.233727\n",
      "[Train epoch 10/50] loss=0.040479, train_rmse=0.190157\n",
      "[Train epoch 15/50] loss=0.031466, train_rmse=0.174831\n",
      "[Train epoch 20/50] loss=0.024934, train_rmse=0.173951\n",
      "[Train epoch 25/50] loss=0.021633, train_rmse=0.171580\n",
      "[Train epoch 30/50] loss=0.018921, train_rmse=0.167343\n",
      "[Train epoch 35/50] loss=0.017755, train_rmse=0.163817\n",
      "[Train epoch 40/50] loss=0.017662, train_rmse=0.166062\n",
      "[Train epoch 45/50] loss=0.016008, train_rmse=0.153355\n",
      "[Train epoch 50/50] loss=0.014912, train_rmse=0.156312\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-194429.0312 exp_ll=-186847.5625 KL=7581.4634\n",
      "[VI iter 80/800] ELBO=-26350.0430 exp_ll=-17872.3887 KL=8477.6543\n",
      "[VI iter 160/800] ELBO=-22505.7227 exp_ll=-13636.0234 KL=8869.6982\n",
      "[VI iter 240/800] ELBO=-21057.1543 exp_ll=-11899.7148 KL=9157.4395\n",
      "[VI iter 320/800] ELBO=-20328.5000 exp_ll=-10948.9863 KL=9379.5137\n",
      "[VI iter 400/800] ELBO=-19911.7266 exp_ll=-10357.1143 KL=9554.6113\n",
      "[VI iter 480/800] ELBO=-19653.9941 exp_ll=-9959.8633 KL=9694.1309\n",
      "[VI iter 560/800] ELBO=-19485.6406 exp_ll=-9679.8555 KL=9805.7842\n",
      "[VI iter 640/800] ELBO=-19370.8633 exp_ll=-9475.7227 KL=9895.1416\n",
      "[VI iter 720/800] ELBO=-19289.8789 exp_ll=-9323.4619 KL=9966.4180\n",
      "[VI iter 800/800] ELBO=-19230.7324 exp_ll=-9207.8154 KL=10022.9170\n",
      "Final test RMSE: 0.15631174764105119\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 81 | labelled size = 830 | pool size = 59170 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.124712, train_rmse=0.285861\n",
      "[Train epoch 5/50] loss=0.059099, train_rmse=0.230667\n",
      "[Train epoch 10/50] loss=0.042640, train_rmse=0.195086\n",
      "[Train epoch 15/50] loss=0.032178, train_rmse=0.179462\n",
      "[Train epoch 20/50] loss=0.026565, train_rmse=0.173349\n",
      "[Train epoch 25/50] loss=0.022361, train_rmse=0.173276\n",
      "[Train epoch 30/50] loss=0.019745, train_rmse=0.170456\n",
      "[Train epoch 35/50] loss=0.016666, train_rmse=0.160520\n",
      "[Train epoch 40/50] loss=0.016531, train_rmse=0.164252\n",
      "[Train epoch 45/50] loss=0.014907, train_rmse=0.162299\n",
      "[Train epoch 50/50] loss=0.015901, train_rmse=0.155557\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-188233.6719 exp_ll=-180686.7344 KL=7546.9355\n",
      "[VI iter 80/800] ELBO=-26387.1406 exp_ll=-17917.4512 KL=8469.6904\n",
      "[VI iter 160/800] ELBO=-22456.8652 exp_ll=-13587.3105 KL=8869.5547\n",
      "[VI iter 240/800] ELBO=-21045.3164 exp_ll=-11885.7910 KL=9159.5244\n",
      "[VI iter 320/800] ELBO=-20349.0000 exp_ll=-10965.7803 KL=9383.2207\n",
      "[VI iter 400/800] ELBO=-19954.5371 exp_ll=-10394.6006 KL=9559.9365\n",
      "[VI iter 480/800] ELBO=-19712.3223 exp_ll=-10011.2715 KL=9701.0508\n",
      "[VI iter 560/800] ELBO=-19555.1719 exp_ll=-9740.9766 KL=9814.1943\n",
      "[VI iter 640/800] ELBO=-19448.7285 exp_ll=-9543.8418 KL=9904.8867\n",
      "[VI iter 720/800] ELBO=-19374.0312 exp_ll=-9396.7070 KL=9977.3232\n",
      "[VI iter 800/800] ELBO=-19319.8945 exp_ll=-9285.0781 KL=10034.8164\n",
      "Final test RMSE: 0.1555567984296707\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 82 | labelled size = 840 | pool size = 59160 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.124568, train_rmse=0.285910\n",
      "[Train epoch 5/50] loss=0.060187, train_rmse=0.234572\n",
      "[Train epoch 10/50] loss=0.044843, train_rmse=0.200135\n",
      "[Train epoch 15/50] loss=0.035935, train_rmse=0.179046\n",
      "[Train epoch 20/50] loss=0.028075, train_rmse=0.173803\n",
      "[Train epoch 25/50] loss=0.026518, train_rmse=0.176929\n",
      "[Train epoch 30/50] loss=0.024568, train_rmse=0.164179\n",
      "[Train epoch 35/50] loss=0.021536, train_rmse=0.169561\n",
      "[Train epoch 40/50] loss=0.018703, train_rmse=0.160278\n",
      "[Train epoch 45/50] loss=0.018597, train_rmse=0.158353\n",
      "[Train epoch 50/50] loss=0.018111, train_rmse=0.161318\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-196686.9219 exp_ll=-189119.4844 KL=7567.4355\n",
      "[VI iter 80/800] ELBO=-27649.8438 exp_ll=-19119.4727 KL=8530.3711\n",
      "[VI iter 160/800] ELBO=-23260.7383 exp_ll=-14312.3438 KL=8948.3955\n",
      "[VI iter 240/800] ELBO=-21671.2188 exp_ll=-12422.3535 KL=9248.8652\n",
      "[VI iter 320/800] ELBO=-20871.4551 exp_ll=-11392.1396 KL=9479.3154\n",
      "[VI iter 400/800] ELBO=-20409.0332 exp_ll=-10748.2705 KL=9660.7627\n",
      "[VI iter 480/800] ELBO=-20119.9414 exp_ll=-10314.3145 KL=9805.6279\n",
      "[VI iter 560/800] ELBO=-19929.4453 exp_ll=-10007.2793 KL=9922.1650\n",
      "[VI iter 640/800] ELBO=-19798.7402 exp_ll=-9782.5029 KL=10016.2373\n",
      "[VI iter 720/800] ELBO=-19706.0781 exp_ll=-9613.8672 KL=10092.2109\n",
      "[VI iter 800/800] ELBO=-19638.5547 exp_ll=-9485.0996 KL=10153.4541\n",
      "Final test RMSE: 0.1613182513820135\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 83 | labelled size = 850 | pool size = 59150 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120587, train_rmse=0.284708\n",
      "[Train epoch 5/50] loss=0.060457, train_rmse=0.228082\n",
      "[Train epoch 10/50] loss=0.043788, train_rmse=0.198189\n",
      "[Train epoch 15/50] loss=0.033267, train_rmse=0.174545\n",
      "[Train epoch 20/50] loss=0.026963, train_rmse=0.173132\n",
      "[Train epoch 25/50] loss=0.021551, train_rmse=0.165084\n",
      "[Train epoch 30/50] loss=0.021208, train_rmse=0.171730\n",
      "[Train epoch 35/50] loss=0.019060, train_rmse=0.167335\n",
      "[Train epoch 40/50] loss=0.018292, train_rmse=0.157330\n",
      "[Train epoch 45/50] loss=0.016539, train_rmse=0.156732\n",
      "[Train epoch 50/50] loss=0.015951, train_rmse=0.160231\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-195168.5312 exp_ll=-187609.4375 KL=7559.0923\n",
      "[VI iter 80/800] ELBO=-26958.7715 exp_ll=-18480.0156 KL=8478.7559\n",
      "[VI iter 160/800] ELBO=-22860.0547 exp_ll=-13982.1152 KL=8877.9404\n",
      "[VI iter 240/800] ELBO=-21377.8887 exp_ll=-12209.7598 KL=9168.1289\n",
      "[VI iter 320/800] ELBO=-20646.1016 exp_ll=-11253.4941 KL=9392.6074\n",
      "[VI iter 400/800] ELBO=-20229.9590 exp_ll=-10659.3643 KL=9570.5947\n",
      "[VI iter 480/800] ELBO=-19973.0977 exp_ll=-10259.7832 KL=9713.3154\n",
      "[VI iter 560/800] ELBO=-19805.5469 exp_ll=-9977.3027 KL=9828.2432\n",
      "[VI iter 640/800] ELBO=-19691.5391 exp_ll=-9770.7744 KL=9920.7646\n",
      "[VI iter 720/800] ELBO=-19611.1602 exp_ll=-9616.1914 KL=9994.9688\n",
      "[VI iter 800/800] ELBO=-19552.6543 exp_ll=-9498.5674 KL=10054.0869\n",
      "Final test RMSE: 0.16023087427861757\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 84 | labelled size = 860 | pool size = 59140 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.124846, train_rmse=0.288637\n",
      "[Train epoch 5/50] loss=0.059856, train_rmse=0.231984\n",
      "[Train epoch 10/50] loss=0.043658, train_rmse=0.195963\n",
      "[Train epoch 15/50] loss=0.032831, train_rmse=0.177278\n",
      "[Train epoch 20/50] loss=0.025108, train_rmse=0.170708\n",
      "[Train epoch 25/50] loss=0.021775, train_rmse=0.169194\n",
      "[Train epoch 30/50] loss=0.020230, train_rmse=0.165315\n",
      "[Train epoch 35/50] loss=0.017713, train_rmse=0.165773\n",
      "[Train epoch 40/50] loss=0.016825, train_rmse=0.158608\n",
      "[Train epoch 45/50] loss=0.015594, train_rmse=0.159347\n",
      "[Train epoch 50/50] loss=0.015951, train_rmse=0.156261\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-197087.2344 exp_ll=-189523.4531 KL=7563.7744\n",
      "[VI iter 80/800] ELBO=-26827.9609 exp_ll=-18358.7520 KL=8469.2080\n",
      "[VI iter 160/800] ELBO=-22867.1289 exp_ll=-14011.4707 KL=8855.6572\n",
      "[VI iter 240/800] ELBO=-21394.5078 exp_ll=-12258.5938 KL=9135.9131\n",
      "[VI iter 320/800] ELBO=-20662.2422 exp_ll=-11310.4482 KL=9351.7930\n",
      "[VI iter 400/800] ELBO=-20245.2500 exp_ll=-10722.8145 KL=9522.4355\n",
      "[VI iter 480/800] ELBO=-19987.8359 exp_ll=-10328.7227 KL=9659.1143\n",
      "[VI iter 560/800] ELBO=-19819.9922 exp_ll=-10050.7383 KL=9769.2529\n",
      "[VI iter 640/800] ELBO=-19705.9023 exp_ll=-9847.7910 KL=9858.1104\n",
      "[VI iter 720/800] ELBO=-19625.6562 exp_ll=-9696.0264 KL=9929.6289\n",
      "[VI iter 800/800] ELBO=-19567.3672 exp_ll=-9580.4814 KL=9986.8867\n",
      "Final test RMSE: 0.15626138046781501\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 85 | labelled size = 870 | pool size = 59130 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120577, train_rmse=0.286339\n",
      "[Train epoch 5/50] loss=0.058955, train_rmse=0.230166\n",
      "[Train epoch 10/50] loss=0.041405, train_rmse=0.193937\n",
      "[Train epoch 15/50] loss=0.031375, train_rmse=0.173994\n",
      "[Train epoch 20/50] loss=0.026368, train_rmse=0.175594\n",
      "[Train epoch 25/50] loss=0.022112, train_rmse=0.162743\n",
      "[Train epoch 30/50] loss=0.019868, train_rmse=0.165988\n",
      "[Train epoch 35/50] loss=0.016981, train_rmse=0.157797\n",
      "[Train epoch 40/50] loss=0.017758, train_rmse=0.160457\n",
      "[Train epoch 45/50] loss=0.014865, train_rmse=0.156233\n",
      "[Train epoch 50/50] loss=0.017006, train_rmse=0.158653\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-175904.5156 exp_ll=-168350.8594 KL=7553.6611\n",
      "[VI iter 80/800] ELBO=-25519.7051 exp_ll=-17061.6367 KL=8458.0684\n",
      "[VI iter 160/800] ELBO=-22204.7988 exp_ll=-13366.4697 KL=8838.3291\n",
      "[VI iter 240/800] ELBO=-21010.5312 exp_ll=-11897.7402 KL=9112.7900\n",
      "[VI iter 320/800] ELBO=-20410.1992 exp_ll=-11087.0557 KL=9323.1445\n",
      "[VI iter 400/800] ELBO=-20064.9609 exp_ll=-10577.4609 KL=9487.4990\n",
      "[VI iter 480/800] ELBO=-19850.5586 exp_ll=-10233.7754 KL=9616.7832\n",
      "[VI iter 560/800] ELBO=-19709.9062 exp_ll=-9991.3984 KL=9718.5088\n",
      "[VI iter 640/800] ELBO=-19613.4570 exp_ll=-9815.2471 KL=9798.2109\n",
      "[VI iter 720/800] ELBO=-19544.7461 exp_ll=-9684.5908 KL=9860.1562\n",
      "[VI iter 800/800] ELBO=-19493.9629 exp_ll=-9586.2197 KL=9907.7432\n",
      "Final test RMSE: 0.1586532402421812\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 86 | labelled size = 880 | pool size = 59120 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122495, train_rmse=0.285252\n",
      "[Train epoch 5/50] loss=0.059441, train_rmse=0.228858\n",
      "[Train epoch 10/50] loss=0.041222, train_rmse=0.192903\n",
      "[Train epoch 15/50] loss=0.030420, train_rmse=0.175982\n",
      "[Train epoch 20/50] loss=0.025639, train_rmse=0.171381\n",
      "[Train epoch 25/50] loss=0.022729, train_rmse=0.162930\n",
      "[Train epoch 30/50] loss=0.018081, train_rmse=0.158027\n",
      "[Train epoch 35/50] loss=0.018014, train_rmse=0.157545\n",
      "[Train epoch 40/50] loss=0.015547, train_rmse=0.162634\n",
      "[Train epoch 45/50] loss=0.015779, train_rmse=0.156133\n",
      "[Train epoch 50/50] loss=0.015326, train_rmse=0.149966\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-206548.0781 exp_ll=-198981.5469 KL=7566.5381\n",
      "[VI iter 80/800] ELBO=-27300.0742 exp_ll=-18837.1016 KL=8462.9736\n",
      "[VI iter 160/800] ELBO=-23181.6875 exp_ll=-14336.5215 KL=8845.1670\n",
      "[VI iter 240/800] ELBO=-21692.1875 exp_ll=-12565.9561 KL=9126.2314\n",
      "[VI iter 320/800] ELBO=-20944.5977 exp_ll=-11598.2744 KL=9346.3242\n",
      "[VI iter 400/800] ELBO=-20514.8223 exp_ll=-10992.0527 KL=9522.7695\n",
      "[VI iter 480/800] ELBO=-20248.1953 exp_ll=-10582.4053 KL=9665.7900\n",
      "[VI iter 560/800] ELBO=-20074.0234 exp_ll=-10291.7686 KL=9782.2539\n",
      "[VI iter 640/800] ELBO=-19955.4297 exp_ll=-10078.2959 KL=9877.1338\n",
      "[VI iter 720/800] ELBO=-19872.0215 exp_ll=-9917.8057 KL=9954.2158\n",
      "[VI iter 800/800] ELBO=-19811.6445 exp_ll=-9795.1523 KL=10016.4922\n",
      "Final test RMSE: 0.14996554978062798\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 87 | labelled size = 890 | pool size = 59110 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120825, train_rmse=0.286789\n",
      "[Train epoch 5/50] loss=0.061228, train_rmse=0.231652\n",
      "[Train epoch 10/50] loss=0.040992, train_rmse=0.188012\n",
      "[Train epoch 15/50] loss=0.030780, train_rmse=0.174386\n",
      "[Train epoch 20/50] loss=0.024257, train_rmse=0.167709\n",
      "[Train epoch 25/50] loss=0.022690, train_rmse=0.164741\n",
      "[Train epoch 30/50] loss=0.018723, train_rmse=0.164426\n",
      "[Train epoch 35/50] loss=0.017724, train_rmse=0.158180\n",
      "[Train epoch 40/50] loss=0.016563, train_rmse=0.157580\n",
      "[Train epoch 45/50] loss=0.014860, train_rmse=0.156552\n",
      "[Train epoch 50/50] loss=0.016231, train_rmse=0.153313\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-194700.9375 exp_ll=-187124.6250 KL=7576.3149\n",
      "[VI iter 80/800] ELBO=-26468.4688 exp_ll=-17995.9473 KL=8472.5225\n",
      "[VI iter 160/800] ELBO=-22851.7500 exp_ll=-14000.8867 KL=8850.8623\n",
      "[VI iter 240/800] ELBO=-21526.1680 exp_ll=-12397.4834 KL=9128.6846\n",
      "[VI iter 320/800] ELBO=-20854.2930 exp_ll=-11509.6074 KL=9344.6846\n",
      "[VI iter 400/800] ELBO=-20464.4199 exp_ll=-10948.4590 KL=9515.9609\n",
      "[VI iter 480/800] ELBO=-20220.5215 exp_ll=-10567.6113 KL=9652.9102\n",
      "[VI iter 560/800] ELBO=-20059.9160 exp_ll=-10297.2256 KL=9762.6904\n",
      "[VI iter 640/800] ELBO=-19949.8008 exp_ll=-10099.2363 KL=9850.5645\n",
      "[VI iter 720/800] ELBO=-19871.6641 exp_ll=-9951.0859 KL=9920.5791\n",
      "[VI iter 800/800] ELBO=-19814.4258 exp_ll=-9838.4795 KL=9975.9453\n",
      "Final test RMSE: 0.15331297712722228\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 88 | labelled size = 900 | pool size = 59100 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122537, train_rmse=0.287367\n",
      "[Train epoch 5/50] loss=0.061974, train_rmse=0.229367\n",
      "[Train epoch 10/50] loss=0.046735, train_rmse=0.196577\n",
      "[Train epoch 15/50] loss=0.037244, train_rmse=0.184241\n",
      "[Train epoch 20/50] loss=0.033453, train_rmse=0.178715\n",
      "[Train epoch 25/50] loss=0.028230, train_rmse=0.174260\n",
      "[Train epoch 30/50] loss=0.024968, train_rmse=0.167534\n",
      "[Train epoch 35/50] loss=0.022493, train_rmse=0.167551\n",
      "[Train epoch 40/50] loss=0.022502, train_rmse=0.166616\n",
      "[Train epoch 45/50] loss=0.021830, train_rmse=0.176550\n",
      "[Train epoch 50/50] loss=0.018991, train_rmse=0.156440\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-201638.0156 exp_ll=-194079.5938 KL=7558.4165\n",
      "[VI iter 80/800] ELBO=-28453.6328 exp_ll=-19933.6934 KL=8519.9385\n",
      "[VI iter 160/800] ELBO=-23906.4492 exp_ll=-14967.8037 KL=8938.6455\n",
      "[VI iter 240/800] ELBO=-22267.4492 exp_ll=-13026.6367 KL=9240.8115\n",
      "[VI iter 320/800] ELBO=-21459.1699 exp_ll=-11984.1377 KL=9475.0322\n",
      "[VI iter 400/800] ELBO=-20999.8320 exp_ll=-11337.6484 KL=9662.1836\n",
      "[VI iter 480/800] ELBO=-20716.4141 exp_ll=-10902.2695 KL=9814.1455\n",
      "[VI iter 560/800] ELBO=-20531.7383 exp_ll=-10593.1387 KL=9938.5996\n",
      "[VI iter 640/800] ELBO=-20406.6016 exp_ll=-10365.6729 KL=10040.9287\n",
      "[VI iter 720/800] ELBO=-20319.1230 exp_ll=-10193.9893 KL=10125.1338\n",
      "[VI iter 800/800] ELBO=-20256.3652 exp_ll=-10062.0410 KL=10194.3242\n",
      "Final test RMSE: 0.15643971214604943\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 89 | labelled size = 910 | pool size = 59090 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120181, train_rmse=0.283530\n",
      "[Train epoch 5/50] loss=0.058856, train_rmse=0.227641\n",
      "[Train epoch 10/50] loss=0.042461, train_rmse=0.189477\n",
      "[Train epoch 15/50] loss=0.031882, train_rmse=0.175303\n",
      "[Train epoch 20/50] loss=0.026944, train_rmse=0.168011\n",
      "[Train epoch 25/50] loss=0.023241, train_rmse=0.162813\n",
      "[Train epoch 30/50] loss=0.021731, train_rmse=0.156835\n",
      "[Train epoch 35/50] loss=0.019568, train_rmse=0.156661\n",
      "[Train epoch 40/50] loss=0.018289, train_rmse=0.159062\n",
      "[Train epoch 45/50] loss=0.015698, train_rmse=0.157966\n",
      "[Train epoch 50/50] loss=0.016725, train_rmse=0.166057\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-189735.0000 exp_ll=-182176.2812 KL=7558.7192\n",
      "[VI iter 80/800] ELBO=-26640.5215 exp_ll=-18166.4688 KL=8474.0527\n",
      "[VI iter 160/800] ELBO=-23057.5508 exp_ll=-14198.2471 KL=8859.3037\n",
      "[VI iter 240/800] ELBO=-21727.1895 exp_ll=-12587.2783 KL=9139.9111\n",
      "[VI iter 320/800] ELBO=-21048.8555 exp_ll=-11692.7256 KL=9356.1289\n",
      "[VI iter 400/800] ELBO=-20656.1484 exp_ll=-11130.0479 KL=9526.1006\n",
      "[VI iter 480/800] ELBO=-20411.0098 exp_ll=-10750.0703 KL=9660.9395\n",
      "[VI iter 560/800] ELBO=-20249.6836 exp_ll=-10481.4014 KL=9768.2832\n",
      "[VI iter 640/800] ELBO=-20139.0430 exp_ll=-10285.3164 KL=9853.7256\n",
      "[VI iter 720/800] ELBO=-20060.5117 exp_ll=-10138.9736 KL=9921.5381\n",
      "[VI iter 800/800] ELBO=-20003.0371 exp_ll=-10027.9561 KL=9975.0811\n",
      "Final test RMSE: 0.1660572999449452\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 90 | labelled size = 920 | pool size = 59080 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.121115, train_rmse=0.286675\n",
      "[Train epoch 5/50] loss=0.059423, train_rmse=0.227950\n",
      "[Train epoch 10/50] loss=0.043518, train_rmse=0.193497\n",
      "[Train epoch 15/50] loss=0.032571, train_rmse=0.176746\n",
      "[Train epoch 20/50] loss=0.025606, train_rmse=0.171940\n",
      "[Train epoch 25/50] loss=0.022675, train_rmse=0.162545\n",
      "[Train epoch 30/50] loss=0.018717, train_rmse=0.161779\n",
      "[Train epoch 35/50] loss=0.019163, train_rmse=0.158671\n",
      "[Train epoch 40/50] loss=0.016660, train_rmse=0.167332\n",
      "[Train epoch 45/50] loss=0.016114, train_rmse=0.155727\n",
      "[Train epoch 50/50] loss=0.015348, train_rmse=0.152222\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-206670.6094 exp_ll=-199106.3906 KL=7564.2183\n",
      "[VI iter 80/800] ELBO=-28028.7988 exp_ll=-19556.5195 KL=8472.2793\n",
      "[VI iter 160/800] ELBO=-23766.1309 exp_ll=-14900.3936 KL=8865.7373\n",
      "[VI iter 240/800] ELBO=-22201.8438 exp_ll=-13048.5225 KL=9153.3213\n",
      "[VI iter 320/800] ELBO=-21416.7539 exp_ll=-12039.9883 KL=9376.7656\n",
      "[VI iter 400/800] ELBO=-20965.4824 exp_ll=-11410.8457 KL=9554.6367\n",
      "[VI iter 480/800] ELBO=-20684.7344 exp_ll=-10986.8613 KL=9697.8721\n",
      "[VI iter 560/800] ELBO=-20500.4277 exp_ll=-10686.6543 KL=9813.7734\n",
      "[VI iter 640/800] ELBO=-20374.3828 exp_ll=-10466.7666 KL=9907.6172\n",
      "[VI iter 720/800] ELBO=-20285.2656 exp_ll=-10301.8584 KL=9983.4072\n",
      "[VI iter 800/800] ELBO=-20220.3203 exp_ll=-10176.0166 KL=10044.3027\n",
      "Final test RMSE: 0.15222213726938544\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 91 | labelled size = 930 | pool size = 59070 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.118609, train_rmse=0.288540\n",
      "[Train epoch 5/50] loss=0.060304, train_rmse=0.228640\n",
      "[Train epoch 10/50] loss=0.041397, train_rmse=0.188087\n",
      "[Train epoch 15/50] loss=0.031234, train_rmse=0.170527\n",
      "[Train epoch 20/50] loss=0.024620, train_rmse=0.170864\n",
      "[Train epoch 25/50] loss=0.021531, train_rmse=0.163336\n",
      "[Train epoch 30/50] loss=0.019535, train_rmse=0.158673\n",
      "[Train epoch 35/50] loss=0.017992, train_rmse=0.158495\n",
      "[Train epoch 40/50] loss=0.016128, train_rmse=0.163058\n",
      "[Train epoch 45/50] loss=0.016294, train_rmse=0.155929\n",
      "[Train epoch 50/50] loss=0.015385, train_rmse=0.153524\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-192717.9531 exp_ll=-185166.8594 KL=7551.0903\n",
      "[VI iter 80/800] ELBO=-26955.3125 exp_ll=-18510.2598 KL=8445.0518\n",
      "[VI iter 160/800] ELBO=-23294.4023 exp_ll=-14470.1035 KL=8824.2988\n",
      "[VI iter 240/800] ELBO=-21897.9512 exp_ll=-12795.3535 KL=9102.5977\n",
      "[VI iter 320/800] ELBO=-21194.8594 exp_ll=-11877.2725 KL=9317.5859\n",
      "[VI iter 400/800] ELBO=-20792.0078 exp_ll=-11304.8398 KL=9487.1680\n",
      "[VI iter 480/800] ELBO=-20542.5723 exp_ll=-10920.3398 KL=9622.2324\n",
      "[VI iter 560/800] ELBO=-20379.5195 exp_ll=-10649.3525 KL=9730.1670\n",
      "[VI iter 640/800] ELBO=-20268.3203 exp_ll=-10451.9922 KL=9816.3291\n",
      "[VI iter 720/800] ELBO=-20189.7070 exp_ll=-10304.9189 KL=9884.7891\n",
      "[VI iter 800/800] ELBO=-20132.2461 exp_ll=-10193.4971 KL=9938.7500\n",
      "Final test RMSE: 0.15352418232525952\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 92 | labelled size = 940 | pool size = 59060 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120804, train_rmse=0.287618\n",
      "[Train epoch 5/50] loss=0.059982, train_rmse=0.226824\n",
      "[Train epoch 10/50] loss=0.042716, train_rmse=0.192676\n",
      "[Train epoch 15/50] loss=0.031673, train_rmse=0.174093\n",
      "[Train epoch 20/50] loss=0.025079, train_rmse=0.165809\n",
      "[Train epoch 25/50] loss=0.022464, train_rmse=0.170055\n",
      "[Train epoch 30/50] loss=0.019981, train_rmse=0.157368\n",
      "[Train epoch 35/50] loss=0.018642, train_rmse=0.157570\n",
      "[Train epoch 40/50] loss=0.016870, train_rmse=0.154498\n",
      "[Train epoch 45/50] loss=0.015807, train_rmse=0.161619\n",
      "[Train epoch 50/50] loss=0.015029, train_rmse=0.150526\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-213919.2656 exp_ll=-206351.2812 KL=7567.9897\n",
      "[VI iter 80/800] ELBO=-27959.4961 exp_ll=-19495.0508 KL=8464.4443\n",
      "[VI iter 160/800] ELBO=-23848.7949 exp_ll=-15001.3916 KL=8847.4033\n",
      "[VI iter 240/800] ELBO=-22348.4531 exp_ll=-13219.5195 KL=9128.9326\n",
      "[VI iter 320/800] ELBO=-21586.6406 exp_ll=-12237.6758 KL=9348.9648\n",
      "[VI iter 400/800] ELBO=-21143.1367 exp_ll=-11618.1543 KL=9524.9834\n",
      "[VI iter 480/800] ELBO=-20864.4062 exp_ll=-11197.0225 KL=9667.3838\n",
      "[VI iter 560/800] ELBO=-20680.0293 exp_ll=-10896.8594 KL=9783.1699\n",
      "[VI iter 640/800] ELBO=-20553.2832 exp_ll=-10675.8701 KL=9877.4131\n",
      "[VI iter 720/800] ELBO=-20463.2441 exp_ll=-10509.2637 KL=9953.9805\n",
      "[VI iter 800/800] ELBO=-20397.4844 exp_ll=-10381.5625 KL=10015.9229\n",
      "Final test RMSE: 0.15052561080725058\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 93 | labelled size = 950 | pool size = 59050 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120650, train_rmse=0.285178\n",
      "[Train epoch 5/50] loss=0.059916, train_rmse=0.227548\n",
      "[Train epoch 10/50] loss=0.040478, train_rmse=0.189659\n",
      "[Train epoch 15/50] loss=0.031061, train_rmse=0.172040\n",
      "[Train epoch 20/50] loss=0.025548, train_rmse=0.164164\n",
      "[Train epoch 25/50] loss=0.021310, train_rmse=0.162682\n",
      "[Train epoch 30/50] loss=0.018933, train_rmse=0.162234\n",
      "[Train epoch 35/50] loss=0.019667, train_rmse=0.161740\n",
      "[Train epoch 40/50] loss=0.016479, train_rmse=0.154549\n",
      "[Train epoch 45/50] loss=0.015852, train_rmse=0.155966\n",
      "[Train epoch 50/50] loss=0.015222, train_rmse=0.154025\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-215084.5781 exp_ll=-207517.3281 KL=7567.2524\n",
      "[VI iter 80/800] ELBO=-27941.4844 exp_ll=-19497.7031 KL=8443.7812\n",
      "[VI iter 160/800] ELBO=-23917.0625 exp_ll=-15094.8633 KL=8822.1982\n",
      "[VI iter 240/800] ELBO=-22402.3008 exp_ll=-13297.8457 KL=9104.4551\n",
      "[VI iter 320/800] ELBO=-21632.4531 exp_ll=-12306.0752 KL=9326.3770\n",
      "[VI iter 400/800] ELBO=-21187.4766 exp_ll=-11683.0527 KL=9504.4248\n",
      "[VI iter 480/800] ELBO=-20910.2559 exp_ll=-11261.6201 KL=9648.6357\n",
      "[VI iter 560/800] ELBO=-20728.4043 exp_ll=-10962.5371 KL=9765.8672\n",
      "[VI iter 640/800] ELBO=-20604.1309 exp_ll=-10742.9932 KL=9861.1377\n",
      "[VI iter 720/800] ELBO=-20516.4648 exp_ll=-10578.1729 KL=9938.2910\n",
      "[VI iter 800/800] ELBO=-20452.3945 exp_ll=-10452.0137 KL=10000.3809\n",
      "Final test RMSE: 0.15402461493378516\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 94 | labelled size = 960 | pool size = 59040 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.118852, train_rmse=0.286040\n",
      "[Train epoch 5/50] loss=0.058091, train_rmse=0.227932\n",
      "[Train epoch 10/50] loss=0.041294, train_rmse=0.190198\n",
      "[Train epoch 15/50] loss=0.030724, train_rmse=0.170124\n",
      "[Train epoch 20/50] loss=0.025478, train_rmse=0.166620\n",
      "[Train epoch 25/50] loss=0.021149, train_rmse=0.161325\n",
      "[Train epoch 30/50] loss=0.020404, train_rmse=0.161299\n",
      "[Train epoch 35/50] loss=0.017927, train_rmse=0.158166\n",
      "[Train epoch 40/50] loss=0.017149, train_rmse=0.154781\n",
      "[Train epoch 45/50] loss=0.017096, train_rmse=0.159937\n",
      "[Train epoch 50/50] loss=0.015702, train_rmse=0.156633\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-203448.4375 exp_ll=-195900.3750 KL=7548.0625\n",
      "[VI iter 80/800] ELBO=-27630.6270 exp_ll=-19176.1367 KL=8454.4902\n",
      "[VI iter 160/800] ELBO=-23675.6484 exp_ll=-14838.3555 KL=8837.2939\n",
      "[VI iter 240/800] ELBO=-22258.3164 exp_ll=-13143.2852 KL=9115.0312\n",
      "[VI iter 320/800] ELBO=-21550.4258 exp_ll=-12219.8750 KL=9330.5508\n",
      "[VI iter 400/800] ELBO=-21144.5391 exp_ll=-11642.5195 KL=9502.0205\n",
      "[VI iter 480/800] ELBO=-20892.4199 exp_ll=-11252.4385 KL=9639.9814\n",
      "[VI iter 560/800] ELBO=-20727.1328 exp_ll=-10975.6953 KL=9751.4375\n",
      "[VI iter 640/800] ELBO=-20614.2539 exp_ll=-10772.8027 KL=9841.4502\n",
      "[VI iter 720/800] ELBO=-20534.5371 exp_ll=-10620.6494 KL=9913.8877\n",
      "[VI iter 800/800] ELBO=-20476.5234 exp_ll=-10504.7051 KL=9971.8184\n",
      "Final test RMSE: 0.15663303305476106\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 95 | labelled size = 970 | pool size = 59030 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.114740, train_rmse=0.284517\n",
      "[Train epoch 5/50] loss=0.060195, train_rmse=0.223674\n",
      "[Train epoch 10/50] loss=0.042106, train_rmse=0.193651\n",
      "[Train epoch 15/50] loss=0.032522, train_rmse=0.171358\n",
      "[Train epoch 20/50] loss=0.027050, train_rmse=0.165028\n",
      "[Train epoch 25/50] loss=0.023660, train_rmse=0.160864\n",
      "[Train epoch 30/50] loss=0.021321, train_rmse=0.156846\n",
      "[Train epoch 35/50] loss=0.019835, train_rmse=0.155938\n",
      "[Train epoch 40/50] loss=0.019691, train_rmse=0.163090\n",
      "[Train epoch 45/50] loss=0.018349, train_rmse=0.154317\n",
      "[Train epoch 50/50] loss=0.017290, train_rmse=0.156241\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-202601.1562 exp_ll=-195013.2500 KL=7587.9058\n",
      "[VI iter 80/800] ELBO=-28306.0684 exp_ll=-19795.5645 KL=8510.5039\n",
      "[VI iter 160/800] ELBO=-24137.9375 exp_ll=-15233.8086 KL=8904.1299\n",
      "[VI iter 240/800] ELBO=-22604.3359 exp_ll=-13414.5508 KL=9189.7852\n",
      "[VI iter 320/800] ELBO=-21840.5605 exp_ll=-12429.8223 KL=9410.7383\n",
      "[VI iter 400/800] ELBO=-21405.4727 exp_ll=-11819.3066 KL=9586.1660\n",
      "[VI iter 480/800] ELBO=-21136.7227 exp_ll=-11409.5342 KL=9727.1875\n",
      "[VI iter 560/800] ELBO=-20961.0820 exp_ll=-11119.9727 KL=9841.1094\n",
      "[VI iter 640/800] ELBO=-20841.2461 exp_ll=-10908.0615 KL=9933.1855\n",
      "[VI iter 720/800] ELBO=-20756.6836 exp_ll=-10749.2744 KL=10007.4102\n",
      "[VI iter 800/800] ELBO=-20695.0156 exp_ll=-10628.0693 KL=10066.9453\n",
      "Final test RMSE: 0.15624095799032772\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 96 | labelled size = 980 | pool size = 59020 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.117834, train_rmse=0.282823\n",
      "[Train epoch 5/50] loss=0.057861, train_rmse=0.225486\n",
      "[Train epoch 10/50] loss=0.040761, train_rmse=0.185035\n",
      "[Train epoch 15/50] loss=0.031587, train_rmse=0.177945\n",
      "[Train epoch 20/50] loss=0.025715, train_rmse=0.165212\n",
      "[Train epoch 25/50] loss=0.022075, train_rmse=0.161237\n",
      "[Train epoch 30/50] loss=0.020569, train_rmse=0.160959\n",
      "[Train epoch 35/50] loss=0.016563, train_rmse=0.157013\n",
      "[Train epoch 40/50] loss=0.016575, train_rmse=0.160755\n",
      "[Train epoch 45/50] loss=0.016845, train_rmse=0.154515\n",
      "[Train epoch 50/50] loss=0.015511, train_rmse=0.155749\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-203624.2656 exp_ll=-196061.3750 KL=7562.8848\n",
      "[VI iter 80/800] ELBO=-28064.2793 exp_ll=-19595.3418 KL=8468.9375\n",
      "[VI iter 160/800] ELBO=-23923.6973 exp_ll=-15065.8438 KL=8857.8535\n",
      "[VI iter 240/800] ELBO=-22462.6074 exp_ll=-13323.6777 KL=9138.9297\n",
      "[VI iter 320/800] ELBO=-21750.7148 exp_ll=-12394.4971 KL=9356.2178\n",
      "[VI iter 400/800] ELBO=-21347.6758 exp_ll=-11818.8477 KL=9528.8281\n",
      "[VI iter 480/800] ELBO=-21098.6875 exp_ll=-11430.9590 KL=9667.7285\n",
      "[VI iter 560/800] ELBO=-20936.1152 exp_ll=-11155.9971 KL=9780.1182\n",
      "[VI iter 640/800] ELBO=-20825.4395 exp_ll=-10954.3154 KL=9871.1240\n",
      "[VI iter 720/800] ELBO=-20747.4883 exp_ll=-10802.8770 KL=9944.6123\n",
      "[VI iter 800/800] ELBO=-20690.9316 exp_ll=-10687.2998 KL=10003.6318\n",
      "Final test RMSE: 0.15574868862647082\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 97 | labelled size = 990 | pool size = 59010 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.117191, train_rmse=0.282871\n",
      "[Train epoch 5/50] loss=0.058191, train_rmse=0.224001\n",
      "[Train epoch 10/50] loss=0.040604, train_rmse=0.186946\n",
      "[Train epoch 15/50] loss=0.030877, train_rmse=0.173921\n",
      "[Train epoch 20/50] loss=0.025610, train_rmse=0.168015\n",
      "[Train epoch 25/50] loss=0.022807, train_rmse=0.159807\n",
      "[Train epoch 30/50] loss=0.020586, train_rmse=0.166123\n",
      "[Train epoch 35/50] loss=0.018699, train_rmse=0.154036\n",
      "[Train epoch 40/50] loss=0.017286, train_rmse=0.156097\n",
      "[Train epoch 45/50] loss=0.017113, train_rmse=0.150776\n",
      "[Train epoch 50/50] loss=0.015930, train_rmse=0.147890\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-216809.5000 exp_ll=-209250.8594 KL=7558.6475\n",
      "[VI iter 80/800] ELBO=-28671.1055 exp_ll=-20213.1016 KL=8458.0029\n",
      "[VI iter 160/800] ELBO=-24435.2324 exp_ll=-15590.8984 KL=8844.3340\n",
      "[VI iter 240/800] ELBO=-22865.8066 exp_ll=-13737.0723 KL=9128.7344\n",
      "[VI iter 320/800] ELBO=-22074.2949 exp_ll=-12723.5449 KL=9350.7500\n",
      "[VI iter 400/800] ELBO=-21618.1055 exp_ll=-12090.0195 KL=9528.0869\n",
      "[VI iter 480/800] ELBO=-21334.0586 exp_ll=-11662.7344 KL=9671.3232\n",
      "[VI iter 560/800] ELBO=-21147.5234 exp_ll=-11359.9219 KL=9787.6016\n",
      "[VI iter 640/800] ELBO=-21019.9258 exp_ll=-11137.8242 KL=9882.1025\n",
      "[VI iter 720/800] ELBO=-20929.6211 exp_ll=-10970.8545 KL=9958.7676\n",
      "[VI iter 800/800] ELBO=-20863.7441 exp_ll=-10843.0430 KL=10020.7012\n",
      "Final test RMSE: 0.14788995214471437\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 98 | labelled size = 1000 | pool size = 59000 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.116790, train_rmse=0.284795\n",
      "[Train epoch 5/50] loss=0.057646, train_rmse=0.221075\n",
      "[Train epoch 10/50] loss=0.041096, train_rmse=0.187264\n",
      "[Train epoch 15/50] loss=0.031345, train_rmse=0.171562\n",
      "[Train epoch 20/50] loss=0.024252, train_rmse=0.165171\n",
      "[Train epoch 25/50] loss=0.021114, train_rmse=0.160850\n",
      "[Train epoch 30/50] loss=0.019040, train_rmse=0.155861\n",
      "[Train epoch 35/50] loss=0.017654, train_rmse=0.156258\n",
      "[Train epoch 40/50] loss=0.016799, train_rmse=0.154156\n",
      "[Train epoch 45/50] loss=0.016781, train_rmse=0.148752\n",
      "[Train epoch 50/50] loss=0.016064, train_rmse=0.155345\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-217904.7656 exp_ll=-210349.1406 KL=7555.6250\n",
      "[VI iter 80/800] ELBO=-28353.3477 exp_ll=-19907.3047 KL=8446.0430\n",
      "[VI iter 160/800] ELBO=-24170.3262 exp_ll=-15351.8203 KL=8818.5059\n",
      "[VI iter 240/800] ELBO=-22737.4180 exp_ll=-13647.9570 KL=9089.4600\n",
      "[VI iter 320/800] ELBO=-22016.0449 exp_ll=-12714.5771 KL=9301.4678\n",
      "[VI iter 400/800] ELBO=-21593.3848 exp_ll=-12121.9395 KL=9471.4453\n",
      "[VI iter 480/800] ELBO=-21325.4375 exp_ll=-11716.3779 KL=9609.0596\n",
      "[VI iter 560/800] ELBO=-21146.6406 exp_ll=-11425.7920 KL=9720.8486\n",
      "[VI iter 640/800] ELBO=-21022.6113 exp_ll=-11210.9814 KL=9811.6299\n",
      "[VI iter 720/800] ELBO=-20933.7676 exp_ll=-11048.6367 KL=9885.1309\n",
      "[VI iter 800/800] ELBO=-20868.3164 exp_ll=-10923.9873 KL=9944.3281\n",
      "Final test RMSE: 0.15534547596941264\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 99 | labelled size = 1010 | pool size = 58990 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.116496, train_rmse=0.284162\n",
      "[Train epoch 5/50] loss=0.058092, train_rmse=0.226055\n",
      "[Train epoch 10/50] loss=0.041101, train_rmse=0.193063\n",
      "[Train epoch 15/50] loss=0.030944, train_rmse=0.171783\n",
      "[Train epoch 20/50] loss=0.023782, train_rmse=0.162726\n",
      "[Train epoch 25/50] loss=0.022380, train_rmse=0.161885\n",
      "[Train epoch 30/50] loss=0.019126, train_rmse=0.158379\n",
      "[Train epoch 35/50] loss=0.017258, train_rmse=0.161842\n",
      "[Train epoch 40/50] loss=0.015608, train_rmse=0.160499\n",
      "[Train epoch 45/50] loss=0.016925, train_rmse=0.156977\n",
      "[Train epoch 50/50] loss=0.016377, train_rmse=0.159353\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-197272.1562 exp_ll=-189714.6406 KL=7557.5142\n",
      "[VI iter 80/800] ELBO=-27707.3477 exp_ll=-19265.2812 KL=8442.0654\n",
      "[VI iter 160/800] ELBO=-23974.9355 exp_ll=-15160.0273 KL=8814.9082\n",
      "[VI iter 240/800] ELBO=-22605.5273 exp_ll=-13517.1631 KL=9088.3633\n",
      "[VI iter 320/800] ELBO=-21913.7070 exp_ll=-12613.2266 KL=9300.4814\n",
      "[VI iter 400/800] ELBO=-21514.7383 exp_ll=-12046.3203 KL=9468.4170\n",
      "[VI iter 480/800] ELBO=-21266.6152 exp_ll=-11664.0908 KL=9602.5244\n",
      "[VI iter 560/800] ELBO=-21103.8867 exp_ll=-11394.0068 KL=9709.8799\n",
      "[VI iter 640/800] ELBO=-20992.6094 exp_ll=-11196.9375 KL=9795.6729\n",
      "[VI iter 720/800] ELBO=-20913.9023 exp_ll=-11050.0088 KL=9863.8945\n",
      "[VI iter 800/800] ELBO=-20855.8125 exp_ll=-10938.0898 KL=9917.7236\n",
      "Final test RMSE: 0.15935283054917607\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 100 | labelled size = 1020 | pool size = 58980 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.116546, train_rmse=0.286117\n",
      "[Train epoch 5/50] loss=0.059800, train_rmse=0.225367\n",
      "[Train epoch 10/50] loss=0.041997, train_rmse=0.187770\n",
      "[Train epoch 15/50] loss=0.031811, train_rmse=0.173447\n",
      "[Train epoch 20/50] loss=0.025520, train_rmse=0.164159\n",
      "[Train epoch 25/50] loss=0.023238, train_rmse=0.162039\n",
      "[Train epoch 30/50] loss=0.020448, train_rmse=0.155009\n",
      "[Train epoch 35/50] loss=0.018059, train_rmse=0.160746\n",
      "[Train epoch 40/50] loss=0.016764, train_rmse=0.158584\n",
      "[Train epoch 45/50] loss=0.015734, train_rmse=0.158401\n",
      "[Train epoch 50/50] loss=0.015054, train_rmse=0.158877\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-195605.6250 exp_ll=-188043.3125 KL=7562.3169\n",
      "[VI iter 80/800] ELBO=-27636.9746 exp_ll=-19183.1094 KL=8453.8652\n",
      "[VI iter 160/800] ELBO=-23972.4551 exp_ll=-15141.9932 KL=8830.4619\n",
      "[VI iter 240/800] ELBO=-22629.8965 exp_ll=-13525.9590 KL=9103.9375\n",
      "[VI iter 320/800] ELBO=-21961.7012 exp_ll=-12647.4180 KL=9314.2832\n",
      "[VI iter 400/800] ELBO=-21578.8281 exp_ll=-12098.8936 KL=9479.9336\n",
      "[VI iter 480/800] ELBO=-21340.5488 exp_ll=-11728.7646 KL=9611.7842\n",
      "[VI iter 560/800] ELBO=-21183.6895 exp_ll=-11466.5508 KL=9717.1387\n",
      "[VI iter 640/800] ELBO=-21075.9004 exp_ll=-11274.6260 KL=9801.2744\n",
      "[VI iter 720/800] ELBO=-20999.1094 exp_ll=-11130.9180 KL=9868.1924\n",
      "[VI iter 800/800] ELBO=-20942.6719 exp_ll=-11021.6445 KL=9921.0283\n",
      "Final test RMSE: 0.1588772618832813\n",
      "Results saved to outputs/bnn_mfvi/history_BNN_MFVI_full_PredCovariance_Run1.json\n",
      "\n",
      "\n",
      "========== Running PredCovariance Seed 4 ==========\n",
      "Training dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "Initial Labelled set size: 20\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "\n",
      "=== Acquisition iteration 0 | labelled size = 20 | pool size = 59980 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.149429, train_rmse=0.317133\n",
      "[Train epoch 5/50] loss=0.119764, train_rmse=0.293240\n",
      "[Train epoch 10/50] loss=0.076251, train_rmse=0.285277\n",
      "[Train epoch 15/50] loss=0.057850, train_rmse=0.278125\n",
      "[Train epoch 20/50] loss=0.046630, train_rmse=0.277298\n",
      "[Train epoch 25/50] loss=0.035609, train_rmse=0.275440\n",
      "[Train epoch 30/50] loss=0.028332, train_rmse=0.271927\n",
      "[Train epoch 35/50] loss=0.025774, train_rmse=0.271689\n",
      "[Train epoch 40/50] loss=0.022811, train_rmse=0.273892\n",
      "[Train epoch 45/50] loss=0.021035, train_rmse=0.274282\n",
      "[Train epoch 50/50] loss=0.023727, train_rmse=0.274801\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-15314.2344 exp_ll=-7745.4565 KL=7568.7778\n",
      "[VI iter 80/800] ELBO=-7654.6812 exp_ll=-546.1282 KL=7108.5527\n",
      "[VI iter 160/800] ELBO=-6154.4365 exp_ll=-483.1866 KL=5671.2500\n",
      "[VI iter 240/800] ELBO=-4652.0454 exp_ll=-500.3132 KL=4151.7324\n",
      "[VI iter 320/800] ELBO=-3304.5684 exp_ll=-518.6722 KL=2785.8962\n",
      "[VI iter 400/800] ELBO=-2363.9883 exp_ll=-521.5189 KL=1842.4692\n",
      "[VI iter 480/800] ELBO=-1887.7212 exp_ll=-483.5904 KL=1404.1309\n",
      "[VI iter 560/800] ELBO=-1686.4189 exp_ll=-457.9246 KL=1228.4944\n",
      "[VI iter 640/800] ELBO=-1542.0178 exp_ll=-392.8996 KL=1149.1182\n",
      "[VI iter 720/800] ELBO=-1482.1195 exp_ll=-375.2985 KL=1106.8210\n",
      "[VI iter 800/800] ELBO=-1437.7007 exp_ll=-355.6858 KL=1082.0149\n",
      "Final test RMSE: 0.27480083987234\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 1 | labelled size = 30 | pool size = 59970 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.177591, train_rmse=0.314571\n",
      "[Train epoch 5/50] loss=0.106953, train_rmse=0.290386\n",
      "[Train epoch 10/50] loss=0.077022, train_rmse=0.283648\n",
      "[Train epoch 15/50] loss=0.054485, train_rmse=0.278501\n",
      "[Train epoch 20/50] loss=0.047493, train_rmse=0.273768\n",
      "[Train epoch 25/50] loss=0.033019, train_rmse=0.270070\n",
      "[Train epoch 30/50] loss=0.038608, train_rmse=0.267624\n",
      "[Train epoch 35/50] loss=0.025998, train_rmse=0.265595\n",
      "[Train epoch 40/50] loss=0.026846, train_rmse=0.263415\n",
      "[Train epoch 45/50] loss=0.026012, train_rmse=0.265766\n",
      "[Train epoch 50/50] loss=0.024447, train_rmse=0.266875\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-19420.0273 exp_ll=-11857.7861 KL=7562.2407\n",
      "[VI iter 80/800] ELBO=-8247.6719 exp_ll=-748.0098 KL=7499.6626\n",
      "[VI iter 160/800] ELBO=-7119.3008 exp_ll=-635.0786 KL=6484.2222\n",
      "[VI iter 240/800] ELBO=-5953.5195 exp_ll=-637.0467 KL=5316.4727\n",
      "[VI iter 320/800] ELBO=-4812.0303 exp_ll=-654.7382 KL=4157.2920\n",
      "[VI iter 400/800] ELBO=-3830.0815 exp_ll=-675.4683 KL=3154.6133\n",
      "[VI iter 480/800] ELBO=-3111.7690 exp_ll=-664.2003 KL=2447.5688\n",
      "[VI iter 560/800] ELBO=-2696.7473 exp_ll=-654.8181 KL=2041.9292\n",
      "[VI iter 640/800] ELBO=-2466.7324 exp_ll=-640.4998 KL=1826.2327\n",
      "[VI iter 720/800] ELBO=-2294.2078 exp_ll=-579.8346 KL=1714.3732\n",
      "[VI iter 800/800] ELBO=-2192.7061 exp_ll=-537.9178 KL=1654.7883\n",
      "Final test RMSE: 0.26687467254332703\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 2 | labelled size = 40 | pool size = 59960 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.209966, train_rmse=0.310533\n",
      "[Train epoch 5/50] loss=0.107318, train_rmse=0.289690\n",
      "[Train epoch 10/50] loss=0.067940, train_rmse=0.281421\n",
      "[Train epoch 15/50] loss=0.054745, train_rmse=0.276184\n",
      "[Train epoch 20/50] loss=0.044510, train_rmse=0.272493\n",
      "[Train epoch 25/50] loss=0.032998, train_rmse=0.266497\n",
      "[Train epoch 30/50] loss=0.027786, train_rmse=0.262986\n",
      "[Train epoch 35/50] loss=0.026221, train_rmse=0.260553\n",
      "[Train epoch 40/50] loss=0.024936, train_rmse=0.260044\n",
      "[Train epoch 45/50] loss=0.023633, train_rmse=0.259705\n",
      "[Train epoch 50/50] loss=0.018793, train_rmse=0.260239\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-24645.4297 exp_ll=-17085.4043 KL=7560.0244\n",
      "[VI iter 80/800] ELBO=-8916.8691 exp_ll=-1162.1816 KL=7754.6875\n",
      "[VI iter 160/800] ELBO=-7979.4629 exp_ll=-901.1536 KL=7078.3096\n",
      "[VI iter 240/800] ELBO=-7086.5186 exp_ll=-849.4739 KL=6237.0449\n",
      "[VI iter 320/800] ELBO=-6197.1885 exp_ll=-849.9426 KL=5347.2456\n",
      "[VI iter 400/800] ELBO=-5360.6309 exp_ll=-868.6470 KL=4491.9839\n",
      "[VI iter 480/800] ELBO=-4627.4292 exp_ll=-866.7440 KL=3760.6851\n",
      "[VI iter 560/800] ELBO=-4059.6396 exp_ll=-860.4552 KL=3199.1843\n",
      "[VI iter 640/800] ELBO=-3647.7656 exp_ll=-843.8431 KL=2803.9226\n",
      "[VI iter 720/800] ELBO=-3346.0161 exp_ll=-807.1344 KL=2538.8816\n",
      "[VI iter 800/800] ELBO=-3145.3535 exp_ll=-782.8665 KL=2362.4871\n",
      "Final test RMSE: 0.2602392040618876\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 3 | labelled size = 50 | pool size = 59950 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.190215, train_rmse=0.317788\n",
      "[Train epoch 5/50] loss=0.088521, train_rmse=0.288543\n",
      "[Train epoch 10/50] loss=0.068422, train_rmse=0.281020\n",
      "[Train epoch 15/50] loss=0.048917, train_rmse=0.271458\n",
      "[Train epoch 20/50] loss=0.048540, train_rmse=0.266191\n",
      "[Train epoch 25/50] loss=0.039280, train_rmse=0.264067\n",
      "[Train epoch 30/50] loss=0.033928, train_rmse=0.260177\n",
      "[Train epoch 35/50] loss=0.032437, train_rmse=0.253968\n",
      "[Train epoch 40/50] loss=0.027661, train_rmse=0.253417\n",
      "[Train epoch 45/50] loss=0.023846, train_rmse=0.253968\n",
      "[Train epoch 50/50] loss=0.022687, train_rmse=0.257238\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-27271.3027 exp_ll=-19718.8809 KL=7552.4219\n",
      "[VI iter 80/800] ELBO=-9317.5762 exp_ll=-1426.9257 KL=7890.6504\n",
      "[VI iter 160/800] ELBO=-8476.8711 exp_ll=-1106.5502 KL=7370.3208\n",
      "[VI iter 240/800] ELBO=-7730.1631 exp_ll=-1034.1272 KL=6696.0356\n",
      "[VI iter 320/800] ELBO=-6984.9375 exp_ll=-1017.8218 KL=5967.1157\n",
      "[VI iter 400/800] ELBO=-6260.3398 exp_ll=-1019.4291 KL=5240.9106\n",
      "[VI iter 480/800] ELBO=-5603.9346 exp_ll=-1032.8834 KL=4571.0513\n",
      "[VI iter 560/800] ELBO=-5025.4321 exp_ll=-1023.9049 KL=4001.5273\n",
      "[VI iter 640/800] ELBO=-4574.6436 exp_ll=-1021.6676 KL=3552.9758\n",
      "[VI iter 720/800] ELBO=-4213.7158 exp_ll=-1002.4139 KL=3211.3018\n",
      "[VI iter 800/800] ELBO=-3953.6868 exp_ll=-991.7373 KL=2961.9495\n",
      "Final test RMSE: 0.2572380685328507\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 4 | labelled size = 60 | pool size = 59940 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.174291, train_rmse=0.311265\n",
      "[Train epoch 5/50] loss=0.093295, train_rmse=0.285405\n",
      "[Train epoch 10/50] loss=0.062009, train_rmse=0.274860\n",
      "[Train epoch 15/50] loss=0.054612, train_rmse=0.269368\n",
      "[Train epoch 20/50] loss=0.046985, train_rmse=0.264762\n",
      "[Train epoch 25/50] loss=0.040955, train_rmse=0.259424\n",
      "[Train epoch 30/50] loss=0.035619, train_rmse=0.254545\n",
      "[Train epoch 35/50] loss=0.031391, train_rmse=0.253209\n",
      "[Train epoch 40/50] loss=0.026323, train_rmse=0.253118\n",
      "[Train epoch 45/50] loss=0.023158, train_rmse=0.251680\n",
      "[Train epoch 50/50] loss=0.020446, train_rmse=0.250777\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-31697.8750 exp_ll=-24137.9863 KL=7559.8877\n",
      "[VI iter 80/800] ELBO=-9901.6318 exp_ll=-1875.9065 KL=8025.7251\n",
      "[VI iter 160/800] ELBO=-9067.0078 exp_ll=-1400.3628 KL=7666.6455\n",
      "[VI iter 240/800] ELBO=-8421.5645 exp_ll=-1266.5032 KL=7155.0610\n",
      "[VI iter 320/800] ELBO=-7806.2021 exp_ll=-1219.8676 KL=6586.3345\n",
      "[VI iter 400/800] ELBO=-7212.0342 exp_ll=-1204.0847 KL=6007.9492\n",
      "[VI iter 480/800] ELBO=-6655.7583 exp_ll=-1204.3745 KL=5451.3838\n",
      "[VI iter 560/800] ELBO=-6151.8862 exp_ll=-1208.7548 KL=4943.1313\n",
      "[VI iter 640/800] ELBO=-5700.1025 exp_ll=-1198.1277 KL=4501.9746\n",
      "[VI iter 720/800] ELBO=-5333.1895 exp_ll=-1203.8978 KL=4129.2915\n",
      "[VI iter 800/800] ELBO=-5009.0127 exp_ll=-1189.6545 KL=3819.3579\n",
      "Final test RMSE: 0.25077731799314185\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 5 | labelled size = 70 | pool size = 59930 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.178985, train_rmse=0.310377\n",
      "[Train epoch 5/50] loss=0.092913, train_rmse=0.286542\n",
      "[Train epoch 10/50] loss=0.069351, train_rmse=0.279707\n",
      "[Train epoch 15/50] loss=0.059220, train_rmse=0.269721\n",
      "[Train epoch 20/50] loss=0.050354, train_rmse=0.263855\n",
      "[Train epoch 25/50] loss=0.042727, train_rmse=0.261840\n",
      "[Train epoch 30/50] loss=0.041735, train_rmse=0.259314\n",
      "[Train epoch 35/50] loss=0.038863, train_rmse=0.256401\n",
      "[Train epoch 40/50] loss=0.034225, train_rmse=0.250249\n",
      "[Train epoch 45/50] loss=0.031363, train_rmse=0.247345\n",
      "[Train epoch 50/50] loss=0.031595, train_rmse=0.251362\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-32946.5703 exp_ll=-25379.1934 KL=7567.3755\n",
      "[VI iter 80/800] ELBO=-10104.1719 exp_ll=-2022.0836 KL=8082.0879\n",
      "[VI iter 160/800] ELBO=-9303.0186 exp_ll=-1518.2805 KL=7784.7378\n",
      "[VI iter 240/800] ELBO=-8716.9150 exp_ll=-1380.8556 KL=7336.0591\n",
      "[VI iter 320/800] ELBO=-8162.0586 exp_ll=-1331.7065 KL=6830.3521\n",
      "[VI iter 400/800] ELBO=-7627.5205 exp_ll=-1314.4143 KL=6313.1060\n",
      "[VI iter 480/800] ELBO=-7124.8408 exp_ll=-1310.8529 KL=5813.9878\n",
      "[VI iter 560/800] ELBO=-6669.0479 exp_ll=-1315.3658 KL=5353.6821\n",
      "[VI iter 640/800] ELBO=-6259.5425 exp_ll=-1311.7241 KL=4947.8184\n",
      "[VI iter 720/800] ELBO=-5904.6787 exp_ll=-1307.2461 KL=4597.4326\n",
      "[VI iter 800/800] ELBO=-5600.2881 exp_ll=-1297.6708 KL=4302.6172\n",
      "Final test RMSE: 0.2513623727996852\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 6 | labelled size = 80 | pool size = 59920 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.185998, train_rmse=0.309236\n",
      "[Train epoch 5/50] loss=0.088261, train_rmse=0.285955\n",
      "[Train epoch 10/50] loss=0.063161, train_rmse=0.276995\n",
      "[Train epoch 15/50] loss=0.051281, train_rmse=0.266607\n",
      "[Train epoch 20/50] loss=0.043509, train_rmse=0.260217\n",
      "[Train epoch 25/50] loss=0.036428, train_rmse=0.253818\n",
      "[Train epoch 30/50] loss=0.032307, train_rmse=0.249440\n",
      "[Train epoch 35/50] loss=0.027161, train_rmse=0.242972\n",
      "[Train epoch 40/50] loss=0.026546, train_rmse=0.245778\n",
      "[Train epoch 45/50] loss=0.022282, train_rmse=0.243975\n",
      "[Train epoch 50/50] loss=0.020865, train_rmse=0.243334\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-36223.8008 exp_ll=-28666.5078 KL=7557.2944\n",
      "[VI iter 80/800] ELBO=-10563.8955 exp_ll=-2409.7317 KL=8154.1641\n",
      "[VI iter 160/800] ELBO=-9738.9238 exp_ll=-1786.0864 KL=7952.8369\n",
      "[VI iter 240/800] ELBO=-9204.6133 exp_ll=-1602.1455 KL=7602.4683\n",
      "[VI iter 320/800] ELBO=-8726.6465 exp_ll=-1529.3105 KL=7197.3354\n",
      "[VI iter 400/800] ELBO=-8275.1074 exp_ll=-1498.2441 KL=6776.8633\n",
      "[VI iter 480/800] ELBO=-7846.2139 exp_ll=-1485.1637 KL=6361.0503\n",
      "[VI iter 560/800] ELBO=-7441.4780 exp_ll=-1479.7949 KL=5961.6831\n",
      "[VI iter 640/800] ELBO=-7070.9463 exp_ll=-1483.6735 KL=5587.2729\n",
      "[VI iter 720/800] ELBO=-6734.8057 exp_ll=-1486.1908 KL=5248.6147\n",
      "[VI iter 800/800] ELBO=-6428.0791 exp_ll=-1481.6384 KL=4946.4404\n",
      "Final test RMSE: 0.24333377884035828\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 7 | labelled size = 90 | pool size = 59910 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.182724, train_rmse=0.310271\n",
      "[Train epoch 5/50] loss=0.079074, train_rmse=0.284405\n",
      "[Train epoch 10/50] loss=0.057539, train_rmse=0.272133\n",
      "[Train epoch 15/50] loss=0.046858, train_rmse=0.263611\n",
      "[Train epoch 20/50] loss=0.038798, train_rmse=0.256145\n",
      "[Train epoch 25/50] loss=0.031799, train_rmse=0.249236\n",
      "[Train epoch 30/50] loss=0.028957, train_rmse=0.245578\n",
      "[Train epoch 35/50] loss=0.023499, train_rmse=0.242532\n",
      "[Train epoch 40/50] loss=0.022844, train_rmse=0.239157\n",
      "[Train epoch 45/50] loss=0.022151, train_rmse=0.241494\n",
      "[Train epoch 50/50] loss=0.019572, train_rmse=0.238556\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-40070.6328 exp_ll=-32507.8145 KL=7562.8169\n",
      "[VI iter 80/800] ELBO=-10747.3477 exp_ll=-2550.0347 KL=8197.3135\n",
      "[VI iter 160/800] ELBO=-9958.5889 exp_ll=-1888.6976 KL=8069.8911\n",
      "[VI iter 240/800] ELBO=-9496.9160 exp_ll=-1699.1929 KL=7797.7236\n",
      "[VI iter 320/800] ELBO=-9091.5547 exp_ll=-1624.7349 KL=7466.8203\n",
      "[VI iter 400/800] ELBO=-8707.8945 exp_ll=-1594.7124 KL=7113.1816\n",
      "[VI iter 480/800] ELBO=-8341.7197 exp_ll=-1584.8093 KL=6756.9106\n",
      "[VI iter 560/800] ELBO=-7993.1616 exp_ll=-1582.4615 KL=6410.7002\n",
      "[VI iter 640/800] ELBO=-7668.4746 exp_ll=-1586.2629 KL=6082.2119\n",
      "[VI iter 720/800] ELBO=-7367.9170 exp_ll=-1588.5046 KL=5779.4126\n",
      "[VI iter 800/800] ELBO=-7098.8945 exp_ll=-1596.4291 KL=5502.4653\n",
      "Final test RMSE: 0.23855619693351646\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 8 | labelled size = 100 | pool size = 59900 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.175125, train_rmse=0.309462\n",
      "[Train epoch 5/50] loss=0.079620, train_rmse=0.282832\n",
      "[Train epoch 10/50] loss=0.056175, train_rmse=0.274140\n",
      "[Train epoch 15/50] loss=0.045679, train_rmse=0.264153\n",
      "[Train epoch 20/50] loss=0.036866, train_rmse=0.253892\n",
      "[Train epoch 25/50] loss=0.030095, train_rmse=0.247612\n",
      "[Train epoch 30/50] loss=0.026549, train_rmse=0.243567\n",
      "[Train epoch 35/50] loss=0.022572, train_rmse=0.244995\n",
      "[Train epoch 40/50] loss=0.019962, train_rmse=0.239774\n",
      "[Train epoch 45/50] loss=0.019884, train_rmse=0.238800\n",
      "[Train epoch 50/50] loss=0.019959, train_rmse=0.238276\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-42499.9023 exp_ll=-34936.7539 KL=7563.1489\n",
      "[VI iter 80/800] ELBO=-11250.0879 exp_ll=-2949.2815 KL=8300.8066\n",
      "[VI iter 160/800] ELBO=-10442.7246 exp_ll=-2174.6494 KL=8268.0752\n",
      "[VI iter 240/800] ELBO=-10006.4922 exp_ll=-1932.6372 KL=8073.8555\n",
      "[VI iter 320/800] ELBO=-9640.4414 exp_ll=-1829.1265 KL=7811.3149\n",
      "[VI iter 400/800] ELBO=-9300.4258 exp_ll=-1780.3538 KL=7520.0723\n",
      "[VI iter 480/800] ELBO=-8976.7178 exp_ll=-1757.3157 KL=7219.4023\n",
      "[VI iter 560/800] ELBO=-8668.6777 exp_ll=-1747.8979 KL=6920.7798\n",
      "[VI iter 640/800] ELBO=-8376.1914 exp_ll=-1745.0555 KL=6631.1362\n",
      "[VI iter 720/800] ELBO=-8099.7441 exp_ll=-1744.7734 KL=6354.9707\n",
      "[VI iter 800/800] ELBO=-7838.6523 exp_ll=-1743.3827 KL=6095.2695\n",
      "Final test RMSE: 0.23827577912600786\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 9 | labelled size = 110 | pool size = 59890 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.179576, train_rmse=0.308872\n",
      "[Train epoch 5/50] loss=0.087547, train_rmse=0.283558\n",
      "[Train epoch 10/50] loss=0.060395, train_rmse=0.272434\n",
      "[Train epoch 15/50] loss=0.049118, train_rmse=0.262371\n",
      "[Train epoch 20/50] loss=0.039971, train_rmse=0.250176\n",
      "[Train epoch 25/50] loss=0.032826, train_rmse=0.244796\n",
      "[Train epoch 30/50] loss=0.027025, train_rmse=0.239024\n",
      "[Train epoch 35/50] loss=0.024776, train_rmse=0.236505\n",
      "[Train epoch 40/50] loss=0.021881, train_rmse=0.232762\n",
      "[Train epoch 45/50] loss=0.020006, train_rmse=0.231724\n",
      "[Train epoch 50/50] loss=0.017211, train_rmse=0.232144\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-48178.3242 exp_ll=-40605.6055 KL=7572.7188\n",
      "[VI iter 80/800] ELBO=-11684.1162 exp_ll=-3359.9590 KL=8324.1572\n",
      "[VI iter 160/800] ELBO=-10761.5078 exp_ll=-2419.2358 KL=8342.2715\n",
      "[VI iter 240/800] ELBO=-10340.0723 exp_ll=-2125.0005 KL=8215.0723\n",
      "[VI iter 320/800] ELBO=-10017.4258 exp_ll=-1992.7686 KL=8024.6577\n",
      "[VI iter 400/800] ELBO=-9728.1455 exp_ll=-1925.4988 KL=7802.6470\n",
      "[VI iter 480/800] ELBO=-9456.2822 exp_ll=-1890.6328 KL=7565.6494\n",
      "[VI iter 560/800] ELBO=-9197.5410 exp_ll=-1873.5846 KL=7323.9561\n",
      "[VI iter 640/800] ELBO=-8949.2266 exp_ll=-1864.8796 KL=7084.3472\n",
      "[VI iter 720/800] ELBO=-8714.9434 exp_ll=-1862.9187 KL=6852.0244\n",
      "[VI iter 800/800] ELBO=-8492.2773 exp_ll=-1863.2876 KL=6628.9897\n",
      "Final test RMSE: 0.2321444607425679\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 10 | labelled size = 120 | pool size = 59880 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.169003, train_rmse=0.304897\n",
      "[Train epoch 5/50] loss=0.078163, train_rmse=0.279674\n",
      "[Train epoch 10/50] loss=0.056829, train_rmse=0.266502\n",
      "[Train epoch 15/50] loss=0.046098, train_rmse=0.255175\n",
      "[Train epoch 20/50] loss=0.034706, train_rmse=0.246233\n",
      "[Train epoch 25/50] loss=0.031649, train_rmse=0.241952\n",
      "[Train epoch 30/50] loss=0.025952, train_rmse=0.233874\n",
      "[Train epoch 35/50] loss=0.023588, train_rmse=0.235532\n",
      "[Train epoch 40/50] loss=0.021019, train_rmse=0.231462\n",
      "[Train epoch 45/50] loss=0.017446, train_rmse=0.226927\n",
      "[Train epoch 50/50] loss=0.017684, train_rmse=0.229591\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-48447.6328 exp_ll=-40883.9805 KL=7563.6543\n",
      "[VI iter 80/800] ELBO=-12053.0039 exp_ll=-3679.4312 KL=8373.5723\n",
      "[VI iter 160/800] ELBO=-11110.5654 exp_ll=-2660.3711 KL=8450.1943\n",
      "[VI iter 240/800] ELBO=-10692.8184 exp_ll=-2324.5034 KL=8368.3154\n",
      "[VI iter 320/800] ELBO=-10387.6719 exp_ll=-2173.0508 KL=8214.6211\n",
      "[VI iter 400/800] ELBO=-10121.2695 exp_ll=-2095.9563 KL=8025.3135\n",
      "[VI iter 480/800] ELBO=-9874.3018 exp_ll=-2055.0186 KL=7819.2832\n",
      "[VI iter 560/800] ELBO=-9640.2793 exp_ll=-2033.0117 KL=7607.2676\n",
      "[VI iter 640/800] ELBO=-9416.7754 exp_ll=-2021.6326 KL=7395.1426\n",
      "[VI iter 720/800] ELBO=-9202.6572 exp_ll=-2016.1985 KL=7186.4585\n",
      "[VI iter 800/800] ELBO=-8997.4746 exp_ll=-2013.8109 KL=6983.6636\n",
      "Final test RMSE: 0.22959097901667624\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 11 | labelled size = 130 | pool size = 59870 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.165481, train_rmse=0.298396\n",
      "[Train epoch 5/50] loss=0.078574, train_rmse=0.277536\n",
      "[Train epoch 10/50] loss=0.065564, train_rmse=0.268752\n",
      "[Train epoch 15/50] loss=0.057919, train_rmse=0.267610\n",
      "[Train epoch 20/50] loss=0.050724, train_rmse=0.261948\n",
      "[Train epoch 25/50] loss=0.046550, train_rmse=0.265508\n",
      "[Train epoch 30/50] loss=0.043438, train_rmse=0.255450\n",
      "[Train epoch 35/50] loss=0.044085, train_rmse=0.247381\n",
      "[Train epoch 40/50] loss=0.037398, train_rmse=0.251590\n",
      "[Train epoch 45/50] loss=0.035146, train_rmse=0.249226\n",
      "[Train epoch 50/50] loss=0.034595, train_rmse=0.246395\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-53333.9375 exp_ll=-45771.6680 KL=7562.2676\n",
      "[VI iter 80/800] ELBO=-13048.7773 exp_ll=-4730.3774 KL=8318.4004\n",
      "[VI iter 160/800] ELBO=-11621.5312 exp_ll=-3271.4512 KL=8350.0801\n",
      "[VI iter 240/800] ELBO=-11016.8701 exp_ll=-2768.4241 KL=8248.4463\n",
      "[VI iter 320/800] ELBO=-10626.2734 exp_ll=-2525.0344 KL=8101.2388\n",
      "[VI iter 400/800] ELBO=-10326.3301 exp_ll=-2387.9712 KL=7938.3584\n",
      "[VI iter 480/800] ELBO=-10075.2393 exp_ll=-2303.8706 KL=7771.3687\n",
      "[VI iter 560/800] ELBO=-9855.4219 exp_ll=-2249.9934 KL=7605.4282\n",
      "[VI iter 640/800] ELBO=-9658.1875 exp_ll=-2214.1033 KL=7444.0840\n",
      "[VI iter 720/800] ELBO=-9480.2070 exp_ll=-2190.3257 KL=7289.8818\n",
      "[VI iter 800/800] ELBO=-9316.7461 exp_ll=-2172.7463 KL=7144.0000\n",
      "Final test RMSE: 0.24639462423142156\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 12 | labelled size = 140 | pool size = 59860 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.174764, train_rmse=0.300254\n",
      "[Train epoch 5/50] loss=0.072721, train_rmse=0.280709\n",
      "[Train epoch 10/50] loss=0.054016, train_rmse=0.264819\n",
      "[Train epoch 15/50] loss=0.046732, train_rmse=0.251977\n",
      "[Train epoch 20/50] loss=0.039535, train_rmse=0.248413\n",
      "[Train epoch 25/50] loss=0.033777, train_rmse=0.242027\n",
      "[Train epoch 30/50] loss=0.029507, train_rmse=0.235857\n",
      "[Train epoch 35/50] loss=0.023229, train_rmse=0.233930\n",
      "[Train epoch 40/50] loss=0.025397, train_rmse=0.232643\n",
      "[Train epoch 45/50] loss=0.021734, train_rmse=0.231309\n",
      "[Train epoch 50/50] loss=0.019835, train_rmse=0.228866\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-57191.5820 exp_ll=-49634.3555 KL=7557.2261\n",
      "[VI iter 80/800] ELBO=-12570.2422 exp_ll=-4209.8262 KL=8360.4160\n",
      "[VI iter 160/800] ELBO=-11546.8877 exp_ll=-3073.1416 KL=8473.7461\n",
      "[VI iter 240/800] ELBO=-11131.3828 exp_ll=-2681.3042 KL=8450.0791\n",
      "[VI iter 320/800] ELBO=-10856.0391 exp_ll=-2492.7749 KL=8363.2646\n",
      "[VI iter 400/800] ELBO=-10634.2949 exp_ll=-2390.2622 KL=8244.0332\n",
      "[VI iter 480/800] ELBO=-10439.0176 exp_ll=-2331.2959 KL=8107.7222\n",
      "[VI iter 560/800] ELBO=-10259.7480 exp_ll=-2296.8955 KL=7962.8530\n",
      "[VI iter 640/800] ELBO=-10091.5859 exp_ll=-2276.5352 KL=7815.0508\n",
      "[VI iter 720/800] ELBO=-9933.5918 exp_ll=-2265.3545 KL=7668.2368\n",
      "[VI iter 800/800] ELBO=-9783.5469 exp_ll=-2258.8125 KL=7524.7349\n",
      "Final test RMSE: 0.22886622533223222\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 13 | labelled size = 150 | pool size = 59850 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.173232, train_rmse=0.296697\n",
      "[Train epoch 5/50] loss=0.074394, train_rmse=0.278835\n",
      "[Train epoch 10/50] loss=0.054126, train_rmse=0.262003\n",
      "[Train epoch 15/50] loss=0.039075, train_rmse=0.249859\n",
      "[Train epoch 20/50] loss=0.033284, train_rmse=0.241449\n",
      "[Train epoch 25/50] loss=0.027068, train_rmse=0.236738\n",
      "[Train epoch 30/50] loss=0.024604, train_rmse=0.232654\n",
      "[Train epoch 35/50] loss=0.020167, train_rmse=0.231976\n",
      "[Train epoch 40/50] loss=0.020582, train_rmse=0.233749\n",
      "[Train epoch 45/50] loss=0.016484, train_rmse=0.230507\n",
      "[Train epoch 50/50] loss=0.018570, train_rmse=0.228550\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-61044.8789 exp_ll=-53472.1914 KL=7572.6870\n",
      "[VI iter 80/800] ELBO=-12977.1152 exp_ll=-4587.0620 KL=8390.0537\n",
      "[VI iter 160/800] ELBO=-11837.3496 exp_ll=-3295.6992 KL=8541.6504\n",
      "[VI iter 240/800] ELBO=-11401.0947 exp_ll=-2844.7190 KL=8556.3760\n",
      "[VI iter 320/800] ELBO=-11135.8262 exp_ll=-2630.1477 KL=8505.6787\n",
      "[VI iter 400/800] ELBO=-10932.8721 exp_ll=-2514.9893 KL=8417.8828\n",
      "[VI iter 480/800] ELBO=-10758.2725 exp_ll=-2450.0254 KL=8308.2471\n",
      "[VI iter 560/800] ELBO=-10599.5840 exp_ll=-2412.9429 KL=8186.6411\n",
      "[VI iter 640/800] ELBO=-10451.9229 exp_ll=-2391.9346 KL=8059.9883\n",
      "[VI iter 720/800] ELBO=-10313.5117 exp_ll=-2380.3252 KL=7933.1865\n",
      "[VI iter 800/800] ELBO=-10183.0869 exp_ll=-2374.2410 KL=7808.8462\n",
      "Final test RMSE: 0.2285495582360985\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 14 | labelled size = 160 | pool size = 59840 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.164394, train_rmse=0.292513\n",
      "[Train epoch 5/50] loss=0.070081, train_rmse=0.273607\n",
      "[Train epoch 10/50] loss=0.053533, train_rmse=0.255869\n",
      "[Train epoch 15/50] loss=0.039660, train_rmse=0.239328\n",
      "[Train epoch 20/50] loss=0.031855, train_rmse=0.229242\n",
      "[Train epoch 25/50] loss=0.027111, train_rmse=0.225027\n",
      "[Train epoch 30/50] loss=0.020563, train_rmse=0.220680\n",
      "[Train epoch 35/50] loss=0.020302, train_rmse=0.220372\n",
      "[Train epoch 40/50] loss=0.019471, train_rmse=0.219895\n",
      "[Train epoch 45/50] loss=0.017180, train_rmse=0.221425\n",
      "[Train epoch 50/50] loss=0.014922, train_rmse=0.219242\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-63208.5820 exp_ll=-55643.2461 KL=7565.3374\n",
      "[VI iter 80/800] ELBO=-13275.0859 exp_ll=-4868.3022 KL=8406.7832\n",
      "[VI iter 160/800] ELBO=-12072.7500 exp_ll=-3480.0308 KL=8592.7188\n",
      "[VI iter 240/800] ELBO=-11640.5176 exp_ll=-3005.6909 KL=8634.8262\n",
      "[VI iter 320/800] ELBO=-11386.3789 exp_ll=-2779.9565 KL=8606.4229\n",
      "[VI iter 400/800] ELBO=-11196.7832 exp_ll=-2658.1006 KL=8538.6826\n",
      "[VI iter 480/800] ELBO=-11037.4785 exp_ll=-2589.0698 KL=8448.4082\n",
      "[VI iter 560/800] ELBO=-10895.2461 exp_ll=-2549.6169 KL=8345.6289\n",
      "[VI iter 640/800] ELBO=-10764.2217 exp_ll=-2527.5935 KL=8236.6279\n",
      "[VI iter 720/800] ELBO=-10641.3945 exp_ll=-2515.8721 KL=8125.5229\n",
      "[VI iter 800/800] ELBO=-10525.2441 exp_ll=-2510.4189 KL=8014.8247\n",
      "Final test RMSE: 0.2192419097695275\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 15 | labelled size = 170 | pool size = 59830 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.174376, train_rmse=0.293646\n",
      "[Train epoch 5/50] loss=0.070120, train_rmse=0.273882\n",
      "[Train epoch 10/50] loss=0.050702, train_rmse=0.250156\n",
      "[Train epoch 15/50] loss=0.039856, train_rmse=0.232390\n",
      "[Train epoch 20/50] loss=0.032661, train_rmse=0.226079\n",
      "[Train epoch 25/50] loss=0.026865, train_rmse=0.220295\n",
      "[Train epoch 30/50] loss=0.020625, train_rmse=0.217236\n",
      "[Train epoch 35/50] loss=0.020191, train_rmse=0.210004\n",
      "[Train epoch 40/50] loss=0.019506, train_rmse=0.214133\n",
      "[Train epoch 45/50] loss=0.016389, train_rmse=0.209475\n",
      "[Train epoch 50/50] loss=0.016731, train_rmse=0.214505\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-64672.0117 exp_ll=-57103.1914 KL=7568.8188\n",
      "[VI iter 80/800] ELBO=-13581.5195 exp_ll=-5151.5581 KL=8429.9619\n",
      "[VI iter 160/800] ELBO=-12345.2480 exp_ll=-3700.4048 KL=8644.8428\n",
      "[VI iter 240/800] ELBO=-11910.9277 exp_ll=-3194.1157 KL=8716.8125\n",
      "[VI iter 320/800] ELBO=-11664.5996 exp_ll=-2948.6211 KL=8715.9785\n",
      "[VI iter 400/800] ELBO=-11486.3633 exp_ll=-2813.8599 KL=8672.5039\n",
      "[VI iter 480/800] ELBO=-11339.2793 exp_ll=-2735.9448 KL=8603.3350\n",
      "[VI iter 560/800] ELBO=-11209.2695 exp_ll=-2690.2661 KL=8519.0029\n",
      "[VI iter 640/800] ELBO=-11090.2178 exp_ll=-2663.8694 KL=8426.3486\n",
      "[VI iter 720/800] ELBO=-10979.4941 exp_ll=-2649.5259 KL=8329.9678\n",
      "[VI iter 800/800] ELBO=-10875.6699 exp_ll=-2642.7876 KL=8232.8818\n",
      "Final test RMSE: 0.21450491994937432\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 16 | labelled size = 180 | pool size = 59820 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.170694, train_rmse=0.292165\n",
      "[Train epoch 5/50] loss=0.074899, train_rmse=0.272566\n",
      "[Train epoch 10/50] loss=0.054464, train_rmse=0.248099\n",
      "[Train epoch 15/50] loss=0.038249, train_rmse=0.228539\n",
      "[Train epoch 20/50] loss=0.032159, train_rmse=0.220419\n",
      "[Train epoch 25/50] loss=0.027376, train_rmse=0.214196\n",
      "[Train epoch 30/50] loss=0.022983, train_rmse=0.209751\n",
      "[Train epoch 35/50] loss=0.019028, train_rmse=0.208961\n",
      "[Train epoch 40/50] loss=0.017955, train_rmse=0.213566\n",
      "[Train epoch 45/50] loss=0.016731, train_rmse=0.211611\n",
      "[Train epoch 50/50] loss=0.015897, train_rmse=0.205900\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-71884.8750 exp_ll=-64316.9883 KL=7567.8906\n",
      "[VI iter 80/800] ELBO=-14187.2832 exp_ll=-5725.9146 KL=8461.3682\n",
      "[VI iter 160/800] ELBO=-12774.2129 exp_ll=-4057.7827 KL=8716.4297\n",
      "[VI iter 240/800] ELBO=-12276.4355 exp_ll=-3452.5703 KL=8823.8652\n",
      "[VI iter 320/800] ELBO=-12010.3555 exp_ll=-3155.2397 KL=8855.1162\n",
      "[VI iter 400/800] ELBO=-11831.1328 exp_ll=-2990.2617 KL=8840.8711\n",
      "[VI iter 480/800] ELBO=-11691.7344 exp_ll=-2893.1655 KL=8798.5693\n",
      "[VI iter 560/800] ELBO=-11573.6670 exp_ll=-2834.4023 KL=8739.2646\n",
      "[VI iter 640/800] ELBO=-11468.8281 exp_ll=-2798.7241 KL=8670.1045\n",
      "[VI iter 720/800] ELBO=-11373.0908 exp_ll=-2777.3623 KL=8595.7285\n",
      "[VI iter 800/800] ELBO=-11284.1934 exp_ll=-2765.0518 KL=8519.1416\n",
      "Final test RMSE: 0.2058999156200464\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 17 | labelled size = 190 | pool size = 59810 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.159118, train_rmse=0.297011\n",
      "[Train epoch 5/50] loss=0.073216, train_rmse=0.270485\n",
      "[Train epoch 10/50] loss=0.052480, train_rmse=0.245803\n",
      "[Train epoch 15/50] loss=0.040289, train_rmse=0.227831\n",
      "[Train epoch 20/50] loss=0.032401, train_rmse=0.218276\n",
      "[Train epoch 25/50] loss=0.029161, train_rmse=0.214531\n",
      "[Train epoch 30/50] loss=0.022838, train_rmse=0.207458\n",
      "[Train epoch 35/50] loss=0.019751, train_rmse=0.210149\n",
      "[Train epoch 40/50] loss=0.018354, train_rmse=0.209754\n",
      "[Train epoch 45/50] loss=0.016531, train_rmse=0.213619\n",
      "[Train epoch 50/50] loss=0.017277, train_rmse=0.211114\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-66552.5859 exp_ll=-58992.0586 KL=7560.5278\n",
      "[VI iter 80/800] ELBO=-13954.0352 exp_ll=-5502.7061 KL=8451.3291\n",
      "[VI iter 160/800] ELBO=-12726.2236 exp_ll=-4015.7649 KL=8710.4590\n",
      "[VI iter 240/800] ELBO=-12289.2246 exp_ll=-3467.1724 KL=8822.0527\n",
      "[VI iter 320/800] ELBO=-12054.6025 exp_ll=-3198.3633 KL=8856.2393\n",
      "[VI iter 400/800] ELBO=-11895.6406 exp_ll=-3051.1257 KL=8844.5146\n",
      "[VI iter 480/800] ELBO=-11771.0508 exp_ll=-2966.4917 KL=8804.5596\n",
      "[VI iter 560/800] ELBO=-11664.8096 exp_ll=-2917.3459 KL=8747.4639\n",
      "[VI iter 640/800] ELBO=-11570.0723 exp_ll=-2889.4736 KL=8680.5986\n",
      "[VI iter 720/800] ELBO=-11483.2959 exp_ll=-2874.3701 KL=8608.9258\n",
      "[VI iter 800/800] ELBO=-11403.3301 exp_ll=-2867.5813 KL=8535.7490\n",
      "Final test RMSE: 0.21111446197120298\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 18 | labelled size = 200 | pool size = 59800 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.165227, train_rmse=0.286460\n",
      "[Train epoch 5/50] loss=0.069480, train_rmse=0.267788\n",
      "[Train epoch 10/50] loss=0.054438, train_rmse=0.245114\n",
      "[Train epoch 15/50] loss=0.043426, train_rmse=0.235480\n",
      "[Train epoch 20/50] loss=0.034751, train_rmse=0.222232\n",
      "[Train epoch 25/50] loss=0.030234, train_rmse=0.220777\n",
      "[Train epoch 30/50] loss=0.029246, train_rmse=0.215946\n",
      "[Train epoch 35/50] loss=0.024995, train_rmse=0.209800\n",
      "[Train epoch 40/50] loss=0.023125, train_rmse=0.216353\n",
      "[Train epoch 45/50] loss=0.022422, train_rmse=0.214217\n",
      "[Train epoch 50/50] loss=0.023172, train_rmse=0.209202\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-73116.9844 exp_ll=-65551.3203 KL=7565.6660\n",
      "[VI iter 80/800] ELBO=-14794.7568 exp_ll=-6304.2354 KL=8490.5215\n",
      "[VI iter 160/800] ELBO=-13236.4443 exp_ll=-4468.7334 KL=8767.7109\n",
      "[VI iter 240/800] ELBO=-12694.6719 exp_ll=-3796.5652 KL=8898.1064\n",
      "[VI iter 320/800] ELBO=-12418.1309 exp_ll=-3464.6948 KL=8953.4355\n",
      "[VI iter 400/800] ELBO=-12242.9570 exp_ll=-3277.9019 KL=8965.0547\n",
      "[VI iter 480/800] ELBO=-12114.8164 exp_ll=-3164.9646 KL=8949.8516\n",
      "[VI iter 560/800] ELBO=-12012.0664 exp_ll=-3094.3130 KL=8917.7539\n",
      "[VI iter 640/800] ELBO=-11924.5869 exp_ll=-3049.4854 KL=8875.1016\n",
      "[VI iter 720/800] ELBO=-11847.2686 exp_ll=-3021.1250 KL=8826.1436\n",
      "[VI iter 800/800] ELBO=-11777.2295 exp_ll=-3003.4651 KL=8773.7646\n",
      "Final test RMSE: 0.20920245514389996\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 19 | labelled size = 210 | pool size = 59790 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.157601, train_rmse=0.286070\n",
      "[Train epoch 5/50] loss=0.068825, train_rmse=0.263441\n",
      "[Train epoch 10/50] loss=0.049160, train_rmse=0.242294\n",
      "[Train epoch 15/50] loss=0.039209, train_rmse=0.224648\n",
      "[Train epoch 20/50] loss=0.032072, train_rmse=0.215477\n",
      "[Train epoch 25/50] loss=0.028273, train_rmse=0.208922\n",
      "[Train epoch 30/50] loss=0.022881, train_rmse=0.215157\n",
      "[Train epoch 35/50] loss=0.018975, train_rmse=0.212422\n",
      "[Train epoch 40/50] loss=0.020064, train_rmse=0.208864\n",
      "[Train epoch 45/50] loss=0.019935, train_rmse=0.208925\n",
      "[Train epoch 50/50] loss=0.019091, train_rmse=0.212504\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-72384.0234 exp_ll=-64824.7656 KL=7559.2588\n",
      "[VI iter 80/800] ELBO=-14571.3545 exp_ll=-6116.7178 KL=8454.6367\n",
      "[VI iter 160/800] ELBO=-13191.3633 exp_ll=-4461.6929 KL=8729.6699\n",
      "[VI iter 240/800] ELBO=-12712.1230 exp_ll=-3847.5381 KL=8864.5850\n",
      "[VI iter 320/800] ELBO=-12463.3555 exp_ll=-3538.1353 KL=8925.2207\n",
      "[VI iter 400/800] ELBO=-12303.1611 exp_ll=-3362.7041 KL=8940.4570\n",
      "[VI iter 480/800] ELBO=-12184.7500 exp_ll=-3257.7759 KL=8926.9746\n",
      "[VI iter 560/800] ELBO=-12089.2676 exp_ll=-3193.6704 KL=8895.5967\n",
      "[VI iter 640/800] ELBO=-12008.1523 exp_ll=-3154.5078 KL=8853.6445\n",
      "[VI iter 720/800] ELBO=-11937.2539 exp_ll=-3131.1465 KL=8806.1074\n",
      "[VI iter 800/800] ELBO=-11873.7627 exp_ll=-3117.4531 KL=8756.3096\n",
      "Final test RMSE: 0.21250385273077443\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 20 | labelled size = 220 | pool size = 59780 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.164622, train_rmse=0.291391\n",
      "[Train epoch 5/50] loss=0.067409, train_rmse=0.268485\n",
      "[Train epoch 10/50] loss=0.051327, train_rmse=0.241776\n",
      "[Train epoch 15/50] loss=0.041580, train_rmse=0.224455\n",
      "[Train epoch 20/50] loss=0.031325, train_rmse=0.214133\n",
      "[Train epoch 25/50] loss=0.024807, train_rmse=0.212100\n",
      "[Train epoch 30/50] loss=0.023199, train_rmse=0.205732\n",
      "[Train epoch 35/50] loss=0.020976, train_rmse=0.205016\n",
      "[Train epoch 40/50] loss=0.019317, train_rmse=0.211192\n",
      "[Train epoch 45/50] loss=0.017269, train_rmse=0.206468\n",
      "[Train epoch 50/50] loss=0.018157, train_rmse=0.203992\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-80249.5703 exp_ll=-72690.0859 KL=7559.4854\n",
      "[VI iter 80/800] ELBO=-15162.5049 exp_ll=-6701.0615 KL=8461.4434\n",
      "[VI iter 160/800] ELBO=-13566.1328 exp_ll=-4808.4556 KL=8757.6777\n",
      "[VI iter 240/800] ELBO=-13015.0693 exp_ll=-4099.9893 KL=8915.0801\n",
      "[VI iter 320/800] ELBO=-12740.7129 exp_ll=-3742.1670 KL=8998.5459\n",
      "[VI iter 400/800] ELBO=-12573.7305 exp_ll=-3537.0173 KL=9036.7129\n",
      "[VI iter 480/800] ELBO=-12457.1172 exp_ll=-3411.5298 KL=9045.5869\n",
      "[VI iter 560/800] ELBO=-12367.2676 exp_ll=-3332.2319 KL=9035.0352\n",
      "[VI iter 640/800] ELBO=-12293.2578 exp_ll=-3281.6384 KL=9011.6191\n",
      "[VI iter 720/800] ELBO=-12229.5361 exp_ll=-3249.5427 KL=8979.9932\n",
      "[VI iter 800/800] ELBO=-12173.2910 exp_ll=-3229.7583 KL=8943.5332\n",
      "Final test RMSE: 0.20399187850446632\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 21 | labelled size = 230 | pool size = 59770 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.153393, train_rmse=0.290272\n",
      "[Train epoch 5/50] loss=0.066822, train_rmse=0.265402\n",
      "[Train epoch 10/50] loss=0.048966, train_rmse=0.236406\n",
      "[Train epoch 15/50] loss=0.036994, train_rmse=0.220187\n",
      "[Train epoch 20/50] loss=0.030273, train_rmse=0.209518\n",
      "[Train epoch 25/50] loss=0.025558, train_rmse=0.207173\n",
      "[Train epoch 30/50] loss=0.020727, train_rmse=0.207622\n",
      "[Train epoch 35/50] loss=0.020613, train_rmse=0.208306\n",
      "[Train epoch 40/50] loss=0.017375, train_rmse=0.201992\n",
      "[Train epoch 45/50] loss=0.015899, train_rmse=0.201639\n",
      "[Train epoch 50/50] loss=0.016117, train_rmse=0.205570\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-77649.7500 exp_ll=-70091.5938 KL=7558.1543\n",
      "[VI iter 80/800] ELBO=-15022.4746 exp_ll=-6555.4565 KL=8467.0186\n",
      "[VI iter 160/800] ELBO=-13547.5322 exp_ll=-4790.6807 KL=8756.8516\n",
      "[VI iter 240/800] ELBO=-13036.6719 exp_ll=-4128.3384 KL=8908.3330\n",
      "[VI iter 320/800] ELBO=-12779.3301 exp_ll=-3793.2209 KL=8986.1094\n",
      "[VI iter 400/800] ELBO=-12620.1152 exp_ll=-3601.5562 KL=9018.5586\n",
      "[VI iter 480/800] ELBO=-12507.0762 exp_ll=-3485.4136 KL=9021.6631\n",
      "[VI iter 560/800] ELBO=-12418.9570 exp_ll=-3413.2715 KL=9005.6855\n",
      "[VI iter 640/800] ELBO=-12346.1211 exp_ll=-3368.4385 KL=8977.6826\n",
      "[VI iter 720/800] ELBO=-12283.9121 exp_ll=-3341.2905 KL=8942.6221\n",
      "[VI iter 800/800] ELBO=-12229.0605 exp_ll=-3325.0623 KL=8903.9980\n",
      "Final test RMSE: 0.2055700907687353\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 22 | labelled size = 240 | pool size = 59760 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.152225, train_rmse=0.288278\n",
      "[Train epoch 5/50] loss=0.066694, train_rmse=0.267038\n",
      "[Train epoch 10/50] loss=0.048367, train_rmse=0.239808\n",
      "[Train epoch 15/50] loss=0.036084, train_rmse=0.222567\n",
      "[Train epoch 20/50] loss=0.030844, train_rmse=0.212638\n",
      "[Train epoch 25/50] loss=0.024072, train_rmse=0.207718\n",
      "[Train epoch 30/50] loss=0.020627, train_rmse=0.202156\n",
      "[Train epoch 35/50] loss=0.017683, train_rmse=0.201057\n",
      "[Train epoch 40/50] loss=0.017864, train_rmse=0.203896\n",
      "[Train epoch 45/50] loss=0.015695, train_rmse=0.200311\n",
      "[Train epoch 50/50] loss=0.016119, train_rmse=0.202695\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-85166.9453 exp_ll=-77600.4922 KL=7566.4517\n",
      "[VI iter 80/800] ELBO=-15684.4531 exp_ll=-7203.6914 KL=8480.7617\n",
      "[VI iter 160/800] ELBO=-13940.5020 exp_ll=-5151.7949 KL=8788.7070\n",
      "[VI iter 240/800] ELBO=-13354.8535 exp_ll=-4394.1670 KL=8960.6865\n",
      "[VI iter 320/800] ELBO=-13071.0645 exp_ll=-4012.1062 KL=9058.9580\n",
      "[VI iter 400/800] ELBO=-12902.9189 exp_ll=-3791.8770 KL=9111.0420\n",
      "[VI iter 480/800] ELBO=-12788.6934 exp_ll=-3656.0015 KL=9132.6924\n",
      "[VI iter 560/800] ELBO=-12703.1689 exp_ll=-3569.1943 KL=9133.9746\n",
      "[VI iter 640/800] ELBO=-12634.7695 exp_ll=-3513.0122 KL=9121.7578\n",
      "[VI iter 720/800] ELBO=-12577.5918 exp_ll=-3476.7053 KL=9100.8867\n",
      "[VI iter 800/800] ELBO=-12528.3477 exp_ll=-3453.5151 KL=9074.8320\n",
      "Final test RMSE: 0.20269488988785606\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 23 | labelled size = 250 | pool size = 59750 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.146781, train_rmse=0.288006\n",
      "[Train epoch 5/50] loss=0.069266, train_rmse=0.263003\n",
      "[Train epoch 10/50] loss=0.046848, train_rmse=0.233772\n",
      "[Train epoch 15/50] loss=0.038266, train_rmse=0.217841\n",
      "[Train epoch 20/50] loss=0.028969, train_rmse=0.209556\n",
      "[Train epoch 25/50] loss=0.024789, train_rmse=0.206221\n",
      "[Train epoch 30/50] loss=0.021467, train_rmse=0.203251\n",
      "[Train epoch 35/50] loss=0.019060, train_rmse=0.201745\n",
      "[Train epoch 40/50] loss=0.017044, train_rmse=0.199461\n",
      "[Train epoch 45/50] loss=0.014848, train_rmse=0.196464\n",
      "[Train epoch 50/50] loss=0.014732, train_rmse=0.197651\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-91365.7578 exp_ll=-83800.6797 KL=7565.0776\n",
      "[VI iter 80/800] ELBO=-15915.5576 exp_ll=-7433.3730 KL=8482.1846\n",
      "[VI iter 160/800] ELBO=-14142.1348 exp_ll=-5346.1870 KL=8795.9482\n",
      "[VI iter 240/800] ELBO=-13544.1250 exp_ll=-4568.0923 KL=8976.0322\n",
      "[VI iter 320/800] ELBO=-13256.3916 exp_ll=-4171.0762 KL=9085.3154\n",
      "[VI iter 400/800] ELBO=-13089.7109 exp_ll=-3939.3857 KL=9150.3252\n",
      "[VI iter 480/800] ELBO=-12979.6016 exp_ll=-3794.0864 KL=9185.5146\n",
      "[VI iter 560/800] ELBO=-12899.4551 exp_ll=-3699.4497 KL=9200.0049\n",
      "[VI iter 640/800] ELBO=-12836.7598 exp_ll=-3636.6665 KL=9200.0938\n",
      "[VI iter 720/800] ELBO=-12785.1504 exp_ll=-3594.8159 KL=9190.3350\n",
      "[VI iter 800/800] ELBO=-12741.2617 exp_ll=-3567.1753 KL=9174.0859\n",
      "Final test RMSE: 0.19765105793884763\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 24 | labelled size = 260 | pool size = 59740 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.148749, train_rmse=0.286687\n",
      "[Train epoch 5/50] loss=0.070345, train_rmse=0.264160\n",
      "[Train epoch 10/50] loss=0.055312, train_rmse=0.241629\n",
      "[Train epoch 15/50] loss=0.044888, train_rmse=0.232385\n",
      "[Train epoch 20/50] loss=0.035991, train_rmse=0.215321\n",
      "[Train epoch 25/50] loss=0.034514, train_rmse=0.211616\n",
      "[Train epoch 30/50] loss=0.030766, train_rmse=0.207274\n",
      "[Train epoch 35/50] loss=0.026674, train_rmse=0.214298\n",
      "[Train epoch 40/50] loss=0.025431, train_rmse=0.201706\n",
      "[Train epoch 45/50] loss=0.024049, train_rmse=0.202850\n",
      "[Train epoch 50/50] loss=0.022237, train_rmse=0.205989\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-82812.9766 exp_ll=-75252.7031 KL=7560.2749\n",
      "[VI iter 80/800] ELBO=-16323.4277 exp_ll=-7819.3599 KL=8504.0684\n",
      "[VI iter 160/800] ELBO=-14412.2441 exp_ll=-5584.8965 KL=8827.3477\n",
      "[VI iter 240/800] ELBO=-13770.5635 exp_ll=-4761.9873 KL=9008.5762\n",
      "[VI iter 320/800] ELBO=-13458.1406 exp_ll=-4341.5786 KL=9116.5625\n",
      "[VI iter 400/800] ELBO=-13275.9883 exp_ll=-4095.6313 KL=9180.3564\n",
      "[VI iter 480/800] ELBO=-13157.0771 exp_ll=-3941.4045 KL=9215.6729\n",
      "[VI iter 560/800] ELBO=-13072.8105 exp_ll=-3840.7456 KL=9232.0654\n",
      "[VI iter 640/800] ELBO=-13009.2793 exp_ll=-3773.5493 KL=9235.7295\n",
      "[VI iter 720/800] ELBO=-12959.0596 exp_ll=-3728.1475 KL=9230.9121\n",
      "[VI iter 800/800] ELBO=-12918.0645 exp_ll=-3697.4028 KL=9220.6621\n",
      "Final test RMSE: 0.20598866784768036\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 25 | labelled size = 270 | pool size = 59730 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.156754, train_rmse=0.293857\n",
      "[Train epoch 5/50] loss=0.070201, train_rmse=0.266979\n",
      "[Train epoch 10/50] loss=0.049537, train_rmse=0.238821\n",
      "[Train epoch 15/50] loss=0.038563, train_rmse=0.222225\n",
      "[Train epoch 20/50] loss=0.033365, train_rmse=0.213588\n",
      "[Train epoch 25/50] loss=0.026127, train_rmse=0.206984\n",
      "[Train epoch 30/50] loss=0.022792, train_rmse=0.206628\n",
      "[Train epoch 35/50] loss=0.021891, train_rmse=0.206119\n",
      "[Train epoch 40/50] loss=0.019698, train_rmse=0.202321\n",
      "[Train epoch 45/50] loss=0.019252, train_rmse=0.207579\n",
      "[Train epoch 50/50] loss=0.016832, train_rmse=0.204130\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-88371.9844 exp_ll=-80806.3828 KL=7565.6016\n",
      "[VI iter 80/800] ELBO=-16631.5859 exp_ll=-8103.8506 KL=8527.7363\n",
      "[VI iter 160/800] ELBO=-14648.8926 exp_ll=-5774.8330 KL=8874.0596\n",
      "[VI iter 240/800] ELBO=-13988.2734 exp_ll=-4910.7764 KL=9077.4971\n",
      "[VI iter 320/800] ELBO=-13671.2930 exp_ll=-4466.7334 KL=9204.5596\n",
      "[VI iter 400/800] ELBO=-13488.8096 exp_ll=-4205.8809 KL=9282.9287\n",
      "[VI iter 480/800] ELBO=-13370.3467 exp_ll=-4042.0137 KL=9328.3330\n",
      "[VI iter 560/800] ELBO=-13286.3672 exp_ll=-3935.2749 KL=9351.0928\n",
      "[VI iter 640/800] ELBO=-13222.6113 exp_ll=-3864.2312 KL=9358.3799\n",
      "[VI iter 720/800] ELBO=-13171.9551 exp_ll=-3816.6821 KL=9355.2734\n",
      "[VI iter 800/800] ELBO=-13130.2852 exp_ll=-3784.8647 KL=9345.4199\n",
      "Final test RMSE: 0.2041302558259665\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 26 | labelled size = 280 | pool size = 59720 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.156342, train_rmse=0.292242\n",
      "[Train epoch 5/50] loss=0.069649, train_rmse=0.268337\n",
      "[Train epoch 10/50] loss=0.049967, train_rmse=0.237832\n",
      "[Train epoch 15/50] loss=0.039548, train_rmse=0.217706\n",
      "[Train epoch 20/50] loss=0.032700, train_rmse=0.210730\n",
      "[Train epoch 25/50] loss=0.024729, train_rmse=0.206472\n",
      "[Train epoch 30/50] loss=0.021531, train_rmse=0.203702\n",
      "[Train epoch 35/50] loss=0.020528, train_rmse=0.198667\n",
      "[Train epoch 40/50] loss=0.017056, train_rmse=0.199424\n",
      "[Train epoch 45/50] loss=0.016696, train_rmse=0.200444\n",
      "[Train epoch 50/50] loss=0.015749, train_rmse=0.199998\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-92574.9375 exp_ll=-85002.4609 KL=7572.4736\n",
      "[VI iter 80/800] ELBO=-16934.4785 exp_ll=-8413.0801 KL=8521.3984\n",
      "[VI iter 160/800] ELBO=-14848.8018 exp_ll=-5978.6670 KL=8870.1348\n",
      "[VI iter 240/800] ELBO=-14150.2988 exp_ll=-5072.0625 KL=9078.2363\n",
      "[VI iter 320/800] ELBO=-13816.4121 exp_ll=-4606.9868 KL=9209.4258\n",
      "[VI iter 400/800] ELBO=-13625.9180 exp_ll=-4334.3208 KL=9291.5967\n",
      "[VI iter 480/800] ELBO=-13503.5391 exp_ll=-4162.7178 KL=9340.8213\n",
      "[VI iter 560/800] ELBO=-13417.6504 exp_ll=-4050.2339 KL=9367.4160\n",
      "[VI iter 640/800] ELBO=-13353.1562 exp_ll=-3974.8032 KL=9378.3535\n",
      "[VI iter 720/800] ELBO=-13302.3730 exp_ll=-3923.7930 KL=9378.5801\n",
      "[VI iter 800/800] ELBO=-13260.9121 exp_ll=-3889.2183 KL=9371.6934\n",
      "Final test RMSE: 0.19999789981931443\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 27 | labelled size = 290 | pool size = 59710 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.153375, train_rmse=0.292535\n",
      "[Train epoch 5/50] loss=0.069078, train_rmse=0.265592\n",
      "[Train epoch 10/50] loss=0.047652, train_rmse=0.232279\n",
      "[Train epoch 15/50] loss=0.036768, train_rmse=0.218888\n",
      "[Train epoch 20/50] loss=0.031858, train_rmse=0.210560\n",
      "[Train epoch 25/50] loss=0.026458, train_rmse=0.200178\n",
      "[Train epoch 30/50] loss=0.020574, train_rmse=0.202854\n",
      "[Train epoch 35/50] loss=0.019430, train_rmse=0.195639\n",
      "[Train epoch 40/50] loss=0.017922, train_rmse=0.203735\n",
      "[Train epoch 45/50] loss=0.018828, train_rmse=0.196249\n",
      "[Train epoch 50/50] loss=0.016665, train_rmse=0.194973\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-96454.2109 exp_ll=-88895.1484 KL=7559.0659\n",
      "[VI iter 80/800] ELBO=-16712.9648 exp_ll=-8226.1016 KL=8486.8643\n",
      "[VI iter 160/800] ELBO=-14797.3672 exp_ll=-5957.8945 KL=8839.4727\n",
      "[VI iter 240/800] ELBO=-14160.1982 exp_ll=-5100.8477 KL=9059.3506\n",
      "[VI iter 320/800] ELBO=-13862.9629 exp_ll=-4658.8867 KL=9204.0762\n",
      "[VI iter 400/800] ELBO=-13696.5576 exp_ll=-4397.5781 KL=9298.9795\n",
      "[VI iter 480/800] ELBO=-13590.8086 exp_ll=-4231.7954 KL=9359.0127\n",
      "[VI iter 560/800] ELBO=-13517.1309 exp_ll=-4122.8960 KL=9394.2344\n",
      "[VI iter 640/800] ELBO=-13461.9678 exp_ll=-4050.1094 KL=9411.8584\n",
      "[VI iter 720/800] ELBO=-13418.5010 exp_ll=-4001.3025 KL=9417.1982\n",
      "[VI iter 800/800] ELBO=-13382.9814 exp_ll=-3968.7812 KL=9414.2002\n",
      "Final test RMSE: 0.19497309298599483\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 28 | labelled size = 300 | pool size = 59700 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.149395, train_rmse=0.289618\n",
      "[Train epoch 5/50] loss=0.066051, train_rmse=0.262637\n",
      "[Train epoch 10/50] loss=0.046603, train_rmse=0.230807\n",
      "[Train epoch 15/50] loss=0.036623, train_rmse=0.213576\n",
      "[Train epoch 20/50] loss=0.027667, train_rmse=0.203683\n",
      "[Train epoch 25/50] loss=0.024729, train_rmse=0.196759\n",
      "[Train epoch 30/50] loss=0.021223, train_rmse=0.194828\n",
      "[Train epoch 35/50] loss=0.019185, train_rmse=0.196708\n",
      "[Train epoch 40/50] loss=0.017708, train_rmse=0.197469\n",
      "[Train epoch 45/50] loss=0.015834, train_rmse=0.190849\n",
      "[Train epoch 50/50] loss=0.015458, train_rmse=0.191622\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-99587.9062 exp_ll=-92015.8750 KL=7572.0327\n",
      "[VI iter 80/800] ELBO=-17258.4512 exp_ll=-8737.8145 KL=8520.6367\n",
      "[VI iter 160/800] ELBO=-15158.7734 exp_ll=-6273.5195 KL=8885.2539\n",
      "[VI iter 240/800] ELBO=-14450.6289 exp_ll=-5336.6641 KL=9113.9648\n",
      "[VI iter 320/800] ELBO=-14113.7871 exp_ll=-4848.3643 KL=9265.4229\n",
      "[VI iter 400/800] ELBO=-13924.8398 exp_ll=-4559.0981 KL=9365.7412\n",
      "[VI iter 480/800] ELBO=-13806.0928 exp_ll=-4375.7178 KL=9430.3750\n",
      "[VI iter 560/800] ELBO=-13724.5469 exp_ll=-4254.9365 KL=9469.6104\n",
      "[VI iter 640/800] ELBO=-13664.4541 exp_ll=-4173.7021 KL=9490.7520\n",
      "[VI iter 720/800] ELBO=-13617.8750 exp_ll=-4118.7036 KL=9499.1719\n",
      "[VI iter 800/800] ELBO=-13580.2578 exp_ll=-4081.3933 KL=9498.8643\n",
      "Final test RMSE: 0.19162197143241705\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 29 | labelled size = 310 | pool size = 59690 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.151511, train_rmse=0.285812\n",
      "[Train epoch 5/50] loss=0.068377, train_rmse=0.262863\n",
      "[Train epoch 10/50] loss=0.049945, train_rmse=0.231098\n",
      "[Train epoch 15/50] loss=0.035422, train_rmse=0.211318\n",
      "[Train epoch 20/50] loss=0.027573, train_rmse=0.204334\n",
      "[Train epoch 25/50] loss=0.024740, train_rmse=0.199543\n",
      "[Train epoch 30/50] loss=0.021879, train_rmse=0.198465\n",
      "[Train epoch 35/50] loss=0.018875, train_rmse=0.196373\n",
      "[Train epoch 40/50] loss=0.017685, train_rmse=0.195787\n",
      "[Train epoch 45/50] loss=0.017804, train_rmse=0.197509\n",
      "[Train epoch 50/50] loss=0.015670, train_rmse=0.192601\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-103953.4219 exp_ll=-96388.6719 KL=7564.7466\n",
      "[VI iter 80/800] ELBO=-17394.3906 exp_ll=-8893.2021 KL=8501.1885\n",
      "[VI iter 160/800] ELBO=-15353.4111 exp_ll=-6490.3564 KL=8863.0547\n",
      "[VI iter 240/800] ELBO=-14627.3730 exp_ll=-5532.9912 KL=9094.3818\n",
      "[VI iter 320/800] ELBO=-14271.4453 exp_ll=-5021.1743 KL=9250.2715\n",
      "[VI iter 400/800] ELBO=-14069.5469 exp_ll=-4713.6851 KL=9355.8623\n",
      "[VI iter 480/800] ELBO=-13942.8623 exp_ll=-4516.7588 KL=9426.1035\n",
      "[VI iter 560/800] ELBO=-13856.7646 exp_ll=-4385.7705 KL=9470.9941\n",
      "[VI iter 640/800] ELBO=-13794.3477 exp_ll=-4296.7261 KL=9497.6211\n",
      "[VI iter 720/800] ELBO=-13746.6777 exp_ll=-4235.5083 KL=9511.1689\n",
      "[VI iter 800/800] ELBO=-13708.8193 exp_ll=-4193.3164 KL=9515.5029\n",
      "Final test RMSE: 0.1926005679038995\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 30 | labelled size = 320 | pool size = 59680 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.153263, train_rmse=0.299877\n",
      "[Train epoch 5/50] loss=0.067200, train_rmse=0.267638\n",
      "[Train epoch 10/50] loss=0.049172, train_rmse=0.231451\n",
      "[Train epoch 15/50] loss=0.035921, train_rmse=0.216523\n",
      "[Train epoch 20/50] loss=0.028450, train_rmse=0.204497\n",
      "[Train epoch 25/50] loss=0.023790, train_rmse=0.198355\n",
      "[Train epoch 30/50] loss=0.021694, train_rmse=0.192674\n",
      "[Train epoch 35/50] loss=0.019647, train_rmse=0.197129\n",
      "[Train epoch 40/50] loss=0.016414, train_rmse=0.194676\n",
      "[Train epoch 45/50] loss=0.015498, train_rmse=0.192221\n",
      "[Train epoch 50/50] loss=0.014459, train_rmse=0.194036\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-100479.9375 exp_ll=-92906.8672 KL=7573.0698\n",
      "[VI iter 80/800] ELBO=-17485.6406 exp_ll=-8970.7051 KL=8514.9346\n",
      "[VI iter 160/800] ELBO=-15418.6514 exp_ll=-6532.9521 KL=8885.6992\n",
      "[VI iter 240/800] ELBO=-14703.2354 exp_ll=-5582.3320 KL=9120.9033\n",
      "[VI iter 320/800] ELBO=-14360.0977 exp_ll=-5081.4189 KL=9278.6787\n",
      "[VI iter 400/800] ELBO=-14167.6885 exp_ll=-4782.3135 KL=9385.3750\n",
      "[VI iter 480/800] ELBO=-14047.8037 exp_ll=-4591.4600 KL=9456.3438\n",
      "[VI iter 560/800] ELBO=-13966.6289 exp_ll=-4464.9653 KL=9501.6631\n",
      "[VI iter 640/800] ELBO=-13907.8223 exp_ll=-4379.3652 KL=9528.4570\n",
      "[VI iter 720/800] ELBO=-13862.9404 exp_ll=-4320.9463 KL=9541.9941\n",
      "[VI iter 800/800] ELBO=-13827.2764 exp_ll=-4281.0254 KL=9546.2510\n",
      "Final test RMSE: 0.19403600398227072\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 31 | labelled size = 330 | pool size = 59670 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.142205, train_rmse=0.288208\n",
      "[Train epoch 5/50] loss=0.068298, train_rmse=0.265405\n",
      "[Train epoch 10/50] loss=0.049901, train_rmse=0.233770\n",
      "[Train epoch 15/50] loss=0.040513, train_rmse=0.219017\n",
      "[Train epoch 20/50] loss=0.031226, train_rmse=0.204407\n",
      "[Train epoch 25/50] loss=0.026254, train_rmse=0.196928\n",
      "[Train epoch 30/50] loss=0.025328, train_rmse=0.198902\n",
      "[Train epoch 35/50] loss=0.021296, train_rmse=0.195152\n",
      "[Train epoch 40/50] loss=0.019199, train_rmse=0.192443\n",
      "[Train epoch 45/50] loss=0.020985, train_rmse=0.195116\n",
      "[Train epoch 50/50] loss=0.017398, train_rmse=0.193894\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-100456.7969 exp_ll=-92902.9531 KL=7553.8408\n",
      "[VI iter 80/800] ELBO=-17979.6934 exp_ll=-9470.7930 KL=8508.9004\n",
      "[VI iter 160/800] ELBO=-15748.7275 exp_ll=-6860.3369 KL=8888.3906\n",
      "[VI iter 240/800] ELBO=-14961.5117 exp_ll=-5829.7988 KL=9131.7129\n",
      "[VI iter 320/800] ELBO=-14583.0732 exp_ll=-5285.7451 KL=9297.3281\n",
      "[VI iter 400/800] ELBO=-14372.3379 exp_ll=-4960.4165 KL=9411.9209\n",
      "[VI iter 480/800] ELBO=-14242.8799 exp_ll=-4752.0283 KL=9490.8516\n",
      "[VI iter 560/800] ELBO=-14156.8555 exp_ll=-4612.8525 KL=9544.0029\n",
      "[VI iter 640/800] ELBO=-14096.1016 exp_ll=-4517.8027 KL=9578.2988\n",
      "[VI iter 720/800] ELBO=-14050.7520 exp_ll=-4451.8921 KL=9598.8594\n",
      "[VI iter 800/800] ELBO=-14015.6465 exp_ll=-4406.0786 KL=9609.5674\n",
      "Final test RMSE: 0.19389360933499467\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 32 | labelled size = 340 | pool size = 59660 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.140642, train_rmse=0.288745\n",
      "[Train epoch 5/50] loss=0.065504, train_rmse=0.255795\n",
      "[Train epoch 10/50] loss=0.046673, train_rmse=0.226555\n",
      "[Train epoch 15/50] loss=0.037391, train_rmse=0.210717\n",
      "[Train epoch 20/50] loss=0.031191, train_rmse=0.203111\n",
      "[Train epoch 25/50] loss=0.023929, train_rmse=0.199945\n",
      "[Train epoch 30/50] loss=0.021787, train_rmse=0.204131\n",
      "[Train epoch 35/50] loss=0.020366, train_rmse=0.197034\n",
      "[Train epoch 40/50] loss=0.017543, train_rmse=0.197890\n",
      "[Train epoch 45/50] loss=0.017465, train_rmse=0.191666\n",
      "[Train epoch 50/50] loss=0.017246, train_rmse=0.195282\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-104927.1016 exp_ll=-97371.0781 KL=7556.0239\n",
      "[VI iter 80/800] ELBO=-18224.1797 exp_ll=-9713.3574 KL=8510.8213\n",
      "[VI iter 160/800] ELBO=-15919.7148 exp_ll=-7029.4883 KL=8890.2266\n",
      "[VI iter 240/800] ELBO=-15109.5713 exp_ll=-5973.5107 KL=9136.0605\n",
      "[VI iter 320/800] ELBO=-14719.1738 exp_ll=-5415.2598 KL=9303.9141\n",
      "[VI iter 400/800] ELBO=-14500.4492 exp_ll=-5080.6016 KL=9419.8477\n",
      "[VI iter 480/800] ELBO=-14365.0039 exp_ll=-4865.5991 KL=9499.4053\n",
      "[VI iter 560/800] ELBO=-14274.7012 exp_ll=-4721.8203 KL=9552.8809\n",
      "[VI iter 640/800] ELBO=-14210.5732 exp_ll=-4623.0586 KL=9587.5146\n",
      "[VI iter 720/800] ELBO=-14162.8125 exp_ll=-4554.2339 KL=9608.5791\n",
      "[VI iter 800/800] ELBO=-14125.9082 exp_ll=-4505.9341 KL=9619.9746\n",
      "Final test RMSE: 0.1952822126907205\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 33 | labelled size = 350 | pool size = 59650 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.143184, train_rmse=0.295428\n",
      "[Train epoch 5/50] loss=0.064645, train_rmse=0.255622\n",
      "[Train epoch 10/50] loss=0.047228, train_rmse=0.225346\n",
      "[Train epoch 15/50] loss=0.037326, train_rmse=0.210318\n",
      "[Train epoch 20/50] loss=0.028409, train_rmse=0.202941\n",
      "[Train epoch 25/50] loss=0.024010, train_rmse=0.197980\n",
      "[Train epoch 30/50] loss=0.021407, train_rmse=0.195347\n",
      "[Train epoch 35/50] loss=0.018117, train_rmse=0.195143\n",
      "[Train epoch 40/50] loss=0.017561, train_rmse=0.195524\n",
      "[Train epoch 45/50] loss=0.016393, train_rmse=0.193551\n",
      "[Train epoch 50/50] loss=0.015050, train_rmse=0.189295\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-114155.8047 exp_ll=-106600.2500 KL=7555.5562\n",
      "[VI iter 80/800] ELBO=-18537.8789 exp_ll=-10038.9521 KL=8498.9277\n",
      "[VI iter 160/800] ELBO=-16139.3691 exp_ll=-7257.4878 KL=8881.8818\n",
      "[VI iter 240/800] ELBO=-15290.7422 exp_ll=-6154.7026 KL=9136.0391\n",
      "[VI iter 320/800] ELBO=-14884.0557 exp_ll=-5570.0264 KL=9314.0293\n",
      "[VI iter 400/800] ELBO=-14658.8457 exp_ll=-5218.7593 KL=9440.0869\n",
      "[VI iter 480/800] ELBO=-14521.1182 exp_ll=-4992.1865 KL=9528.9316\n",
      "[VI iter 560/800] ELBO=-14430.2031 exp_ll=-4839.6943 KL=9590.5088\n",
      "[VI iter 640/800] ELBO=-14366.3984 exp_ll=-4734.4492 KL=9631.9492\n",
      "[VI iter 720/800] ELBO=-14319.0938 exp_ll=-4660.5464 KL=9658.5479\n",
      "[VI iter 800/800] ELBO=-14282.5098 exp_ll=-4608.2114 KL=9674.2988\n",
      "Final test RMSE: 0.18929486066539192\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 34 | labelled size = 360 | pool size = 59640 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.143390, train_rmse=0.289266\n",
      "[Train epoch 5/50] loss=0.064498, train_rmse=0.254992\n",
      "[Train epoch 10/50] loss=0.047119, train_rmse=0.227190\n",
      "[Train epoch 15/50] loss=0.036497, train_rmse=0.209483\n",
      "[Train epoch 20/50] loss=0.028013, train_rmse=0.203108\n",
      "[Train epoch 25/50] loss=0.024922, train_rmse=0.195766\n",
      "[Train epoch 30/50] loss=0.021040, train_rmse=0.198858\n",
      "[Train epoch 35/50] loss=0.017443, train_rmse=0.196728\n",
      "[Train epoch 40/50] loss=0.018458, train_rmse=0.195562\n",
      "[Train epoch 45/50] loss=0.015178, train_rmse=0.190984\n",
      "[Train epoch 50/50] loss=0.015095, train_rmse=0.193134\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-113458.9219 exp_ll=-105896.8750 KL=7562.0503\n",
      "[VI iter 80/800] ELBO=-18910.1660 exp_ll=-10385.6514 KL=8524.5146\n",
      "[VI iter 160/800] ELBO=-16341.9297 exp_ll=-7425.6777 KL=8916.2520\n",
      "[VI iter 240/800] ELBO=-15471.2207 exp_ll=-6300.0479 KL=9171.1729\n",
      "[VI iter 320/800] ELBO=-15053.7197 exp_ll=-5705.5303 KL=9348.1895\n",
      "[VI iter 400/800] ELBO=-14819.3613 exp_ll=-5346.3398 KL=9473.0215\n",
      "[VI iter 480/800] ELBO=-14674.1045 exp_ll=-5113.4326 KL=9560.6719\n",
      "[VI iter 560/800] ELBO=-14577.1348 exp_ll=-4955.9731 KL=9621.1621\n",
      "[VI iter 640/800] ELBO=-14508.4180 exp_ll=-4846.7524 KL=9661.6650\n",
      "[VI iter 720/800] ELBO=-14457.2305 exp_ll=-4769.7295 KL=9687.5010\n",
      "[VI iter 800/800] ELBO=-14417.6494 exp_ll=-4714.9727 KL=9702.6768\n",
      "Final test RMSE: 0.19313403485592884\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 35 | labelled size = 370 | pool size = 59630 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.141487, train_rmse=0.287005\n",
      "[Train epoch 5/50] loss=0.066125, train_rmse=0.256462\n",
      "[Train epoch 10/50] loss=0.048211, train_rmse=0.224711\n",
      "[Train epoch 15/50] loss=0.035652, train_rmse=0.212105\n",
      "[Train epoch 20/50] loss=0.028572, train_rmse=0.197675\n",
      "[Train epoch 25/50] loss=0.023227, train_rmse=0.196538\n",
      "[Train epoch 30/50] loss=0.020355, train_rmse=0.193270\n",
      "[Train epoch 35/50] loss=0.019469, train_rmse=0.188935\n",
      "[Train epoch 40/50] loss=0.018133, train_rmse=0.195116\n",
      "[Train epoch 45/50] loss=0.015362, train_rmse=0.191822\n",
      "[Train epoch 50/50] loss=0.016739, train_rmse=0.185779\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-111694.2500 exp_ll=-104152.6250 KL=7541.6230\n",
      "[VI iter 80/800] ELBO=-18557.4688 exp_ll=-10065.0293 KL=8492.4395\n",
      "[VI iter 160/800] ELBO=-16171.1113 exp_ll=-7293.0000 KL=8878.1113\n",
      "[VI iter 240/800] ELBO=-15376.6191 exp_ll=-6244.3594 KL=9132.2598\n",
      "[VI iter 320/800] ELBO=-15003.6299 exp_ll=-5693.1455 KL=9310.4844\n",
      "[VI iter 400/800] ELBO=-14798.2275 exp_ll=-5360.9541 KL=9437.2734\n",
      "[VI iter 480/800] ELBO=-14672.8418 exp_ll=-5145.6865 KL=9527.1553\n",
      "[VI iter 560/800] ELBO=-14590.1934 exp_ll=-5000.3164 KL=9589.8770\n",
      "[VI iter 640/800] ELBO=-14532.1318 exp_ll=-4899.7197 KL=9632.4121\n",
      "[VI iter 720/800] ELBO=-14489.1484 exp_ll=-4829.2036 KL=9659.9443\n",
      "[VI iter 800/800] ELBO=-14455.7549 exp_ll=-4779.3496 KL=9676.4053\n",
      "Final test RMSE: 0.18577865730959758\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 36 | labelled size = 380 | pool size = 59620 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.143951, train_rmse=0.288928\n",
      "[Train epoch 5/50] loss=0.065611, train_rmse=0.256993\n",
      "[Train epoch 10/50] loss=0.048314, train_rmse=0.227219\n",
      "[Train epoch 15/50] loss=0.038531, train_rmse=0.207140\n",
      "[Train epoch 20/50] loss=0.028585, train_rmse=0.201117\n",
      "[Train epoch 25/50] loss=0.025410, train_rmse=0.198532\n",
      "[Train epoch 30/50] loss=0.021993, train_rmse=0.189665\n",
      "[Train epoch 35/50] loss=0.019315, train_rmse=0.192788\n",
      "[Train epoch 40/50] loss=0.017303, train_rmse=0.190159\n",
      "[Train epoch 45/50] loss=0.016583, train_rmse=0.187539\n",
      "[Train epoch 50/50] loss=0.015664, train_rmse=0.190346\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-108747.2344 exp_ll=-101185.5781 KL=7561.6562\n",
      "[VI iter 80/800] ELBO=-18610.6484 exp_ll=-10093.2012 KL=8517.4482\n",
      "[VI iter 160/800] ELBO=-16236.0244 exp_ll=-7329.6738 KL=8906.3506\n",
      "[VI iter 240/800] ELBO=-15450.6562 exp_ll=-6292.9438 KL=9157.7129\n",
      "[VI iter 320/800] ELBO=-15085.1895 exp_ll=-5753.9233 KL=9331.2656\n",
      "[VI iter 400/800] ELBO=-14884.5391 exp_ll=-5431.2969 KL=9453.2422\n",
      "[VI iter 480/800] ELBO=-14762.1816 exp_ll=-5223.4312 KL=9538.7500\n",
      "[VI iter 560/800] ELBO=-14681.5029 exp_ll=-5083.7939 KL=9597.7090\n",
      "[VI iter 640/800] ELBO=-14624.7051 exp_ll=-4987.5654 KL=9637.1396\n",
      "[VI iter 720/800] ELBO=-14582.6250 exp_ll=-4920.4019 KL=9662.2227\n",
      "[VI iter 800/800] ELBO=-14550.1357 exp_ll=-4873.2637 KL=9676.8721\n",
      "Final test RMSE: 0.19034571854145388\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 37 | labelled size = 390 | pool size = 59610 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.137033, train_rmse=0.290439\n",
      "[Train epoch 5/50] loss=0.067454, train_rmse=0.259861\n",
      "[Train epoch 10/50] loss=0.048964, train_rmse=0.230755\n",
      "[Train epoch 15/50] loss=0.039118, train_rmse=0.213830\n",
      "[Train epoch 20/50] loss=0.034180, train_rmse=0.204112\n",
      "[Train epoch 25/50] loss=0.028914, train_rmse=0.198332\n",
      "[Train epoch 30/50] loss=0.024947, train_rmse=0.190414\n",
      "[Train epoch 35/50] loss=0.023801, train_rmse=0.192121\n",
      "[Train epoch 40/50] loss=0.022947, train_rmse=0.192924\n",
      "[Train epoch 45/50] loss=0.021733, train_rmse=0.189473\n",
      "[Train epoch 50/50] loss=0.019716, train_rmse=0.199514\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-110807.6719 exp_ll=-103256.9297 KL=7550.7461\n",
      "[VI iter 80/800] ELBO=-19241.1328 exp_ll=-10704.1396 KL=8536.9932\n",
      "[VI iter 160/800] ELBO=-16704.8789 exp_ll=-7767.1973 KL=8937.6816\n",
      "[VI iter 240/800] ELBO=-15835.1504 exp_ll=-6633.0728 KL=9202.0781\n",
      "[VI iter 320/800] ELBO=-15424.6836 exp_ll=-6035.9673 KL=9388.7158\n",
      "[VI iter 400/800] ELBO=-15198.1104 exp_ll=-5674.7510 KL=9523.3594\n",
      "[VI iter 480/800] ELBO=-15060.1934 exp_ll=-5439.1899 KL=9621.0039\n",
      "[VI iter 560/800] ELBO=-14970.1602 exp_ll=-5278.5640 KL=9691.5967\n",
      "[VI iter 640/800] ELBO=-14908.0996 exp_ll=-5165.9253 KL=9742.1748\n",
      "[VI iter 720/800] ELBO=-14863.2598 exp_ll=-5085.3779 KL=9777.8818\n",
      "[VI iter 800/800] ELBO=-14829.6357 exp_ll=-5027.0957 KL=9802.5400\n",
      "Final test RMSE: 0.19951425948128687\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 38 | labelled size = 400 | pool size = 59600 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.140439, train_rmse=0.287653\n",
      "[Train epoch 5/50] loss=0.064538, train_rmse=0.252356\n",
      "[Train epoch 10/50] loss=0.045437, train_rmse=0.222478\n",
      "[Train epoch 15/50] loss=0.035831, train_rmse=0.209581\n",
      "[Train epoch 20/50] loss=0.030979, train_rmse=0.198740\n",
      "[Train epoch 25/50] loss=0.026786, train_rmse=0.190824\n",
      "[Train epoch 30/50] loss=0.021764, train_rmse=0.188236\n",
      "[Train epoch 35/50] loss=0.019159, train_rmse=0.191629\n",
      "[Train epoch 40/50] loss=0.018549, train_rmse=0.191889\n",
      "[Train epoch 45/50] loss=0.018558, train_rmse=0.189814\n",
      "[Train epoch 50/50] loss=0.017369, train_rmse=0.188491\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-111547.1094 exp_ll=-103983.0391 KL=7564.0679\n",
      "[VI iter 80/800] ELBO=-19083.0938 exp_ll=-10564.2998 KL=8518.7939\n",
      "[VI iter 160/800] ELBO=-16616.9922 exp_ll=-7702.7939 KL=8914.1973\n",
      "[VI iter 240/800] ELBO=-15781.3730 exp_ll=-6606.4712 KL=9174.9023\n",
      "[VI iter 320/800] ELBO=-15389.4785 exp_ll=-6031.9932 KL=9357.4854\n",
      "[VI iter 400/800] ELBO=-15173.9053 exp_ll=-5686.5889 KL=9487.3164\n",
      "[VI iter 480/800] ELBO=-15042.4922 exp_ll=-5463.0693 KL=9579.4229\n",
      "[VI iter 560/800] ELBO=-14955.9043 exp_ll=-5312.0190 KL=9643.8848\n",
      "[VI iter 640/800] ELBO=-14895.0723 exp_ll=-5207.1470 KL=9687.9248\n",
      "[VI iter 720/800] ELBO=-14850.1543 exp_ll=-5133.2739 KL=9716.8809\n",
      "[VI iter 800/800] ELBO=-14815.5996 exp_ll=-5080.8154 KL=9734.7842\n",
      "Final test RMSE: 0.18849083138486883\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 39 | labelled size = 410 | pool size = 59590 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.141022, train_rmse=0.288961\n",
      "[Train epoch 5/50] loss=0.065379, train_rmse=0.249223\n",
      "[Train epoch 10/50] loss=0.045989, train_rmse=0.219303\n",
      "[Train epoch 15/50] loss=0.037336, train_rmse=0.208175\n",
      "[Train epoch 20/50] loss=0.029623, train_rmse=0.199129\n",
      "[Train epoch 25/50] loss=0.024793, train_rmse=0.192467\n",
      "[Train epoch 30/50] loss=0.021658, train_rmse=0.186907\n",
      "[Train epoch 35/50] loss=0.020018, train_rmse=0.186575\n",
      "[Train epoch 40/50] loss=0.017705, train_rmse=0.181349\n",
      "[Train epoch 45/50] loss=0.017318, train_rmse=0.185251\n",
      "[Train epoch 50/50] loss=0.015148, train_rmse=0.181014\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-123957.9219 exp_ll=-116402.5547 KL=7555.3682\n",
      "[VI iter 80/800] ELBO=-19666.6230 exp_ll=-11149.9570 KL=8516.6660\n",
      "[VI iter 160/800] ELBO=-17070.4766 exp_ll=-8152.9951 KL=8917.4824\n",
      "[VI iter 240/800] ELBO=-16156.7539 exp_ll=-6966.8525 KL=9189.9014\n",
      "[VI iter 320/800] ELBO=-15712.4629 exp_ll=-6326.5908 KL=9385.8721\n",
      "[VI iter 400/800] ELBO=-15463.1836 exp_ll=-5933.9810 KL=9529.2021\n",
      "[VI iter 480/800] ELBO=-15310.3672 exp_ll=-5676.0132 KL=9634.3535\n",
      "[VI iter 560/800] ELBO=-15210.4023 exp_ll=-5499.2612 KL=9711.1416\n",
      "[VI iter 640/800] ELBO=-15141.3652 exp_ll=-5374.7456 KL=9766.6201\n",
      "[VI iter 720/800] ELBO=-15091.4980 exp_ll=-5285.4683 KL=9806.0293\n",
      "[VI iter 800/800] ELBO=-15054.1797 exp_ll=-5220.8247 KL=9833.3555\n",
      "Final test RMSE: 0.18101448600716932\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 40 | labelled size = 420 | pool size = 59580 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.137434, train_rmse=0.289589\n",
      "[Train epoch 5/50] loss=0.064956, train_rmse=0.251901\n",
      "[Train epoch 10/50] loss=0.049111, train_rmse=0.224565\n",
      "[Train epoch 15/50] loss=0.037149, train_rmse=0.205205\n",
      "[Train epoch 20/50] loss=0.029072, train_rmse=0.197865\n",
      "[Train epoch 25/50] loss=0.025270, train_rmse=0.191904\n",
      "[Train epoch 30/50] loss=0.020671, train_rmse=0.184493\n",
      "[Train epoch 35/50] loss=0.020365, train_rmse=0.191891\n",
      "[Train epoch 40/50] loss=0.016852, train_rmse=0.189696\n",
      "[Train epoch 45/50] loss=0.018154, train_rmse=0.185884\n",
      "[Train epoch 50/50] loss=0.014874, train_rmse=0.181429\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-118845.5312 exp_ll=-111287.4688 KL=7558.0645\n",
      "[VI iter 80/800] ELBO=-19556.5508 exp_ll=-11049.7852 KL=8506.7656\n",
      "[VI iter 160/800] ELBO=-16942.2812 exp_ll=-8045.1611 KL=8897.1201\n",
      "[VI iter 240/800] ELBO=-16067.0977 exp_ll=-6909.6279 KL=9157.4697\n",
      "[VI iter 320/800] ELBO=-15652.7207 exp_ll=-6309.6221 KL=9343.0986\n",
      "[VI iter 400/800] ELBO=-15422.5469 exp_ll=-5944.3809 KL=9478.1660\n",
      "[VI iter 480/800] ELBO=-15281.9912 exp_ll=-5705.2178 KL=9576.7734\n",
      "[VI iter 560/800] ELBO=-15190.0459 exp_ll=-5541.7383 KL=9648.3076\n",
      "[VI iter 640/800] ELBO=-15126.4932 exp_ll=-5427.0391 KL=9699.4541\n",
      "[VI iter 720/800] ELBO=-15080.7227 exp_ll=-5345.5249 KL=9735.1973\n",
      "[VI iter 800/800] ELBO=-15045.6650 exp_ll=-5286.3271 KL=9759.3379\n",
      "Final test RMSE: 0.18142931975643747\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 41 | labelled size = 430 | pool size = 59570 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.137254, train_rmse=0.287413\n",
      "[Train epoch 5/50] loss=0.063704, train_rmse=0.254056\n",
      "[Train epoch 10/50] loss=0.047245, train_rmse=0.222140\n",
      "[Train epoch 15/50] loss=0.036049, train_rmse=0.206543\n",
      "[Train epoch 20/50] loss=0.027791, train_rmse=0.195606\n",
      "[Train epoch 25/50] loss=0.022911, train_rmse=0.189266\n",
      "[Train epoch 30/50] loss=0.020218, train_rmse=0.185301\n",
      "[Train epoch 35/50] loss=0.018030, train_rmse=0.179394\n",
      "[Train epoch 40/50] loss=0.018213, train_rmse=0.187652\n",
      "[Train epoch 45/50] loss=0.016182, train_rmse=0.183288\n",
      "[Train epoch 50/50] loss=0.014617, train_rmse=0.182020\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-125104.1797 exp_ll=-117537.0938 KL=7567.0835\n",
      "[VI iter 80/800] ELBO=-19580.5820 exp_ll=-11080.4082 KL=8500.1729\n",
      "[VI iter 160/800] ELBO=-17102.1562 exp_ll=-8211.2383 KL=8890.9170\n",
      "[VI iter 240/800] ELBO=-16220.1104 exp_ll=-7061.6357 KL=9158.4746\n",
      "[VI iter 320/800] ELBO=-15794.0254 exp_ll=-6441.7983 KL=9352.2266\n",
      "[VI iter 400/800] ELBO=-15557.8262 exp_ll=-6063.0249 KL=9494.8008\n",
      "[VI iter 480/800] ELBO=-15414.5645 exp_ll=-5814.7290 KL=9599.8350\n",
      "[VI iter 560/800] ELBO=-15321.4746 exp_ll=-5644.8955 KL=9676.5791\n",
      "[VI iter 640/800] ELBO=-15257.2812 exp_ll=-5525.5288 KL=9731.7529\n",
      "[VI iter 720/800] ELBO=-15210.7646 exp_ll=-5440.3340 KL=9770.4307\n",
      "[VI iter 800/800] ELBO=-15175.6484 exp_ll=-5379.0933 KL=9796.5557\n",
      "Final test RMSE: 0.18202008440212117\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 42 | labelled size = 440 | pool size = 59560 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.139384, train_rmse=0.287841\n",
      "[Train epoch 5/50] loss=0.065418, train_rmse=0.250132\n",
      "[Train epoch 10/50] loss=0.045776, train_rmse=0.219646\n",
      "[Train epoch 15/50] loss=0.034565, train_rmse=0.198163\n",
      "[Train epoch 20/50] loss=0.026552, train_rmse=0.192574\n",
      "[Train epoch 25/50] loss=0.024289, train_rmse=0.184746\n",
      "[Train epoch 30/50] loss=0.021534, train_rmse=0.186363\n",
      "[Train epoch 35/50] loss=0.018455, train_rmse=0.180514\n",
      "[Train epoch 40/50] loss=0.016561, train_rmse=0.176871\n",
      "[Train epoch 45/50] loss=0.014331, train_rmse=0.177611\n",
      "[Train epoch 50/50] loss=0.014189, train_rmse=0.180988\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-126038.2109 exp_ll=-118461.6953 KL=7576.5122\n",
      "[VI iter 80/800] ELBO=-20088.7500 exp_ll=-11568.5234 KL=8520.2256\n",
      "[VI iter 160/800] ELBO=-17424.6445 exp_ll=-8512.9668 KL=8911.6768\n",
      "[VI iter 240/800] ELBO=-16461.5547 exp_ll=-7284.8779 KL=9176.6758\n",
      "[VI iter 320/800] ELBO=-15990.7979 exp_ll=-6623.5537 KL=9367.2441\n",
      "[VI iter 400/800] ELBO=-15728.4473 exp_ll=-6221.1211 KL=9507.3262\n",
      "[VI iter 480/800] ELBO=-15569.0918 exp_ll=-5958.0767 KL=9611.0146\n",
      "[VI iter 560/800] ELBO=-15465.7109 exp_ll=-5778.1509 KL=9687.5596\n",
      "[VI iter 640/800] ELBO=-15394.8350 exp_ll=-5651.3652 KL=9743.4697\n",
      "[VI iter 720/800] ELBO=-15343.8936 exp_ll=-5560.3320 KL=9783.5615\n",
      "[VI iter 800/800] ELBO=-15305.7471 exp_ll=-5494.2363 KL=9811.5107\n",
      "Final test RMSE: 0.18098847342244592\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 43 | labelled size = 450 | pool size = 59550 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.134794, train_rmse=0.290460\n",
      "[Train epoch 5/50] loss=0.066864, train_rmse=0.249063\n",
      "[Train epoch 10/50] loss=0.051968, train_rmse=0.226393\n",
      "[Train epoch 15/50] loss=0.040359, train_rmse=0.207016\n",
      "[Train epoch 20/50] loss=0.037919, train_rmse=0.207055\n",
      "[Train epoch 25/50] loss=0.032355, train_rmse=0.198559\n",
      "[Train epoch 30/50] loss=0.029670, train_rmse=0.200803\n",
      "[Train epoch 35/50] loss=0.028913, train_rmse=0.190984\n",
      "[Train epoch 40/50] loss=0.028557, train_rmse=0.190420\n",
      "[Train epoch 45/50] loss=0.025178, train_rmse=0.188829\n",
      "[Train epoch 50/50] loss=0.023308, train_rmse=0.186349\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-120023.7812 exp_ll=-112458.0391 KL=7565.7451\n",
      "[VI iter 80/800] ELBO=-21231.8984 exp_ll=-12631.3047 KL=8600.5938\n",
      "[VI iter 160/800] ELBO=-18139.3906 exp_ll=-9102.0410 KL=9037.3486\n",
      "[VI iter 240/800] ELBO=-17039.1895 exp_ll=-7707.1050 KL=9332.0850\n",
      "[VI iter 320/800] ELBO=-16505.9844 exp_ll=-6961.0312 KL=9544.9541\n",
      "[VI iter 400/800] ELBO=-16210.3535 exp_ll=-6507.2202 KL=9703.1328\n",
      "[VI iter 480/800] ELBO=-16032.0361 exp_ll=-6209.7100 KL=9822.3262\n",
      "[VI iter 560/800] ELBO=-15917.6523 exp_ll=-6005.0469 KL=9912.6055\n",
      "[VI iter 640/800] ELBO=-15840.6445 exp_ll=-5859.6304 KL=9981.0146\n",
      "[VI iter 720/800] ELBO=-15786.5947 exp_ll=-5753.8594 KL=10032.7354\n",
      "[VI iter 800/800] ELBO=-15747.3809 exp_ll=-5675.7056 KL=10071.6758\n",
      "Final test RMSE: 0.1863491915071931\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 44 | labelled size = 460 | pool size = 59540 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.132663, train_rmse=0.284971\n",
      "[Train epoch 5/50] loss=0.064702, train_rmse=0.250314\n",
      "[Train epoch 10/50] loss=0.047310, train_rmse=0.221655\n",
      "[Train epoch 15/50] loss=0.035706, train_rmse=0.203529\n",
      "[Train epoch 20/50] loss=0.029552, train_rmse=0.189233\n",
      "[Train epoch 25/50] loss=0.024667, train_rmse=0.188109\n",
      "[Train epoch 30/50] loss=0.022187, train_rmse=0.186426\n",
      "[Train epoch 35/50] loss=0.019934, train_rmse=0.182327\n",
      "[Train epoch 40/50] loss=0.018950, train_rmse=0.184112\n",
      "[Train epoch 45/50] loss=0.018463, train_rmse=0.181072\n",
      "[Train epoch 50/50] loss=0.018015, train_rmse=0.184615\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-122635.0000 exp_ll=-115073.9453 KL=7561.0562\n",
      "[VI iter 80/800] ELBO=-20471.0859 exp_ll=-11941.2734 KL=8529.8135\n",
      "[VI iter 160/800] ELBO=-17708.6211 exp_ll=-8771.8652 KL=8936.7559\n",
      "[VI iter 240/800] ELBO=-16731.8164 exp_ll=-7518.4346 KL=9213.3818\n",
      "[VI iter 320/800] ELBO=-16260.5801 exp_ll=-6847.0464 KL=9413.5342\n",
      "[VI iter 400/800] ELBO=-15998.6699 exp_ll=-6437.2871 KL=9561.3828\n",
      "[VI iter 480/800] ELBO=-15839.9121 exp_ll=-6168.6416 KL=9671.2705\n",
      "[VI iter 560/800] ELBO=-15737.4404 exp_ll=-5984.6133 KL=9752.8271\n",
      "[VI iter 640/800] ELBO=-15667.7969 exp_ll=-5854.8574 KL=9812.9395\n",
      "[VI iter 720/800] ELBO=-15618.2656 exp_ll=-5761.5591 KL=9856.7070\n",
      "[VI iter 800/800] ELBO=-15581.6211 exp_ll=-5693.6299 KL=9887.9912\n",
      "Final test RMSE: 0.1846148010954591\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 45 | labelled size = 470 | pool size = 59530 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.132883, train_rmse=0.290356\n",
      "[Train epoch 5/50] loss=0.064035, train_rmse=0.251020\n",
      "[Train epoch 10/50] loss=0.045736, train_rmse=0.224657\n",
      "[Train epoch 15/50] loss=0.036291, train_rmse=0.204745\n",
      "[Train epoch 20/50] loss=0.028612, train_rmse=0.193947\n",
      "[Train epoch 25/50] loss=0.025488, train_rmse=0.187632\n",
      "[Train epoch 30/50] loss=0.022455, train_rmse=0.186637\n",
      "[Train epoch 35/50] loss=0.018377, train_rmse=0.185568\n",
      "[Train epoch 40/50] loss=0.017161, train_rmse=0.182067\n",
      "[Train epoch 45/50] loss=0.017744, train_rmse=0.184623\n",
      "[Train epoch 50/50] loss=0.016288, train_rmse=0.182491\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-128484.3516 exp_ll=-120904.4297 KL=7579.9189\n",
      "[VI iter 80/800] ELBO=-20687.3398 exp_ll=-12139.2305 KL=8548.1104\n",
      "[VI iter 160/800] ELBO=-17798.7539 exp_ll=-8841.1562 KL=8957.5967\n",
      "[VI iter 240/800] ELBO=-16809.3320 exp_ll=-7576.9375 KL=9232.3955\n",
      "[VI iter 320/800] ELBO=-16339.4277 exp_ll=-6910.7344 KL=9428.6934\n",
      "[VI iter 400/800] ELBO=-16079.4941 exp_ll=-6507.4966 KL=9571.9971\n",
      "[VI iter 480/800] ELBO=-15921.7354 exp_ll=-6244.2949 KL=9677.4404\n",
      "[VI iter 560/800] ELBO=-15819.4688 exp_ll=-6064.3896 KL=9755.0791\n",
      "[VI iter 640/800] ELBO=-15749.6465 exp_ll=-5937.6670 KL=9811.9795\n",
      "[VI iter 720/800] ELBO=-15699.8271 exp_ll=-5846.5498 KL=9853.2773\n",
      "[VI iter 800/800] ELBO=-15662.9395 exp_ll=-5780.1567 KL=9882.7822\n",
      "Final test RMSE: 0.18249054781068816\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 46 | labelled size = 480 | pool size = 59520 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.136379, train_rmse=0.290403\n",
      "[Train epoch 5/50] loss=0.066403, train_rmse=0.255827\n",
      "[Train epoch 10/50] loss=0.046986, train_rmse=0.219352\n",
      "[Train epoch 15/50] loss=0.034768, train_rmse=0.199789\n",
      "[Train epoch 20/50] loss=0.029043, train_rmse=0.188313\n",
      "[Train epoch 25/50] loss=0.023943, train_rmse=0.183006\n",
      "[Train epoch 30/50] loss=0.021528, train_rmse=0.184504\n",
      "[Train epoch 35/50] loss=0.019340, train_rmse=0.183056\n",
      "[Train epoch 40/50] loss=0.017232, train_rmse=0.185308\n",
      "[Train epoch 45/50] loss=0.016849, train_rmse=0.178436\n",
      "[Train epoch 50/50] loss=0.015284, train_rmse=0.181373\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-132175.9688 exp_ll=-124612.6172 KL=7563.3501\n",
      "[VI iter 80/800] ELBO=-20619.5352 exp_ll=-12109.9766 KL=8509.5586\n",
      "[VI iter 160/800] ELBO=-17878.5859 exp_ll=-8976.2812 KL=8902.3057\n",
      "[VI iter 240/800] ELBO=-16906.6875 exp_ll=-7735.5811 KL=9171.1074\n",
      "[VI iter 320/800] ELBO=-16430.7734 exp_ll=-7064.2920 KL=9366.4814\n",
      "[VI iter 400/800] ELBO=-16162.5469 exp_ll=-6651.0732 KL=9511.4736\n",
      "[VI iter 480/800] ELBO=-15998.0332 exp_ll=-6378.2061 KL=9619.8271\n",
      "[VI iter 560/800] ELBO=-15890.6934 exp_ll=-6190.0132 KL=9700.6797\n",
      "[VI iter 640/800] ELBO=-15817.0742 exp_ll=-6056.5327 KL=9760.5420\n",
      "[VI iter 720/800] ELBO=-15764.1807 exp_ll=-5959.9014 KL=9804.2793\n",
      "[VI iter 800/800] ELBO=-15724.9453 exp_ll=-5889.3125 KL=9835.6328\n",
      "Final test RMSE: 0.1813731399601127\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 47 | labelled size = 490 | pool size = 59510 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.130692, train_rmse=0.284190\n",
      "[Train epoch 5/50] loss=0.064683, train_rmse=0.251363\n",
      "[Train epoch 10/50] loss=0.046129, train_rmse=0.213830\n",
      "[Train epoch 15/50] loss=0.034948, train_rmse=0.202899\n",
      "[Train epoch 20/50] loss=0.029094, train_rmse=0.190879\n",
      "[Train epoch 25/50] loss=0.023349, train_rmse=0.182898\n",
      "[Train epoch 30/50] loss=0.020644, train_rmse=0.188302\n",
      "[Train epoch 35/50] loss=0.019836, train_rmse=0.179611\n",
      "[Train epoch 40/50] loss=0.017755, train_rmse=0.183146\n",
      "[Train epoch 45/50] loss=0.015963, train_rmse=0.180088\n",
      "[Train epoch 50/50] loss=0.016227, train_rmse=0.176709\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-134861.7188 exp_ll=-127313.8906 KL=7547.8354\n",
      "[VI iter 80/800] ELBO=-20994.2129 exp_ll=-12511.7793 KL=8482.4336\n",
      "[VI iter 160/800] ELBO=-18102.5957 exp_ll=-9218.7129 KL=8883.8828\n",
      "[VI iter 240/800] ELBO=-17060.3281 exp_ll=-7899.7646 KL=9160.5645\n",
      "[VI iter 320/800] ELBO=-16559.1191 exp_ll=-7197.3154 KL=9361.8037\n",
      "[VI iter 400/800] ELBO=-16279.9453 exp_ll=-6768.8398 KL=9511.1055\n",
      "[VI iter 480/800] ELBO=-16109.1602 exp_ll=-6486.7485 KL=9622.4111\n",
      "[VI iter 560/800] ELBO=-15997.2686 exp_ll=-6292.2803 KL=9704.9883\n",
      "[VI iter 640/800] ELBO=-15919.6992 exp_ll=-6154.2246 KL=9765.4746\n",
      "[VI iter 720/800] ELBO=-15863.3223 exp_ll=-6054.4429 KL=9808.8799\n",
      "[VI iter 800/800] ELBO=-15820.9102 exp_ll=-5981.8032 KL=9839.1064\n",
      "Final test RMSE: 0.17670866494783663\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 48 | labelled size = 500 | pool size = 59500 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.130232, train_rmse=0.285164\n",
      "[Train epoch 5/50] loss=0.062608, train_rmse=0.242323\n",
      "[Train epoch 10/50] loss=0.045506, train_rmse=0.212179\n",
      "[Train epoch 15/50] loss=0.033183, train_rmse=0.199290\n",
      "[Train epoch 20/50] loss=0.027213, train_rmse=0.185917\n",
      "[Train epoch 25/50] loss=0.021339, train_rmse=0.186917\n",
      "[Train epoch 30/50] loss=0.021311, train_rmse=0.183059\n",
      "[Train epoch 35/50] loss=0.018751, train_rmse=0.180473\n",
      "[Train epoch 40/50] loss=0.016901, train_rmse=0.182327\n",
      "[Train epoch 45/50] loss=0.017115, train_rmse=0.178066\n",
      "[Train epoch 50/50] loss=0.015679, train_rmse=0.179517\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-121772.3750 exp_ll=-114213.9297 KL=7558.4492\n",
      "[VI iter 80/800] ELBO=-20108.2383 exp_ll=-11616.6289 KL=8491.6104\n",
      "[VI iter 160/800] ELBO=-17699.6973 exp_ll=-8814.6553 KL=8885.0420\n",
      "[VI iter 240/800] ELBO=-16837.0215 exp_ll=-7682.7466 KL=9154.2754\n",
      "[VI iter 320/800] ELBO=-16419.7109 exp_ll=-7071.6826 KL=9348.0283\n",
      "[VI iter 400/800] ELBO=-16187.5938 exp_ll=-6697.8994 KL=9489.6943\n",
      "[VI iter 480/800] ELBO=-16046.6699 exp_ll=-6453.1162 KL=9593.5537\n",
      "[VI iter 560/800] ELBO=-15955.3340 exp_ll=-6286.0371 KL=9669.2969\n",
      "[VI iter 640/800] ELBO=-15892.8418 exp_ll=-6168.9531 KL=9723.8887\n",
      "[VI iter 720/800] ELBO=-15847.8945 exp_ll=-6085.3862 KL=9762.5078\n",
      "[VI iter 800/800] ELBO=-15814.3594 exp_ll=-6025.2803 KL=9789.0791\n",
      "Final test RMSE: 0.17951716146808508\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 49 | labelled size = 510 | pool size = 59490 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.130270, train_rmse=0.286706\n",
      "[Train epoch 5/50] loss=0.065212, train_rmse=0.250440\n",
      "[Train epoch 10/50] loss=0.046665, train_rmse=0.215933\n",
      "[Train epoch 15/50] loss=0.034827, train_rmse=0.198176\n",
      "[Train epoch 20/50] loss=0.027803, train_rmse=0.187278\n",
      "[Train epoch 25/50] loss=0.022844, train_rmse=0.185041\n",
      "[Train epoch 30/50] loss=0.020683, train_rmse=0.181795\n",
      "[Train epoch 35/50] loss=0.018906, train_rmse=0.177805\n",
      "[Train epoch 40/50] loss=0.017325, train_rmse=0.176043\n",
      "[Train epoch 45/50] loss=0.016580, train_rmse=0.175993\n",
      "[Train epoch 50/50] loss=0.015329, train_rmse=0.174714\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-135896.4375 exp_ll=-128337.2578 KL=7559.1860\n",
      "[VI iter 80/800] ELBO=-21183.5664 exp_ll=-12672.8721 KL=8510.6953\n",
      "[VI iter 160/800] ELBO=-18315.3320 exp_ll=-9398.2324 KL=8917.1006\n",
      "[VI iter 240/800] ELBO=-17303.0898 exp_ll=-8103.2236 KL=9199.8652\n",
      "[VI iter 320/800] ELBO=-16811.5586 exp_ll=-7403.1904 KL=9408.3691\n",
      "[VI iter 400/800] ELBO=-16537.2930 exp_ll=-6972.4082 KL=9564.8857\n",
      "[VI iter 480/800] ELBO=-16370.7217 exp_ll=-6687.7705 KL=9682.9512\n",
      "[VI iter 560/800] ELBO=-16262.9746 exp_ll=-6491.1636 KL=9771.8115\n",
      "[VI iter 640/800] ELBO=-16189.7520 exp_ll=-6351.5625 KL=9838.1895\n",
      "[VI iter 720/800] ELBO=-16137.2266 exp_ll=-6250.0679 KL=9887.1582\n",
      "[VI iter 800/800] ELBO=-16098.4414 exp_ll=-6175.7969 KL=9922.6445\n",
      "Final test RMSE: 0.17471431048748098\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 50 | labelled size = 520 | pool size = 59480 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.127717, train_rmse=0.284423\n",
      "[Train epoch 5/50] loss=0.064333, train_rmse=0.247855\n",
      "[Train epoch 10/50] loss=0.050725, train_rmse=0.218175\n",
      "[Train epoch 15/50] loss=0.038488, train_rmse=0.203577\n",
      "[Train epoch 20/50] loss=0.032702, train_rmse=0.193364\n",
      "[Train epoch 25/50] loss=0.028035, train_rmse=0.188612\n",
      "[Train epoch 30/50] loss=0.023785, train_rmse=0.187948\n",
      "[Train epoch 35/50] loss=0.021991, train_rmse=0.181645\n",
      "[Train epoch 40/50] loss=0.021547, train_rmse=0.186336\n",
      "[Train epoch 45/50] loss=0.019634, train_rmse=0.179625\n",
      "[Train epoch 50/50] loss=0.018552, train_rmse=0.176419\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-133722.9375 exp_ll=-126155.1719 KL=7567.7725\n",
      "[VI iter 80/800] ELBO=-21883.0781 exp_ll=-13344.4424 KL=8538.6348\n",
      "[VI iter 160/800] ELBO=-18687.1367 exp_ll=-9722.4619 KL=8964.6758\n",
      "[VI iter 240/800] ELBO=-17575.4082 exp_ll=-8316.1367 KL=9259.2715\n",
      "[VI iter 320/800] ELBO=-17047.9863 exp_ll=-7572.3755 KL=9475.6104\n",
      "[VI iter 400/800] ELBO=-16757.1953 exp_ll=-7119.2783 KL=9637.9180\n",
      "[VI iter 480/800] ELBO=-16581.8008 exp_ll=-6821.2412 KL=9760.5605\n",
      "[VI iter 560/800] ELBO=-16469.0195 exp_ll=-6615.8594 KL=9853.1592\n",
      "[VI iter 640/800] ELBO=-16392.6289 exp_ll=-6470.0044 KL=9922.6250\n",
      "[VI iter 720/800] ELBO=-16338.5195 exp_ll=-6364.3662 KL=9974.1533\n",
      "[VI iter 800/800] ELBO=-16298.6084 exp_ll=-6286.8408 KL=10011.7676\n",
      "Final test RMSE: 0.17641945364965114\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 51 | labelled size = 530 | pool size = 59470 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.127261, train_rmse=0.287331\n",
      "[Train epoch 5/50] loss=0.062882, train_rmse=0.244106\n",
      "[Train epoch 10/50] loss=0.045765, train_rmse=0.210635\n",
      "[Train epoch 15/50] loss=0.036883, train_rmse=0.197482\n",
      "[Train epoch 20/50] loss=0.031352, train_rmse=0.196104\n",
      "[Train epoch 25/50] loss=0.024733, train_rmse=0.186610\n",
      "[Train epoch 30/50] loss=0.023608, train_rmse=0.184699\n",
      "[Train epoch 35/50] loss=0.019351, train_rmse=0.183786\n",
      "[Train epoch 40/50] loss=0.018908, train_rmse=0.179449\n",
      "[Train epoch 45/50] loss=0.018946, train_rmse=0.180920\n",
      "[Train epoch 50/50] loss=0.016561, train_rmse=0.177302\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-150057.8750 exp_ll=-142498.2031 KL=7559.6777\n",
      "[VI iter 80/800] ELBO=-22279.8203 exp_ll=-13773.5801 KL=8506.2402\n",
      "[VI iter 160/800] ELBO=-18981.6680 exp_ll=-10067.5342 KL=8914.1328\n",
      "[VI iter 240/800] ELBO=-17819.3398 exp_ll=-8619.1895 KL=9200.1514\n",
      "[VI iter 320/800] ELBO=-17249.2168 exp_ll=-7835.4238 KL=9413.7930\n",
      "[VI iter 400/800] ELBO=-16926.9004 exp_ll=-7350.0366 KL=9576.8633\n",
      "[VI iter 480/800] ELBO=-16729.1191 exp_ll=-7026.7383 KL=9702.3809\n",
      "[VI iter 560/800] ELBO=-16600.3203 exp_ll=-6801.1606 KL=9799.1602\n",
      "[VI iter 640/800] ELBO=-16512.5137 exp_ll=-6638.9536 KL=9873.5596\n",
      "[VI iter 720/800] ELBO=-16450.1113 exp_ll=-6519.7534 KL=9930.3574\n",
      "[VI iter 800/800] ELBO=-16404.0703 exp_ll=-6430.8271 KL=9973.2441\n",
      "Final test RMSE: 0.17730211500884702\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 52 | labelled size = 540 | pool size = 59460 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.130359, train_rmse=0.286286\n",
      "[Train epoch 5/50] loss=0.061743, train_rmse=0.241675\n",
      "[Train epoch 10/50] loss=0.044098, train_rmse=0.210004\n",
      "[Train epoch 15/50] loss=0.034201, train_rmse=0.196715\n",
      "[Train epoch 20/50] loss=0.027781, train_rmse=0.186871\n",
      "[Train epoch 25/50] loss=0.022847, train_rmse=0.179648\n",
      "[Train epoch 30/50] loss=0.021024, train_rmse=0.181528\n",
      "[Train epoch 35/50] loss=0.018956, train_rmse=0.180032\n",
      "[Train epoch 40/50] loss=0.018997, train_rmse=0.185973\n",
      "[Train epoch 45/50] loss=0.015791, train_rmse=0.180076\n",
      "[Train epoch 50/50] loss=0.016848, train_rmse=0.176965\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-150292.3594 exp_ll=-142736.6562 KL=7555.7031\n",
      "[VI iter 80/800] ELBO=-21788.9766 exp_ll=-13316.3535 KL=8472.6240\n",
      "[VI iter 160/800] ELBO=-18771.3301 exp_ll=-9911.7695 KL=8859.5605\n",
      "[VI iter 240/800] ELBO=-17674.2363 exp_ll=-8544.7891 KL=9129.4473\n",
      "[VI iter 320/800] ELBO=-17136.0156 exp_ll=-7806.3008 KL=9329.7148\n",
      "[VI iter 400/800] ELBO=-16833.4746 exp_ll=-7351.3774 KL=9482.0977\n",
      "[VI iter 480/800] ELBO=-16648.3242 exp_ll=-7049.1470 KL=9599.1777\n",
      "[VI iter 560/800] ELBO=-16527.7383 exp_ll=-6838.4551 KL=9689.2832\n",
      "[VI iter 640/800] ELBO=-16445.3262 exp_ll=-6686.9702 KL=9758.3564\n",
      "[VI iter 720/800] ELBO=-16386.4980 exp_ll=-6575.6431 KL=9810.8555\n",
      "[VI iter 800/800] ELBO=-16343.0430 exp_ll=-6492.7915 KL=9850.2520\n",
      "Final test RMSE: 0.17696546631612114\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 53 | labelled size = 550 | pool size = 59450 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.128546, train_rmse=0.288748\n",
      "[Train epoch 5/50] loss=0.062713, train_rmse=0.246258\n",
      "[Train epoch 10/50] loss=0.046063, train_rmse=0.212174\n",
      "[Train epoch 15/50] loss=0.034333, train_rmse=0.192681\n",
      "[Train epoch 20/50] loss=0.027133, train_rmse=0.188370\n",
      "[Train epoch 25/50] loss=0.023432, train_rmse=0.184984\n",
      "[Train epoch 30/50] loss=0.019615, train_rmse=0.177788\n",
      "[Train epoch 35/50] loss=0.018665, train_rmse=0.178497\n",
      "[Train epoch 40/50] loss=0.017277, train_rmse=0.189284\n",
      "[Train epoch 45/50] loss=0.016153, train_rmse=0.179288\n",
      "[Train epoch 50/50] loss=0.016424, train_rmse=0.179712\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-139700.9688 exp_ll=-132133.9844 KL=7566.9912\n",
      "[VI iter 80/800] ELBO=-21556.3730 exp_ll=-13057.8145 KL=8498.5586\n",
      "[VI iter 160/800] ELBO=-18679.9219 exp_ll=-9779.7021 KL=8900.2188\n",
      "[VI iter 240/800] ELBO=-17659.8730 exp_ll=-8478.5488 KL=9181.3242\n",
      "[VI iter 320/800] ELBO=-17164.7148 exp_ll=-7775.2036 KL=9389.5107\n",
      "[VI iter 400/800] ELBO=-16889.4141 exp_ll=-7342.7373 KL=9546.6758\n",
      "[VI iter 480/800] ELBO=-16722.9043 exp_ll=-7056.9170 KL=9665.9873\n",
      "[VI iter 560/800] ELBO=-16615.6992 exp_ll=-6859.3403 KL=9756.3594\n",
      "[VI iter 640/800] ELBO=-16543.0547 exp_ll=-6718.7773 KL=9824.2773\n",
      "[VI iter 720/800] ELBO=-16491.5352 exp_ll=-6616.8555 KL=9874.6797\n",
      "[VI iter 800/800] ELBO=-16453.5078 exp_ll=-6542.0723 KL=9911.4346\n",
      "Final test RMSE: 0.1797120320167771\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 54 | labelled size = 560 | pool size = 59440 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.124387, train_rmse=0.284099\n",
      "[Train epoch 5/50] loss=0.063301, train_rmse=0.244378\n",
      "[Train epoch 10/50] loss=0.042009, train_rmse=0.211723\n",
      "[Train epoch 15/50] loss=0.034641, train_rmse=0.193720\n",
      "[Train epoch 20/50] loss=0.027789, train_rmse=0.185797\n",
      "[Train epoch 25/50] loss=0.022899, train_rmse=0.182095\n",
      "[Train epoch 30/50] loss=0.020431, train_rmse=0.176130\n",
      "[Train epoch 35/50] loss=0.017481, train_rmse=0.180989\n",
      "[Train epoch 40/50] loss=0.016944, train_rmse=0.187320\n",
      "[Train epoch 45/50] loss=0.016908, train_rmse=0.174930\n",
      "[Train epoch 50/50] loss=0.014540, train_rmse=0.176322\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-140019.2812 exp_ll=-132444.4062 KL=7574.8706\n",
      "[VI iter 80/800] ELBO=-21624.4766 exp_ll=-13120.2305 KL=8504.2461\n",
      "[VI iter 160/800] ELBO=-18799.3047 exp_ll=-9896.2988 KL=8903.0059\n",
      "[VI iter 240/800] ELBO=-17760.3145 exp_ll=-8577.6807 KL=9182.6338\n",
      "[VI iter 320/800] ELBO=-17251.5195 exp_ll=-7862.6152 KL=9388.9033\n",
      "[VI iter 400/800] ELBO=-16967.7598 exp_ll=-7424.1963 KL=9543.5635\n",
      "[VI iter 480/800] ELBO=-16795.8359 exp_ll=-7135.8184 KL=9660.0186\n",
      "[VI iter 560/800] ELBO=-16685.0488 exp_ll=-6937.5801 KL=9747.4688\n",
      "[VI iter 640/800] ELBO=-16609.7656 exp_ll=-6797.1504 KL=9812.6143\n",
      "[VI iter 720/800] ELBO=-16556.3359 exp_ll=-6695.8193 KL=9860.5156\n",
      "[VI iter 800/800] ELBO=-16516.8711 exp_ll=-6621.7939 KL=9895.0771\n",
      "Final test RMSE: 0.17632236854983505\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 55 | labelled size = 570 | pool size = 59430 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.124342, train_rmse=0.286847\n",
      "[Train epoch 5/50] loss=0.062497, train_rmse=0.242633\n",
      "[Train epoch 10/50] loss=0.044453, train_rmse=0.211258\n",
      "[Train epoch 15/50] loss=0.034141, train_rmse=0.193123\n",
      "[Train epoch 20/50] loss=0.027995, train_rmse=0.191542\n",
      "[Train epoch 25/50] loss=0.024080, train_rmse=0.186805\n",
      "[Train epoch 30/50] loss=0.019851, train_rmse=0.183579\n",
      "[Train epoch 35/50] loss=0.020459, train_rmse=0.188944\n",
      "[Train epoch 40/50] loss=0.016578, train_rmse=0.177740\n",
      "[Train epoch 45/50] loss=0.015328, train_rmse=0.182846\n",
      "[Train epoch 50/50] loss=0.016599, train_rmse=0.180574\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-142435.4219 exp_ll=-134856.9062 KL=7578.5146\n",
      "[VI iter 80/800] ELBO=-21940.6992 exp_ll=-13423.4629 KL=8517.2354\n",
      "[VI iter 160/800] ELBO=-18949.2891 exp_ll=-10033.8926 KL=8915.3975\n",
      "[VI iter 240/800] ELBO=-17897.4492 exp_ll=-8706.2461 KL=9191.2021\n",
      "[VI iter 320/800] ELBO=-17390.7578 exp_ll=-7996.2832 KL=9394.4736\n",
      "[VI iter 400/800] ELBO=-17108.0430 exp_ll=-7560.5718 KL=9547.4717\n",
      "[VI iter 480/800] ELBO=-16935.4531 exp_ll=-7272.0610 KL=9663.3916\n",
      "[VI iter 560/800] ELBO=-16823.1426 exp_ll=-7072.0132 KL=9751.1299\n",
      "[VI iter 640/800] ELBO=-16746.2344 exp_ll=-6929.1152 KL=9817.1201\n",
      "[VI iter 720/800] ELBO=-16691.2500 exp_ll=-6825.0361 KL=9866.2129\n",
      "[VI iter 800/800] ELBO=-16650.4023 exp_ll=-6748.2402 KL=9902.1611\n",
      "Final test RMSE: 0.18057428772036035\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 56 | labelled size = 580 | pool size = 59420 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.125593, train_rmse=0.282041\n",
      "[Train epoch 5/50] loss=0.065734, train_rmse=0.243672\n",
      "[Train epoch 10/50] loss=0.050351, train_rmse=0.219714\n",
      "[Train epoch 15/50] loss=0.039870, train_rmse=0.206218\n",
      "[Train epoch 20/50] loss=0.033879, train_rmse=0.192230\n",
      "[Train epoch 25/50] loss=0.030125, train_rmse=0.195847\n",
      "[Train epoch 30/50] loss=0.026194, train_rmse=0.189415\n",
      "[Train epoch 35/50] loss=0.023846, train_rmse=0.181796\n",
      "[Train epoch 40/50] loss=0.022496, train_rmse=0.188085\n",
      "[Train epoch 45/50] loss=0.020275, train_rmse=0.179480\n",
      "[Train epoch 50/50] loss=0.021414, train_rmse=0.177326\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-150541.3281 exp_ll=-142970.5000 KL=7570.8311\n",
      "[VI iter 80/800] ELBO=-23647.5137 exp_ll=-15080.8535 KL=8566.6602\n",
      "[VI iter 160/800] ELBO=-20032.3594 exp_ll=-11026.5586 KL=9005.8008\n",
      "[VI iter 240/800] ELBO=-18724.8281 exp_ll=-9408.2500 KL=9316.5781\n",
      "[VI iter 320/800] ELBO=-18078.7383 exp_ll=-8528.2891 KL=9550.4502\n",
      "[VI iter 400/800] ELBO=-17714.4102 exp_ll=-7983.9150 KL=9730.4961\n",
      "[VI iter 480/800] ELBO=-17492.3789 exp_ll=-7621.7275 KL=9870.6523\n",
      "[VI iter 560/800] ELBO=-17349.4414 exp_ll=-7369.1426 KL=9980.2979\n",
      "[VI iter 640/800] ELBO=-17253.2832 exp_ll=-7187.1387 KL=10066.1445\n",
      "[VI iter 720/800] ELBO=-17186.1719 exp_ll=-7052.9639 KL=10133.2090\n",
      "[VI iter 800/800] ELBO=-17137.8047 exp_ll=-6952.4453 KL=10185.3584\n",
      "Final test RMSE: 0.17732550456428245\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 57 | labelled size = 590 | pool size = 59410 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.127078, train_rmse=0.286771\n",
      "[Train epoch 5/50] loss=0.063817, train_rmse=0.243407\n",
      "[Train epoch 10/50] loss=0.045816, train_rmse=0.212868\n",
      "[Train epoch 15/50] loss=0.035990, train_rmse=0.199838\n",
      "[Train epoch 20/50] loss=0.028354, train_rmse=0.187739\n",
      "[Train epoch 25/50] loss=0.026724, train_rmse=0.186460\n",
      "[Train epoch 30/50] loss=0.020809, train_rmse=0.180007\n",
      "[Train epoch 35/50] loss=0.020822, train_rmse=0.179020\n",
      "[Train epoch 40/50] loss=0.017318, train_rmse=0.174352\n",
      "[Train epoch 45/50] loss=0.016899, train_rmse=0.173842\n",
      "[Train epoch 50/50] loss=0.016141, train_rmse=0.175716\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-148128.9688 exp_ll=-140562.5156 KL=7566.4453\n",
      "[VI iter 80/800] ELBO=-23139.8828 exp_ll=-14605.6953 KL=8534.1875\n",
      "[VI iter 160/800] ELBO=-19745.3926 exp_ll=-10795.9590 KL=8949.4336\n",
      "[VI iter 240/800] ELBO=-18508.8105 exp_ll=-9268.4629 KL=9240.3477\n",
      "[VI iter 320/800] ELBO=-17903.2500 exp_ll=-8445.8711 KL=9457.3779\n",
      "[VI iter 400/800] ELBO=-17563.2832 exp_ll=-7940.0605 KL=9623.2227\n",
      "[VI iter 480/800] ELBO=-17355.9570 exp_ll=-7604.7964 KL=9751.1611\n",
      "[VI iter 560/800] ELBO=-17221.8477 exp_ll=-7371.8086 KL=9850.0391\n",
      "[VI iter 640/800] ELBO=-17130.9746 exp_ll=-7204.7622 KL=9926.2119\n",
      "[VI iter 720/800] ELBO=-17066.6016 exp_ll=-7082.1162 KL=9984.4854\n",
      "[VI iter 800/800] ELBO=-17019.5645 exp_ll=-6990.9663 KL=10028.5977\n",
      "Final test RMSE: 0.175715630648973\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 58 | labelled size = 600 | pool size = 59400 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122599, train_rmse=0.286223\n",
      "[Train epoch 5/50] loss=0.061813, train_rmse=0.244212\n",
      "[Train epoch 10/50] loss=0.044413, train_rmse=0.208834\n",
      "[Train epoch 15/50] loss=0.034527, train_rmse=0.196953\n",
      "[Train epoch 20/50] loss=0.027522, train_rmse=0.187511\n",
      "[Train epoch 25/50] loss=0.024117, train_rmse=0.179115\n",
      "[Train epoch 30/50] loss=0.020155, train_rmse=0.180631\n",
      "[Train epoch 35/50] loss=0.019389, train_rmse=0.177348\n",
      "[Train epoch 40/50] loss=0.016743, train_rmse=0.179486\n",
      "[Train epoch 45/50] loss=0.017464, train_rmse=0.174399\n",
      "[Train epoch 50/50] loss=0.016189, train_rmse=0.184095\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-151689.5938 exp_ll=-144107.4219 KL=7582.1689\n",
      "[VI iter 80/800] ELBO=-22706.7988 exp_ll=-14184.6758 KL=8522.1230\n",
      "[VI iter 160/800] ELBO=-19543.0938 exp_ll=-10616.0000 KL=8927.0938\n",
      "[VI iter 240/800] ELBO=-18404.9375 exp_ll=-9193.3857 KL=9211.5508\n",
      "[VI iter 320/800] ELBO=-17845.5078 exp_ll=-8422.3398 KL=9423.1670\n",
      "[VI iter 400/800] ELBO=-17529.5273 exp_ll=-7945.7993 KL=9583.7285\n",
      "[VI iter 480/800] ELBO=-17335.7969 exp_ll=-7629.4541 KL=9706.3418\n",
      "[VI iter 560/800] ELBO=-17209.6133 exp_ll=-7409.6807 KL=9799.9336\n",
      "[VI iter 640/800] ELBO=-17123.4980 exp_ll=-7252.4683 KL=9871.0293\n",
      "[VI iter 720/800] ELBO=-17062.3359 exp_ll=-7137.7451 KL=9924.5908\n",
      "[VI iter 800/800] ELBO=-17017.1094 exp_ll=-7052.6270 KL=9964.4824\n",
      "Final test RMSE: 0.184094777384274\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 59 | labelled size = 610 | pool size = 59390 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.128201, train_rmse=0.284591\n",
      "[Train epoch 5/50] loss=0.060696, train_rmse=0.240997\n",
      "[Train epoch 10/50] loss=0.043714, train_rmse=0.206391\n",
      "[Train epoch 15/50] loss=0.032727, train_rmse=0.188119\n",
      "[Train epoch 20/50] loss=0.027319, train_rmse=0.177709\n",
      "[Train epoch 25/50] loss=0.020247, train_rmse=0.180417\n",
      "[Train epoch 30/50] loss=0.020660, train_rmse=0.176397\n",
      "[Train epoch 35/50] loss=0.018343, train_rmse=0.181596\n",
      "[Train epoch 40/50] loss=0.016407, train_rmse=0.175219\n",
      "[Train epoch 45/50] loss=0.016393, train_rmse=0.179939\n",
      "[Train epoch 50/50] loss=0.016013, train_rmse=0.179564\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-150076.2188 exp_ll=-142508.1875 KL=7568.0264\n",
      "[VI iter 80/800] ELBO=-22515.6328 exp_ll=-14030.4863 KL=8485.1475\n",
      "[VI iter 160/800] ELBO=-19463.8555 exp_ll=-10592.6152 KL=8871.2393\n",
      "[VI iter 240/800] ELBO=-18368.0430 exp_ll=-9223.3057 KL=9144.7383\n",
      "[VI iter 320/800] ELBO=-17828.3125 exp_ll=-8478.3340 KL=9349.9775\n",
      "[VI iter 400/800] ELBO=-17522.7930 exp_ll=-8015.9092 KL=9506.8838\n",
      "[VI iter 480/800] ELBO=-17334.9766 exp_ll=-7707.4473 KL=9627.5283\n",
      "[VI iter 560/800] ELBO=-17212.5137 exp_ll=-7492.3257 KL=9720.1875\n",
      "[VI iter 640/800] ELBO=-17128.8223 exp_ll=-7337.9077 KL=9790.9150\n",
      "[VI iter 720/800] ELBO=-17069.1680 exp_ll=-7224.8188 KL=9844.3496\n",
      "[VI iter 800/800] ELBO=-17025.0605 exp_ll=-7140.9126 KL=9884.1484\n",
      "Final test RMSE: 0.17956402803269442\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 60 | labelled size = 620 | pool size = 59380 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.124146, train_rmse=0.285082\n",
      "[Train epoch 5/50] loss=0.061567, train_rmse=0.239600\n",
      "[Train epoch 10/50] loss=0.043807, train_rmse=0.211065\n",
      "[Train epoch 15/50] loss=0.034398, train_rmse=0.192581\n",
      "[Train epoch 20/50] loss=0.027596, train_rmse=0.186956\n",
      "[Train epoch 25/50] loss=0.023594, train_rmse=0.179438\n",
      "[Train epoch 30/50] loss=0.019494, train_rmse=0.174569\n",
      "[Train epoch 35/50] loss=0.017564, train_rmse=0.176917\n",
      "[Train epoch 40/50] loss=0.015954, train_rmse=0.182596\n",
      "[Train epoch 45/50] loss=0.016530, train_rmse=0.178242\n",
      "[Train epoch 50/50] loss=0.014542, train_rmse=0.176303\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-156336.4375 exp_ll=-148778.7656 KL=7557.6650\n",
      "[VI iter 80/800] ELBO=-22632.1992 exp_ll=-14154.5342 KL=8477.6641\n",
      "[VI iter 160/800] ELBO=-19560.2500 exp_ll=-10697.9746 KL=8862.2754\n",
      "[VI iter 240/800] ELBO=-18468.7969 exp_ll=-9333.6777 KL=9135.1191\n",
      "[VI iter 320/800] ELBO=-17932.4062 exp_ll=-8591.7617 KL=9340.6445\n",
      "[VI iter 400/800] ELBO=-17628.2422 exp_ll=-8129.5293 KL=9498.7139\n",
      "[VI iter 480/800] ELBO=-17440.9473 exp_ll=-7819.7622 KL=9621.1855\n",
      "[VI iter 560/800] ELBO=-17318.6719 exp_ll=-7602.5820 KL=9716.0898\n",
      "[VI iter 640/800] ELBO=-17235.0137 exp_ll=-7445.7397 KL=9789.2734\n",
      "[VI iter 720/800] ELBO=-17175.4180 exp_ll=-7330.2188 KL=9845.2002\n",
      "[VI iter 800/800] ELBO=-17131.4648 exp_ll=-7244.0674 KL=9887.3984\n",
      "Final test RMSE: 0.17630286549366972\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 61 | labelled size = 630 | pool size = 59370 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.121904, train_rmse=0.287925\n",
      "[Train epoch 5/50] loss=0.061295, train_rmse=0.238284\n",
      "[Train epoch 10/50] loss=0.043728, train_rmse=0.206030\n",
      "[Train epoch 15/50] loss=0.032118, train_rmse=0.191309\n",
      "[Train epoch 20/50] loss=0.025479, train_rmse=0.187335\n",
      "[Train epoch 25/50] loss=0.024732, train_rmse=0.180334\n",
      "[Train epoch 30/50] loss=0.020770, train_rmse=0.186889\n",
      "[Train epoch 35/50] loss=0.017505, train_rmse=0.172861\n",
      "[Train epoch 40/50] loss=0.017201, train_rmse=0.173826\n",
      "[Train epoch 45/50] loss=0.015552, train_rmse=0.174975\n",
      "[Train epoch 50/50] loss=0.015690, train_rmse=0.176935\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-154146.2188 exp_ll=-146603.2812 KL=7542.9326\n",
      "[VI iter 80/800] ELBO=-22766.3516 exp_ll=-14296.5391 KL=8469.8135\n",
      "[VI iter 160/800] ELBO=-19631.4062 exp_ll=-10771.0449 KL=8860.3623\n",
      "[VI iter 240/800] ELBO=-18525.3125 exp_ll=-9389.8477 KL=9135.4648\n",
      "[VI iter 320/800] ELBO=-17986.6953 exp_ll=-8645.0381 KL=9341.6562\n",
      "[VI iter 400/800] ELBO=-17684.9453 exp_ll=-8185.2842 KL=9499.6621\n",
      "[VI iter 480/800] ELBO=-17500.9492 exp_ll=-7879.1904 KL=9621.7598\n",
      "[VI iter 560/800] ELBO=-17381.8027 exp_ll=-7665.6396 KL=9716.1631\n",
      "[VI iter 640/800] ELBO=-17300.8008 exp_ll=-7512.0156 KL=9788.7852\n",
      "[VI iter 720/800] ELBO=-17243.4336 exp_ll=-7399.3252 KL=9844.1084\n",
      "[VI iter 800/800] ELBO=-17201.1113 exp_ll=-7315.4551 KL=9885.6562\n",
      "Final test RMSE: 0.17693482230480323\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 62 | labelled size = 640 | pool size = 59360 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.123561, train_rmse=0.285963\n",
      "[Train epoch 5/50] loss=0.062188, train_rmse=0.241712\n",
      "[Train epoch 10/50] loss=0.043858, train_rmse=0.208373\n",
      "[Train epoch 15/50] loss=0.032892, train_rmse=0.193290\n",
      "[Train epoch 20/50] loss=0.028030, train_rmse=0.181183\n",
      "[Train epoch 25/50] loss=0.023654, train_rmse=0.172903\n",
      "[Train epoch 30/50] loss=0.020030, train_rmse=0.177885\n",
      "[Train epoch 35/50] loss=0.019537, train_rmse=0.170808\n",
      "[Train epoch 40/50] loss=0.016102, train_rmse=0.172237\n",
      "[Train epoch 45/50] loss=0.014634, train_rmse=0.168968\n",
      "[Train epoch 50/50] loss=0.014788, train_rmse=0.173500\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-141389.1562 exp_ll=-133819.6719 KL=7569.4780\n",
      "[VI iter 80/800] ELBO=-22904.3887 exp_ll=-14389.0664 KL=8515.3223\n",
      "[VI iter 160/800] ELBO=-19706.3945 exp_ll=-10782.7852 KL=8923.6104\n",
      "[VI iter 240/800] ELBO=-18608.0117 exp_ll=-9402.0977 KL=9205.9141\n",
      "[VI iter 320/800] ELBO=-18085.7031 exp_ll=-8671.5176 KL=9414.1865\n",
      "[VI iter 400/800] ELBO=-17795.9531 exp_ll=-8224.5400 KL=9571.4141\n",
      "[VI iter 480/800] ELBO=-17619.7500 exp_ll=-7928.8203 KL=9690.9287\n",
      "[VI iter 560/800] ELBO=-17505.4531 exp_ll=-7723.7969 KL=9781.6553\n",
      "[VI iter 640/800] ELBO=-17427.4199 exp_ll=-7577.3584 KL=9850.0615\n",
      "[VI iter 720/800] ELBO=-17371.8242 exp_ll=-7470.7661 KL=9901.0576\n",
      "[VI iter 800/800] ELBO=-17330.6348 exp_ll=-7392.1733 KL=9938.4619\n",
      "Final test RMSE: 0.17350025031596658\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 63 | labelled size = 650 | pool size = 59350 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120997, train_rmse=0.285358\n",
      "[Train epoch 5/50] loss=0.062820, train_rmse=0.240140\n",
      "[Train epoch 10/50] loss=0.045597, train_rmse=0.210067\n",
      "[Train epoch 15/50] loss=0.035652, train_rmse=0.189439\n",
      "[Train epoch 20/50] loss=0.030154, train_rmse=0.189728\n",
      "[Train epoch 25/50] loss=0.025687, train_rmse=0.177092\n",
      "[Train epoch 30/50] loss=0.024329, train_rmse=0.179279\n",
      "[Train epoch 35/50] loss=0.020799, train_rmse=0.173074\n",
      "[Train epoch 40/50] loss=0.019445, train_rmse=0.174591\n",
      "[Train epoch 45/50] loss=0.018344, train_rmse=0.175721\n",
      "[Train epoch 50/50] loss=0.017960, train_rmse=0.175559\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-167184.5156 exp_ll=-159617.8906 KL=7566.6187\n",
      "[VI iter 80/800] ELBO=-24223.5586 exp_ll=-15720.7266 KL=8502.8330\n",
      "[VI iter 160/800] ELBO=-20626.2422 exp_ll=-11717.7988 KL=8908.4443\n",
      "[VI iter 240/800] ELBO=-19290.4590 exp_ll=-10092.7109 KL=9197.7480\n",
      "[VI iter 320/800] ELBO=-18619.6719 exp_ll=-9203.0742 KL=9416.5977\n",
      "[VI iter 400/800] ELBO=-18236.5898 exp_ll=-8650.6729 KL=9585.9170\n",
      "[VI iter 480/800] ELBO=-18000.5156 exp_ll=-8282.2646 KL=9718.2500\n",
      "[VI iter 560/800] ELBO=-17846.7422 exp_ll=-8024.6807 KL=9822.0615\n",
      "[VI iter 640/800] ELBO=-17742.1602 exp_ll=-7838.7031 KL=9903.4561\n",
      "[VI iter 720/800] ELBO=-17668.3320 exp_ll=-7701.3086 KL=9967.0234\n",
      "[VI iter 800/800] ELBO=-17614.3867 exp_ll=-7598.0601 KL=10016.3262\n",
      "Final test RMSE: 0.17555850304806492\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 64 | labelled size = 660 | pool size = 59340 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122989, train_rmse=0.283194\n",
      "[Train epoch 5/50] loss=0.062214, train_rmse=0.237380\n",
      "[Train epoch 10/50] loss=0.043393, train_rmse=0.205724\n",
      "[Train epoch 15/50] loss=0.033480, train_rmse=0.184643\n",
      "[Train epoch 20/50] loss=0.027781, train_rmse=0.182207\n",
      "[Train epoch 25/50] loss=0.023749, train_rmse=0.178405\n",
      "[Train epoch 30/50] loss=0.021337, train_rmse=0.174473\n",
      "[Train epoch 35/50] loss=0.019478, train_rmse=0.170106\n",
      "[Train epoch 40/50] loss=0.017521, train_rmse=0.171417\n",
      "[Train epoch 45/50] loss=0.015809, train_rmse=0.174734\n",
      "[Train epoch 50/50] loss=0.015361, train_rmse=0.170853\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-165853.9844 exp_ll=-158296.9062 KL=7557.0752\n",
      "[VI iter 80/800] ELBO=-24019.8711 exp_ll=-15525.0674 KL=8494.8047\n",
      "[VI iter 160/800] ELBO=-20475.1035 exp_ll=-11579.4121 KL=8895.6914\n",
      "[VI iter 240/800] ELBO=-19202.4141 exp_ll=-10022.1572 KL=9180.2559\n",
      "[VI iter 320/800] ELBO=-18579.7773 exp_ll=-9184.6523 KL=9395.1260\n",
      "[VI iter 400/800] ELBO=-18228.6680 exp_ll=-8667.2109 KL=9561.4561\n",
      "[VI iter 480/800] ELBO=-18013.3750 exp_ll=-8321.5312 KL=9691.8428\n",
      "[VI iter 560/800] ELBO=-17873.6660 exp_ll=-8078.9639 KL=9794.7021\n",
      "[VI iter 640/800] ELBO=-17779.0195 exp_ll=-7903.0015 KL=9876.0186\n",
      "[VI iter 720/800] ELBO=-17712.5566 exp_ll=-7772.3330 KL=9940.2236\n",
      "[VI iter 800/800] ELBO=-17664.4219 exp_ll=-7673.7188 KL=9990.7031\n",
      "Final test RMSE: 0.17085287399029347\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 65 | labelled size = 670 | pool size = 59330 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122557, train_rmse=0.283280\n",
      "[Train epoch 5/50] loss=0.060724, train_rmse=0.237321\n",
      "[Train epoch 10/50] loss=0.044225, train_rmse=0.204371\n",
      "[Train epoch 15/50] loss=0.032338, train_rmse=0.188408\n",
      "[Train epoch 20/50] loss=0.026139, train_rmse=0.182566\n",
      "[Train epoch 25/50] loss=0.024005, train_rmse=0.177469\n",
      "[Train epoch 30/50] loss=0.021156, train_rmse=0.179691\n",
      "[Train epoch 35/50] loss=0.017891, train_rmse=0.170556\n",
      "[Train epoch 40/50] loss=0.016800, train_rmse=0.174789\n",
      "[Train epoch 45/50] loss=0.015952, train_rmse=0.166504\n",
      "[Train epoch 50/50] loss=0.016015, train_rmse=0.174501\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-167401.9375 exp_ll=-159837.9062 KL=7564.0352\n",
      "[VI iter 80/800] ELBO=-23578.4727 exp_ll=-15097.3594 KL=8481.1133\n",
      "[VI iter 160/800] ELBO=-20326.5938 exp_ll=-11457.5625 KL=8869.0303\n",
      "[VI iter 240/800] ELBO=-19156.5703 exp_ll=-10008.0078 KL=9148.5625\n",
      "[VI iter 320/800] ELBO=-18572.2559 exp_ll=-9210.4668 KL=9361.7891\n",
      "[VI iter 400/800] ELBO=-18238.4746 exp_ll=-8710.8438 KL=9527.6309\n",
      "[VI iter 480/800] ELBO=-18032.4180 exp_ll=-8374.8447 KL=9657.5732\n",
      "[VI iter 560/800] ELBO=-17898.0430 exp_ll=-8138.5332 KL=9759.5088\n",
      "[VI iter 640/800] ELBO=-17806.4551 exp_ll=-7967.2188 KL=9839.2363\n",
      "[VI iter 720/800] ELBO=-17741.6641 exp_ll=-7840.4609 KL=9901.2031\n",
      "[VI iter 800/800] ELBO=-17694.0039 exp_ll=-7745.0796 KL=9948.9238\n",
      "Final test RMSE: 0.17450102775456888\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 66 | labelled size = 680 | pool size = 59320 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.119412, train_rmse=0.286170\n",
      "[Train epoch 5/50] loss=0.061769, train_rmse=0.238135\n",
      "[Train epoch 10/50] loss=0.043360, train_rmse=0.204261\n",
      "[Train epoch 15/50] loss=0.033762, train_rmse=0.189459\n",
      "[Train epoch 20/50] loss=0.026815, train_rmse=0.176878\n",
      "[Train epoch 25/50] loss=0.021848, train_rmse=0.177084\n",
      "[Train epoch 30/50] loss=0.020587, train_rmse=0.176866\n",
      "[Train epoch 35/50] loss=0.019062, train_rmse=0.180639\n",
      "[Train epoch 40/50] loss=0.017071, train_rmse=0.177476\n",
      "[Train epoch 45/50] loss=0.015812, train_rmse=0.164116\n",
      "[Train epoch 50/50] loss=0.014461, train_rmse=0.171114\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-159927.3438 exp_ll=-152365.8438 KL=7561.4990\n",
      "[VI iter 80/800] ELBO=-23831.2930 exp_ll=-15326.8301 KL=8504.4639\n",
      "[VI iter 160/800] ELBO=-20347.6172 exp_ll=-11447.2207 KL=8900.3955\n",
      "[VI iter 240/800] ELBO=-19182.3164 exp_ll=-10005.3818 KL=9176.9346\n",
      "[VI iter 320/800] ELBO=-18609.0859 exp_ll=-9224.5098 KL=9384.5771\n",
      "[VI iter 400/800] ELBO=-18283.2188 exp_ll=-8739.0674 KL=9544.1523\n",
      "[VI iter 480/800] ELBO=-18082.5977 exp_ll=-8414.6914 KL=9667.9053\n",
      "[VI iter 560/800] ELBO=-17951.8750 exp_ll=-8187.7861 KL=9764.0889\n",
      "[VI iter 640/800] ELBO=-17862.7227 exp_ll=-8024.0508 KL=9838.6729\n",
      "[VI iter 720/800] ELBO=-17799.4727 exp_ll=-7903.3213 KL=9896.1504\n",
      "[VI iter 800/800] ELBO=-17752.9805 exp_ll=-7812.9722 KL=9940.0078\n",
      "Final test RMSE: 0.17111402491449393\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 67 | labelled size = 690 | pool size = 59310 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.123535, train_rmse=0.287896\n",
      "[Train epoch 5/50] loss=0.060580, train_rmse=0.237952\n",
      "[Train epoch 10/50] loss=0.041164, train_rmse=0.205498\n",
      "[Train epoch 15/50] loss=0.030384, train_rmse=0.186901\n",
      "[Train epoch 20/50] loss=0.025415, train_rmse=0.182670\n",
      "[Train epoch 25/50] loss=0.023418, train_rmse=0.178195\n",
      "[Train epoch 30/50] loss=0.020145, train_rmse=0.176702\n",
      "[Train epoch 35/50] loss=0.017738, train_rmse=0.173915\n",
      "[Train epoch 40/50] loss=0.017008, train_rmse=0.180135\n",
      "[Train epoch 45/50] loss=0.016559, train_rmse=0.170702\n",
      "[Train epoch 50/50] loss=0.015660, train_rmse=0.166803\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-171470.4062 exp_ll=-163925.8906 KL=7544.5078\n",
      "[VI iter 80/800] ELBO=-24183.1348 exp_ll=-15729.9668 KL=8453.1680\n",
      "[VI iter 160/800] ELBO=-20749.5957 exp_ll=-11905.4834 KL=8844.1123\n",
      "[VI iter 240/800] ELBO=-19488.5781 exp_ll=-10361.3818 KL=9127.1963\n",
      "[VI iter 320/800] ELBO=-18852.6621 exp_ll=-9509.0176 KL=9343.6445\n",
      "[VI iter 400/800] ELBO=-18487.9297 exp_ll=-8975.7939 KL=9512.1348\n",
      "[VI iter 480/800] ELBO=-18261.9102 exp_ll=-8617.7676 KL=9644.1416\n",
      "[VI iter 560/800] ELBO=-18114.0039 exp_ll=-8366.3965 KL=9747.6064\n",
      "[VI iter 640/800] ELBO=-18012.8008 exp_ll=-8184.3936 KL=9828.4062\n",
      "[VI iter 720/800] ELBO=-17940.9004 exp_ll=-8049.8252 KL=9891.0752\n",
      "[VI iter 800/800] ELBO=-17887.8320 exp_ll=-7948.6182 KL=9939.2139\n",
      "Final test RMSE: 0.16680270290511812\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 68 | labelled size = 700 | pool size = 59300 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.117508, train_rmse=0.282377\n",
      "[Train epoch 5/50] loss=0.061476, train_rmse=0.237026\n",
      "[Train epoch 10/50] loss=0.044003, train_rmse=0.207539\n",
      "[Train epoch 15/50] loss=0.033445, train_rmse=0.187523\n",
      "[Train epoch 20/50] loss=0.024085, train_rmse=0.176732\n",
      "[Train epoch 25/50] loss=0.020913, train_rmse=0.176189\n",
      "[Train epoch 30/50] loss=0.019906, train_rmse=0.177753\n",
      "[Train epoch 35/50] loss=0.016865, train_rmse=0.177504\n",
      "[Train epoch 40/50] loss=0.016679, train_rmse=0.170774\n",
      "[Train epoch 45/50] loss=0.016509, train_rmse=0.175401\n",
      "[Train epoch 50/50] loss=0.015644, train_rmse=0.170691\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-166130.9844 exp_ll=-158564.1875 KL=7566.8032\n",
      "[VI iter 80/800] ELBO=-23965.0625 exp_ll=-15493.7090 KL=8471.3545\n",
      "[VI iter 160/800] ELBO=-20712.2090 exp_ll=-11855.5156 KL=8856.6934\n",
      "[VI iter 240/800] ELBO=-19474.0469 exp_ll=-10338.4062 KL=9135.6406\n",
      "[VI iter 320/800] ELBO=-18853.6934 exp_ll=-9506.0713 KL=9347.6221\n",
      "[VI iter 400/800] ELBO=-18501.6172 exp_ll=-8989.8691 KL=9511.7480\n",
      "[VI iter 480/800] ELBO=-18285.6719 exp_ll=-8645.8877 KL=9639.7852\n",
      "[VI iter 560/800] ELBO=-18145.4102 exp_ll=-8405.6396 KL=9739.7705\n",
      "[VI iter 640/800] ELBO=-18050.0469 exp_ll=-8232.4688 KL=9817.5781\n",
      "[VI iter 720/800] ELBO=-17982.5859 exp_ll=-8104.8936 KL=9877.6924\n",
      "[VI iter 800/800] ELBO=-17933.0449 exp_ll=-8009.4033 KL=9923.6416\n",
      "Final test RMSE: 0.17069139157262056\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 69 | labelled size = 710 | pool size = 59290 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120064, train_rmse=0.280098\n",
      "[Train epoch 5/50] loss=0.061551, train_rmse=0.239885\n",
      "[Train epoch 10/50] loss=0.046365, train_rmse=0.210350\n",
      "[Train epoch 15/50] loss=0.037382, train_rmse=0.193410\n",
      "[Train epoch 20/50] loss=0.030311, train_rmse=0.185940\n",
      "[Train epoch 25/50] loss=0.026163, train_rmse=0.179045\n",
      "[Train epoch 30/50] loss=0.023446, train_rmse=0.177941\n",
      "[Train epoch 35/50] loss=0.021123, train_rmse=0.177976\n",
      "[Train epoch 40/50] loss=0.019266, train_rmse=0.171472\n",
      "[Train epoch 45/50] loss=0.020334, train_rmse=0.174439\n",
      "[Train epoch 50/50] loss=0.018437, train_rmse=0.173260\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-161400.1562 exp_ll=-153831.2188 KL=7568.9453\n",
      "[VI iter 80/800] ELBO=-24952.1562 exp_ll=-16403.7559 KL=8548.4004\n",
      "[VI iter 160/800] ELBO=-21197.0430 exp_ll=-12220.9570 KL=8976.0859\n",
      "[VI iter 240/800] ELBO=-19885.9570 exp_ll=-10607.2188 KL=9278.7373\n",
      "[VI iter 320/800] ELBO=-19240.6758 exp_ll=-9732.9785 KL=9507.6973\n",
      "[VI iter 400/800] ELBO=-18875.0000 exp_ll=-9189.8662 KL=9685.1328\n",
      "[VI iter 480/800] ELBO=-18650.9297 exp_ll=-8826.8809 KL=9824.0488\n",
      "[VI iter 560/800] ELBO=-18505.9355 exp_ll=-8572.7627 KL=9933.1729\n",
      "[VI iter 640/800] ELBO=-18407.9883 exp_ll=-8389.1592 KL=10018.8301\n",
      "[VI iter 720/800] ELBO=-18339.4258 exp_ll=-8253.5938 KL=10085.8311\n",
      "[VI iter 800/800] ELBO=-18289.7012 exp_ll=-8151.7412 KL=10137.9600\n",
      "Final test RMSE: 0.17325996061759025\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 70 | labelled size = 720 | pool size = 59280 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.121128, train_rmse=0.285409\n",
      "[Train epoch 5/50] loss=0.061515, train_rmse=0.237183\n",
      "[Train epoch 10/50] loss=0.044467, train_rmse=0.202745\n",
      "[Train epoch 15/50] loss=0.035322, train_rmse=0.184822\n",
      "[Train epoch 20/50] loss=0.027534, train_rmse=0.180461\n",
      "[Train epoch 25/50] loss=0.026408, train_rmse=0.185432\n",
      "[Train epoch 30/50] loss=0.020363, train_rmse=0.172336\n",
      "[Train epoch 35/50] loss=0.020510, train_rmse=0.167388\n",
      "[Train epoch 40/50] loss=0.017761, train_rmse=0.170628\n",
      "[Train epoch 45/50] loss=0.018191, train_rmse=0.170076\n",
      "[Train epoch 50/50] loss=0.016087, train_rmse=0.169625\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-185440.8438 exp_ll=-177884.1250 KL=7556.7124\n",
      "[VI iter 80/800] ELBO=-25806.7695 exp_ll=-17305.2910 KL=8501.4795\n",
      "[VI iter 160/800] ELBO=-21597.2070 exp_ll=-12695.1348 KL=8902.0713\n",
      "[VI iter 240/800] ELBO=-20124.5762 exp_ll=-10940.3457 KL=9184.2305\n",
      "[VI iter 320/800] ELBO=-19409.3047 exp_ll=-10011.3516 KL=9397.9541\n",
      "[VI iter 400/800] ELBO=-19002.1992 exp_ll=-9437.1689 KL=9565.0312\n",
      "[VI iter 480/800] ELBO=-18748.3574 exp_ll=-9050.7520 KL=9697.6055\n",
      "[VI iter 560/800] ELBO=-18580.4414 exp_ll=-8776.9746 KL=9803.4658\n",
      "[VI iter 640/800] ELBO=-18464.4375 exp_ll=-8576.3496 KL=9888.0869\n",
      "[VI iter 720/800] ELBO=-18381.4453 exp_ll=-8425.8770 KL=9955.5674\n",
      "[VI iter 800/800] ELBO=-18320.2852 exp_ll=-8311.1777 KL=10009.1074\n",
      "Final test RMSE: 0.16962545689582434\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 71 | labelled size = 730 | pool size = 59270 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.122112, train_rmse=0.284796\n",
      "[Train epoch 5/50] loss=0.060832, train_rmse=0.236548\n",
      "[Train epoch 10/50] loss=0.043428, train_rmse=0.211184\n",
      "[Train epoch 15/50] loss=0.032657, train_rmse=0.188590\n",
      "[Train epoch 20/50] loss=0.025635, train_rmse=0.180858\n",
      "[Train epoch 25/50] loss=0.023038, train_rmse=0.175365\n",
      "[Train epoch 30/50] loss=0.021947, train_rmse=0.179768\n",
      "[Train epoch 35/50] loss=0.018214, train_rmse=0.168093\n",
      "[Train epoch 40/50] loss=0.016264, train_rmse=0.171949\n",
      "[Train epoch 45/50] loss=0.015650, train_rmse=0.178541\n",
      "[Train epoch 50/50] loss=0.015404, train_rmse=0.172382\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-178967.3281 exp_ll=-171407.0156 KL=7560.3140\n",
      "[VI iter 80/800] ELBO=-24985.2637 exp_ll=-16504.6387 KL=8480.6250\n",
      "[VI iter 160/800] ELBO=-21363.8008 exp_ll=-12491.6797 KL=8872.1201\n",
      "[VI iter 240/800] ELBO=-20035.4453 exp_ll=-10878.4883 KL=9156.9570\n",
      "[VI iter 320/800] ELBO=-19369.0820 exp_ll=-9992.9395 KL=9376.1416\n",
      "[VI iter 400/800] ELBO=-18987.3281 exp_ll=-9439.1855 KL=9548.1436\n",
      "[VI iter 480/800] ELBO=-18750.5625 exp_ll=-9066.3086 KL=9684.2529\n",
      "[VI iter 560/800] ELBO=-18595.2305 exp_ll=-8802.9990 KL=9792.2314\n",
      "[VI iter 640/800] ELBO=-18488.7500 exp_ll=-8610.9736 KL=9877.7764\n",
      "[VI iter 720/800] ELBO=-18413.0078 exp_ll=-8467.7539 KL=9945.2529\n",
      "[VI iter 800/800] ELBO=-18357.4551 exp_ll=-8359.3555 KL=9998.0996\n",
      "Final test RMSE: 0.1723816108929705\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 72 | labelled size = 740 | pool size = 59260 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.118916, train_rmse=0.281954\n",
      "[Train epoch 5/50] loss=0.060597, train_rmse=0.234366\n",
      "[Train epoch 10/50] loss=0.042077, train_rmse=0.203966\n",
      "[Train epoch 15/50] loss=0.033232, train_rmse=0.192282\n",
      "[Train epoch 20/50] loss=0.027745, train_rmse=0.178878\n",
      "[Train epoch 25/50] loss=0.021953, train_rmse=0.178238\n",
      "[Train epoch 30/50] loss=0.020617, train_rmse=0.178942\n",
      "[Train epoch 35/50] loss=0.017637, train_rmse=0.176091\n",
      "[Train epoch 40/50] loss=0.016848, train_rmse=0.169616\n",
      "[Train epoch 45/50] loss=0.016242, train_rmse=0.163022\n",
      "[Train epoch 50/50] loss=0.016690, train_rmse=0.169403\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-175342.7344 exp_ll=-167772.9219 KL=7569.8086\n",
      "[VI iter 80/800] ELBO=-24944.0566 exp_ll=-16451.1426 KL=8492.9141\n",
      "[VI iter 160/800] ELBO=-21293.2520 exp_ll=-12404.2324 KL=8889.0195\n",
      "[VI iter 240/800] ELBO=-19978.1797 exp_ll=-10805.0371 KL=9173.1436\n",
      "[VI iter 320/800] ELBO=-19337.0898 exp_ll=-9947.3164 KL=9389.7744\n",
      "[VI iter 400/800] ELBO=-18977.9727 exp_ll=-9419.1191 KL=9558.8545\n",
      "[VI iter 480/800] ELBO=-18758.8828 exp_ll=-9066.7656 KL=9692.1172\n",
      "[VI iter 560/800] ELBO=-18616.9141 exp_ll=-8819.5225 KL=9797.3916\n",
      "[VI iter 640/800] ELBO=-18520.5312 exp_ll=-8640.2002 KL=9880.3311\n",
      "[VI iter 720/800] ELBO=-18452.2754 exp_ll=-8507.0322 KL=9945.2432\n",
      "[VI iter 800/800] ELBO=-18402.2656 exp_ll=-8406.7246 KL=9995.5410\n",
      "Final test RMSE: 0.16940309404854464\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 73 | labelled size = 750 | pool size = 59250 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.119405, train_rmse=0.284441\n",
      "[Train epoch 5/50] loss=0.060240, train_rmse=0.236386\n",
      "[Train epoch 10/50] loss=0.042601, train_rmse=0.201475\n",
      "[Train epoch 15/50] loss=0.035077, train_rmse=0.190965\n",
      "[Train epoch 20/50] loss=0.025607, train_rmse=0.175722\n",
      "[Train epoch 25/50] loss=0.023272, train_rmse=0.179482\n",
      "[Train epoch 30/50] loss=0.020143, train_rmse=0.175973\n",
      "[Train epoch 35/50] loss=0.018352, train_rmse=0.167897\n",
      "[Train epoch 40/50] loss=0.017695, train_rmse=0.173491\n",
      "[Train epoch 45/50] loss=0.017283, train_rmse=0.176125\n",
      "[Train epoch 50/50] loss=0.015072, train_rmse=0.172075\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-166959.8281 exp_ll=-159400.9375 KL=7558.8877\n",
      "[VI iter 80/800] ELBO=-24848.2031 exp_ll=-16370.9961 KL=8477.2061\n",
      "[VI iter 160/800] ELBO=-21366.5430 exp_ll=-12491.1270 KL=8875.4160\n",
      "[VI iter 240/800] ELBO=-20065.4590 exp_ll=-10903.6943 KL=9161.7646\n",
      "[VI iter 320/800] ELBO=-19415.7539 exp_ll=-10036.6641 KL=9379.0908\n",
      "[VI iter 400/800] ELBO=-19047.4922 exp_ll=-9500.0293 KL=9547.4619\n",
      "[VI iter 480/800] ELBO=-18821.6387 exp_ll=-9142.5977 KL=9679.0410\n",
      "[VI iter 560/800] ELBO=-18675.0078 exp_ll=-8892.9775 KL=9782.0293\n",
      "[VI iter 640/800] ELBO=-18575.2754 exp_ll=-8712.9150 KL=9862.3604\n",
      "[VI iter 720/800] ELBO=-18504.7441 exp_ll=-8580.2061 KL=9924.5381\n",
      "[VI iter 800/800] ELBO=-18453.0156 exp_ll=-8480.9092 KL=9972.1055\n",
      "Final test RMSE: 0.17207475208179815\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 74 | labelled size = 760 | pool size = 59240 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.120872, train_rmse=0.285515\n",
      "[Train epoch 5/50] loss=0.061449, train_rmse=0.235024\n",
      "[Train epoch 10/50] loss=0.042245, train_rmse=0.200790\n",
      "[Train epoch 15/50] loss=0.033319, train_rmse=0.180473\n",
      "[Train epoch 20/50] loss=0.024865, train_rmse=0.173431\n",
      "[Train epoch 25/50] loss=0.022976, train_rmse=0.174426\n",
      "[Train epoch 30/50] loss=0.020588, train_rmse=0.175769\n",
      "[Train epoch 35/50] loss=0.017250, train_rmse=0.172004\n",
      "[Train epoch 40/50] loss=0.017439, train_rmse=0.175121\n",
      "[Train epoch 45/50] loss=0.016699, train_rmse=0.167528\n",
      "[Train epoch 50/50] loss=0.014168, train_rmse=0.167930\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-166640.5781 exp_ll=-159075.0938 KL=7565.4771\n",
      "[VI iter 80/800] ELBO=-24294.1660 exp_ll=-15819.9824 KL=8474.1836\n",
      "[VI iter 160/800] ELBO=-21107.7617 exp_ll=-12253.0215 KL=8854.7393\n",
      "[VI iter 240/800] ELBO=-19941.1562 exp_ll=-10811.3164 KL=9129.8389\n",
      "[VI iter 320/800] ELBO=-19358.1816 exp_ll=-10018.0371 KL=9340.1445\n",
      "[VI iter 400/800] ELBO=-19025.3047 exp_ll=-9521.4580 KL=9503.8467\n",
      "[VI iter 480/800] ELBO=-18819.4746 exp_ll=-9187.4189 KL=9632.0557\n",
      "[VI iter 560/800] ELBO=-18684.9336 exp_ll=-8952.4473 KL=9732.4854\n",
      "[VI iter 640/800] ELBO=-18593.0195 exp_ll=-8782.1699 KL=9810.8486\n",
      "[VI iter 720/800] ELBO=-18527.8516 exp_ll=-8656.3037 KL=9871.5469\n",
      "[VI iter 800/800] ELBO=-18479.9766 exp_ll=-8561.9111 KL=9918.0664\n",
      "Final test RMSE: 0.16793010241503145\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 75 | labelled size = 770 | pool size = 59230 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.117025, train_rmse=0.283694\n",
      "[Train epoch 5/50] loss=0.062316, train_rmse=0.237007\n",
      "[Train epoch 10/50] loss=0.048765, train_rmse=0.212729\n",
      "[Train epoch 15/50] loss=0.038974, train_rmse=0.194597\n",
      "[Train epoch 20/50] loss=0.032303, train_rmse=0.182631\n",
      "[Train epoch 25/50] loss=0.034229, train_rmse=0.195033\n",
      "[Train epoch 30/50] loss=0.029445, train_rmse=0.185397\n",
      "[Train epoch 35/50] loss=0.025263, train_rmse=0.177211\n",
      "[Train epoch 40/50] loss=0.024274, train_rmse=0.181951\n",
      "[Train epoch 45/50] loss=0.025075, train_rmse=0.179499\n",
      "[Train epoch 50/50] loss=0.021862, train_rmse=0.173062\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-180392.4844 exp_ll=-172835.2656 KL=7557.2188\n",
      "[VI iter 80/800] ELBO=-27174.4199 exp_ll=-18618.7754 KL=8555.6445\n",
      "[VI iter 160/800] ELBO=-22733.8555 exp_ll=-13736.4414 KL=8997.4131\n",
      "[VI iter 240/800] ELBO=-21098.7988 exp_ll=-11786.8848 KL=9311.9141\n",
      "[VI iter 320/800] ELBO=-20287.0977 exp_ll=-10736.6211 KL=9550.4775\n",
      "[VI iter 400/800] ELBO=-19825.5430 exp_ll=-10088.8428 KL=9736.6992\n",
      "[VI iter 480/800] ELBO=-19541.0742 exp_ll=-9656.5400 KL=9884.5332\n",
      "[VI iter 560/800] ELBO=-19356.0078 exp_ll=-9352.7832 KL=10003.2246\n",
      "[VI iter 640/800] ELBO=-19230.3926 exp_ll=-9131.2617 KL=10099.1309\n",
      "[VI iter 720/800] ELBO=-19142.1758 exp_ll=-8965.4834 KL=10176.6924\n",
      "[VI iter 800/800] ELBO=-19078.3203 exp_ll=-8839.0869 KL=10239.2334\n",
      "Final test RMSE: 0.17306249164871962\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 76 | labelled size = 780 | pool size = 59220 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.119683, train_rmse=0.283910\n",
      "[Train epoch 5/50] loss=0.060540, train_rmse=0.234507\n",
      "[Train epoch 10/50] loss=0.043262, train_rmse=0.204773\n",
      "[Train epoch 15/50] loss=0.034257, train_rmse=0.183260\n",
      "[Train epoch 20/50] loss=0.028001, train_rmse=0.172674\n",
      "[Train epoch 25/50] loss=0.024090, train_rmse=0.172366\n",
      "[Train epoch 30/50] loss=0.023273, train_rmse=0.174733\n",
      "[Train epoch 35/50] loss=0.020250, train_rmse=0.174233\n",
      "[Train epoch 40/50] loss=0.017751, train_rmse=0.171888\n",
      "[Train epoch 45/50] loss=0.018777, train_rmse=0.162284\n",
      "[Train epoch 50/50] loss=0.017494, train_rmse=0.166988\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-186507.9531 exp_ll=-178955.7188 KL=7552.2354\n",
      "[VI iter 80/800] ELBO=-25928.5234 exp_ll=-17449.4922 KL=8479.0303\n",
      "[VI iter 160/800] ELBO=-22104.0000 exp_ll=-13221.8740 KL=8882.1270\n",
      "[VI iter 240/800] ELBO=-20700.8496 exp_ll=-11525.7588 KL=9175.0908\n",
      "[VI iter 320/800] ELBO=-19990.9141 exp_ll=-10589.9775 KL=9400.9375\n",
      "[VI iter 400/800] ELBO=-19582.6133 exp_ll=-10003.6553 KL=9578.9590\n",
      "[VI iter 480/800] ELBO=-19329.4219 exp_ll=-9608.6719 KL=9720.7510\n",
      "[VI iter 560/800] ELBO=-19163.7715 exp_ll=-9329.5918 KL=9834.1797\n",
      "[VI iter 640/800] ELBO=-19050.8965 exp_ll=-9125.9355 KL=9924.9609\n",
      "[VI iter 720/800] ELBO=-18970.8398 exp_ll=-8973.3975 KL=9997.4424\n",
      "[VI iter 800/800] ELBO=-18912.6094 exp_ll=-8857.5596 KL=10055.0498\n",
      "Final test RMSE: 0.16698783061807693\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 77 | labelled size = 790 | pool size = 59210 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.116721, train_rmse=0.282953\n",
      "[Train epoch 5/50] loss=0.060607, train_rmse=0.232698\n",
      "[Train epoch 10/50] loss=0.041363, train_rmse=0.199079\n",
      "[Train epoch 15/50] loss=0.033213, train_rmse=0.178838\n",
      "[Train epoch 20/50] loss=0.026060, train_rmse=0.175418\n",
      "[Train epoch 25/50] loss=0.023955, train_rmse=0.175994\n",
      "[Train epoch 30/50] loss=0.020582, train_rmse=0.168423\n",
      "[Train epoch 35/50] loss=0.017822, train_rmse=0.165634\n",
      "[Train epoch 40/50] loss=0.017792, train_rmse=0.172899\n",
      "[Train epoch 45/50] loss=0.016603, train_rmse=0.170615\n",
      "[Train epoch 50/50] loss=0.015563, train_rmse=0.163810\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-183345.4531 exp_ll=-175785.8438 KL=7559.6162\n",
      "[VI iter 80/800] ELBO=-25711.1543 exp_ll=-17240.1816 KL=8470.9727\n",
      "[VI iter 160/800] ELBO=-21976.4180 exp_ll=-13115.0156 KL=8861.4033\n",
      "[VI iter 240/800] ELBO=-20601.7383 exp_ll=-11459.0762 KL=9142.6631\n",
      "[VI iter 320/800] ELBO=-19914.4902 exp_ll=-10556.9805 KL=9357.5098\n",
      "[VI iter 400/800] ELBO=-19521.5332 exp_ll=-9996.0459 KL=9525.4873\n",
      "[VI iter 480/800] ELBO=-19278.0781 exp_ll=-9619.8604 KL=9658.2188\n",
      "[VI iter 560/800] ELBO=-19118.5547 exp_ll=-9355.0439 KL=9763.5117\n",
      "[VI iter 640/800] ELBO=-19009.3320 exp_ll=-9162.3340 KL=9846.9971\n",
      "[VI iter 720/800] ELBO=-18931.7969 exp_ll=-9018.8711 KL=9912.9268\n",
      "[VI iter 800/800] ELBO=-18874.9336 exp_ll=-8910.2988 KL=9964.6348\n",
      "Final test RMSE: 0.16380971956713308\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 78 | labelled size = 800 | pool size = 59200 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.115313, train_rmse=0.286447\n",
      "[Train epoch 5/50] loss=0.059327, train_rmse=0.229751\n",
      "[Train epoch 10/50] loss=0.041655, train_rmse=0.203815\n",
      "[Train epoch 15/50] loss=0.032415, train_rmse=0.185458\n",
      "[Train epoch 20/50] loss=0.025622, train_rmse=0.175433\n",
      "[Train epoch 25/50] loss=0.021312, train_rmse=0.169784\n",
      "[Train epoch 30/50] loss=0.020152, train_rmse=0.173177\n",
      "[Train epoch 35/50] loss=0.017369, train_rmse=0.166352\n",
      "[Train epoch 40/50] loss=0.017821, train_rmse=0.165333\n",
      "[Train epoch 45/50] loss=0.017155, train_rmse=0.167132\n",
      "[Train epoch 50/50] loss=0.015870, train_rmse=0.160807\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-186494.0781 exp_ll=-178928.2188 KL=7565.8521\n",
      "[VI iter 80/800] ELBO=-25702.0195 exp_ll=-17242.0605 KL=8459.9590\n",
      "[VI iter 160/800] ELBO=-22044.8086 exp_ll=-13203.7334 KL=8841.0762\n",
      "[VI iter 240/800] ELBO=-20679.3594 exp_ll=-11558.2920 KL=9121.0674\n",
      "[VI iter 320/800] ELBO=-19988.3516 exp_ll=-10650.5205 KL=9337.8311\n",
      "[VI iter 400/800] ELBO=-19592.2891 exp_ll=-10083.4199 KL=9508.8701\n",
      "[VI iter 480/800] ELBO=-19347.7656 exp_ll=-9702.8076 KL=9644.9570\n",
      "[VI iter 560/800] ELBO=-19188.4297 exp_ll=-9434.9668 KL=9753.4629\n",
      "[VI iter 640/800] ELBO=-19080.0195 exp_ll=-9240.2539 KL=9839.7656\n",
      "[VI iter 720/800] ELBO=-19003.5273 exp_ll=-9095.5459 KL=9907.9805\n",
      "[VI iter 800/800] ELBO=-18947.5586 exp_ll=-8986.1846 KL=9961.3740\n",
      "Final test RMSE: 0.16080688337472415\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 79 | labelled size = 810 | pool size = 59190 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.114936, train_rmse=0.283767\n",
      "[Train epoch 5/50] loss=0.059829, train_rmse=0.229669\n",
      "[Train epoch 10/50] loss=0.042749, train_rmse=0.196142\n",
      "[Train epoch 15/50] loss=0.031741, train_rmse=0.182249\n",
      "[Train epoch 20/50] loss=0.025344, train_rmse=0.172615\n",
      "[Train epoch 25/50] loss=0.021945, train_rmse=0.171207\n",
      "[Train epoch 30/50] loss=0.019580, train_rmse=0.170758\n",
      "[Train epoch 35/50] loss=0.018329, train_rmse=0.166639\n",
      "[Train epoch 40/50] loss=0.015952, train_rmse=0.164248\n",
      "[Train epoch 45/50] loss=0.016881, train_rmse=0.164710\n",
      "[Train epoch 50/50] loss=0.016151, train_rmse=0.158416\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-190864.5469 exp_ll=-183300.5781 KL=7563.9634\n",
      "[VI iter 80/800] ELBO=-25677.8594 exp_ll=-17212.3965 KL=8465.4639\n",
      "[VI iter 160/800] ELBO=-21909.5859 exp_ll=-13069.1387 KL=8840.4482\n",
      "[VI iter 240/800] ELBO=-20612.3633 exp_ll=-11502.9365 KL=9109.4268\n",
      "[VI iter 320/800] ELBO=-19981.5371 exp_ll=-10664.8652 KL=9316.6719\n",
      "[VI iter 400/800] ELBO=-19621.6738 exp_ll=-10140.8613 KL=9480.8125\n",
      "[VI iter 480/800] ELBO=-19397.4883 exp_ll=-9785.0996 KL=9612.3896\n",
      "[VI iter 560/800] ELBO=-19249.8496 exp_ll=-9531.4883 KL=9718.3613\n",
      "[VI iter 640/800] ELBO=-19148.6133 exp_ll=-9344.8818 KL=9803.7305\n",
      "[VI iter 720/800] ELBO=-19076.8555 exp_ll=-9204.5576 KL=9872.2969\n",
      "[VI iter 800/800] ELBO=-19024.4297 exp_ll=-9097.3809 KL=9927.0498\n",
      "Final test RMSE: 0.15841577465224962\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 80 | labelled size = 820 | pool size = 59180 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.114760, train_rmse=0.282423\n",
      "[Train epoch 5/50] loss=0.059392, train_rmse=0.231627\n",
      "[Train epoch 10/50] loss=0.041687, train_rmse=0.194176\n",
      "[Train epoch 15/50] loss=0.031573, train_rmse=0.178847\n",
      "[Train epoch 20/50] loss=0.027515, train_rmse=0.176872\n",
      "[Train epoch 25/50] loss=0.021640, train_rmse=0.171030\n",
      "[Train epoch 30/50] loss=0.021368, train_rmse=0.164987\n",
      "[Train epoch 35/50] loss=0.017829, train_rmse=0.166832\n",
      "[Train epoch 40/50] loss=0.016647, train_rmse=0.162745\n",
      "[Train epoch 45/50] loss=0.017113, train_rmse=0.163558\n",
      "[Train epoch 50/50] loss=0.016359, train_rmse=0.167188\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-181862.2188 exp_ll=-174313.8438 KL=7548.3701\n",
      "[VI iter 80/800] ELBO=-25860.6719 exp_ll=-17411.8359 KL=8448.8350\n",
      "[VI iter 160/800] ELBO=-22231.8867 exp_ll=-13392.1230 KL=8839.7637\n",
      "[VI iter 240/800] ELBO=-20857.6406 exp_ll=-11733.9883 KL=9123.6514\n",
      "[VI iter 320/800] ELBO=-20166.6953 exp_ll=-10826.2695 KL=9340.4248\n",
      "[VI iter 400/800] ELBO=-19771.1992 exp_ll=-10262.1094 KL=9509.0889\n",
      "[VI iter 480/800] ELBO=-19525.6562 exp_ll=-9884.3242 KL=9641.3320\n",
      "[VI iter 560/800] ELBO=-19364.1270 exp_ll=-9618.9482 KL=9745.1787\n",
      "[VI iter 640/800] ELBO=-19253.0039 exp_ll=-9426.4844 KL=9826.5195\n",
      "[VI iter 720/800] ELBO=-19173.4453 exp_ll=-9283.5898 KL=9889.8545\n",
      "[VI iter 800/800] ELBO=-19114.6562 exp_ll=-9175.9307 KL=9938.7266\n",
      "Final test RMSE: 0.16718848108734619\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 81 | labelled size = 830 | pool size = 59170 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.115959, train_rmse=0.286537\n",
      "[Train epoch 5/50] loss=0.061547, train_rmse=0.234174\n",
      "[Train epoch 10/50] loss=0.041387, train_rmse=0.195220\n",
      "[Train epoch 15/50] loss=0.031591, train_rmse=0.177925\n",
      "[Train epoch 20/50] loss=0.028268, train_rmse=0.170458\n",
      "[Train epoch 25/50] loss=0.022447, train_rmse=0.170505\n",
      "[Train epoch 30/50] loss=0.020116, train_rmse=0.169230\n",
      "[Train epoch 35/50] loss=0.019684, train_rmse=0.171536\n",
      "[Train epoch 40/50] loss=0.016422, train_rmse=0.168923\n",
      "[Train epoch 45/50] loss=0.016160, train_rmse=0.168895\n",
      "[Train epoch 50/50] loss=0.015583, train_rmse=0.166193\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-167390.4844 exp_ll=-159817.5156 KL=7572.9614\n",
      "[VI iter 80/800] ELBO=-25145.3633 exp_ll=-16664.3516 KL=8481.0127\n",
      "[VI iter 160/800] ELBO=-21844.4863 exp_ll=-12972.0156 KL=8872.4707\n",
      "[VI iter 240/800] ELBO=-20631.5977 exp_ll=-11477.2188 KL=9154.3779\n",
      "[VI iter 320/800] ELBO=-20032.3164 exp_ll=-10663.2041 KL=9369.1133\n",
      "[VI iter 400/800] ELBO=-19694.0371 exp_ll=-10157.8213 KL=9536.2158\n",
      "[VI iter 480/800] ELBO=-19487.1797 exp_ll=-9819.8242 KL=9667.3564\n",
      "[VI iter 560/800] ELBO=-19353.2773 exp_ll=-9582.8945 KL=9770.3838\n",
      "[VI iter 640/800] ELBO=-19262.6172 exp_ll=-9411.6367 KL=9850.9795\n",
      "[VI iter 720/800] ELBO=-19198.7070 exp_ll=-9285.2324 KL=9913.4746\n",
      "[VI iter 800/800] ELBO=-19151.9668 exp_ll=-9190.6729 KL=9961.2939\n",
      "Final test RMSE: 0.166193469367501\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 82 | labelled size = 840 | pool size = 59160 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.114548, train_rmse=0.282031\n",
      "[Train epoch 5/50] loss=0.059273, train_rmse=0.231132\n",
      "[Train epoch 10/50] loss=0.043287, train_rmse=0.200199\n",
      "[Train epoch 15/50] loss=0.035353, train_rmse=0.185045\n",
      "[Train epoch 20/50] loss=0.027697, train_rmse=0.174562\n",
      "[Train epoch 25/50] loss=0.024321, train_rmse=0.171566\n",
      "[Train epoch 30/50] loss=0.023038, train_rmse=0.175172\n",
      "[Train epoch 35/50] loss=0.020706, train_rmse=0.169003\n",
      "[Train epoch 40/50] loss=0.021119, train_rmse=0.171119\n",
      "[Train epoch 45/50] loss=0.019284, train_rmse=0.174600\n",
      "[Train epoch 50/50] loss=0.016760, train_rmse=0.161502\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-209949.0469 exp_ll=-202379.0312 KL=7570.0083\n",
      "[VI iter 80/800] ELBO=-28071.7031 exp_ll=-19567.7188 KL=8503.9854\n",
      "[VI iter 160/800] ELBO=-23475.2559 exp_ll=-14565.3027 KL=8909.9531\n",
      "[VI iter 240/800] ELBO=-21798.8477 exp_ll=-12592.7002 KL=9206.1475\n",
      "[VI iter 320/800] ELBO=-20954.2910 exp_ll=-11517.8193 KL=9436.4717\n",
      "[VI iter 400/800] ELBO=-20465.2734 exp_ll=-10845.1143 KL=9620.1582\n",
      "[VI iter 480/800] ELBO=-20158.9531 exp_ll=-10390.4453 KL=9768.5088\n",
      "[VI iter 560/800] ELBO=-19956.8281 exp_ll=-10067.7461 KL=9889.0811\n",
      "[VI iter 640/800] ELBO=-19818.1230 exp_ll=-9830.8086 KL=9987.3145\n",
      "[VI iter 720/800] ELBO=-19719.8320 exp_ll=-9652.5332 KL=10067.2988\n",
      "[VI iter 800/800] ELBO=-19648.2070 exp_ll=-9515.9766 KL=10132.2305\n",
      "Final test RMSE: 0.16150217128185745\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 83 | labelled size = 850 | pool size = 59150 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.117600, train_rmse=0.284639\n",
      "[Train epoch 5/50] loss=0.060543, train_rmse=0.232537\n",
      "[Train epoch 10/50] loss=0.041281, train_rmse=0.197463\n",
      "[Train epoch 15/50] loss=0.033916, train_rmse=0.180909\n",
      "[Train epoch 20/50] loss=0.028092, train_rmse=0.180949\n",
      "[Train epoch 25/50] loss=0.023154, train_rmse=0.171234\n",
      "[Train epoch 30/50] loss=0.019850, train_rmse=0.172093\n",
      "[Train epoch 35/50] loss=0.019150, train_rmse=0.173274\n",
      "[Train epoch 40/50] loss=0.019304, train_rmse=0.163080\n",
      "[Train epoch 45/50] loss=0.017074, train_rmse=0.159968\n",
      "[Train epoch 50/50] loss=0.017672, train_rmse=0.161135\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-197599.4688 exp_ll=-190039.8594 KL=7559.6021\n",
      "[VI iter 80/800] ELBO=-26971.4199 exp_ll=-18494.5898 KL=8476.8301\n",
      "[VI iter 160/800] ELBO=-22981.0371 exp_ll=-14106.5586 KL=8874.4785\n",
      "[VI iter 240/800] ELBO=-21497.8125 exp_ll=-12333.6348 KL=9164.1787\n",
      "[VI iter 320/800] ELBO=-20742.3086 exp_ll=-11354.0918 KL=9388.2178\n",
      "[VI iter 400/800] ELBO=-20304.1680 exp_ll=-10738.6270 KL=9565.5420\n",
      "[VI iter 480/800] ELBO=-20030.4219 exp_ll=-10322.9131 KL=9707.5088\n",
      "[VI iter 560/800] ELBO=-19850.3242 exp_ll=-10028.5449 KL=9821.7803\n",
      "[VI iter 640/800] ELBO=-19727.0938 exp_ll=-9813.2061 KL=9913.8867\n",
      "[VI iter 720/800] ELBO=-19640.0195 exp_ll=-9652.0156 KL=9988.0029\n",
      "[VI iter 800/800] ELBO=-19576.3379 exp_ll=-9528.9541 KL=10047.3838\n",
      "Final test RMSE: 0.16113530935121598\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 84 | labelled size = 860 | pool size = 59140 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.115257, train_rmse=0.280263\n",
      "[Train epoch 5/50] loss=0.058685, train_rmse=0.228646\n",
      "[Train epoch 10/50] loss=0.040818, train_rmse=0.191061\n",
      "[Train epoch 15/50] loss=0.032157, train_rmse=0.182209\n",
      "[Train epoch 20/50] loss=0.025700, train_rmse=0.179291\n",
      "[Train epoch 25/50] loss=0.021762, train_rmse=0.166636\n",
      "[Train epoch 30/50] loss=0.020164, train_rmse=0.164940\n",
      "[Train epoch 35/50] loss=0.018246, train_rmse=0.165431\n",
      "[Train epoch 40/50] loss=0.018329, train_rmse=0.164936\n",
      "[Train epoch 45/50] loss=0.015707, train_rmse=0.164609\n",
      "[Train epoch 50/50] loss=0.016822, train_rmse=0.159544\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-199990.0469 exp_ll=-192436.3594 KL=7553.6826\n",
      "[VI iter 80/800] ELBO=-26972.7676 exp_ll=-18519.0234 KL=8453.7441\n",
      "[VI iter 160/800] ELBO=-22892.2266 exp_ll=-14050.1934 KL=8842.0332\n",
      "[VI iter 240/800] ELBO=-21442.7676 exp_ll=-12318.1553 KL=9124.6123\n",
      "[VI iter 320/800] ELBO=-20718.7109 exp_ll=-11374.9258 KL=9343.7852\n",
      "[VI iter 400/800] ELBO=-20300.0605 exp_ll=-10782.3418 KL=9517.7188\n",
      "[VI iter 480/800] ELBO=-20037.9023 exp_ll=-10380.7891 KL=9657.1123\n",
      "[VI iter 560/800] ELBO=-19864.6836 exp_ll=-10095.4609 KL=9769.2236\n",
      "[VI iter 640/800] ELBO=-19745.3906 exp_ll=-9886.0273 KL=9859.3633\n",
      "[VI iter 720/800] ELBO=-19660.3320 exp_ll=-9728.7402 KL=9931.5908\n",
      "[VI iter 800/800] ELBO=-19597.8555 exp_ll=-9608.7451 KL=9989.1094\n",
      "Final test RMSE: 0.15954388779696152\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 85 | labelled size = 870 | pool size = 59130 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.115387, train_rmse=0.285136\n",
      "[Train epoch 5/50] loss=0.057810, train_rmse=0.229008\n",
      "[Train epoch 10/50] loss=0.040979, train_rmse=0.192838\n",
      "[Train epoch 15/50] loss=0.033557, train_rmse=0.181609\n",
      "[Train epoch 20/50] loss=0.026165, train_rmse=0.175077\n",
      "[Train epoch 25/50] loss=0.022643, train_rmse=0.172950\n",
      "[Train epoch 30/50] loss=0.019320, train_rmse=0.165547\n",
      "[Train epoch 35/50] loss=0.017840, train_rmse=0.165353\n",
      "[Train epoch 40/50] loss=0.016915, train_rmse=0.163946\n",
      "[Train epoch 45/50] loss=0.014610, train_rmse=0.162974\n",
      "[Train epoch 50/50] loss=0.015778, train_rmse=0.161718\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-187823.8906 exp_ll=-180266.6719 KL=7557.2178\n",
      "[VI iter 80/800] ELBO=-26421.5117 exp_ll=-17957.8379 KL=8463.6729\n",
      "[VI iter 160/800] ELBO=-22605.6875 exp_ll=-13757.3525 KL=8848.3359\n",
      "[VI iter 240/800] ELBO=-21251.5508 exp_ll=-12125.2051 KL=9126.3467\n",
      "[VI iter 320/800] ELBO=-20587.3984 exp_ll=-11246.8770 KL=9340.5225\n",
      "[VI iter 400/800] ELBO=-20210.2383 exp_ll=-10700.6729 KL=9509.5645\n",
      "[VI iter 480/800] ELBO=-19977.3086 exp_ll=-10332.9756 KL=9644.3320\n",
      "[VI iter 560/800] ELBO=-19825.0742 exp_ll=-10073.0020 KL=9752.0732\n",
      "[VI iter 640/800] ELBO=-19721.1152 exp_ll=-9883.0723 KL=9838.0430\n",
      "[VI iter 720/800] ELBO=-19647.4492 exp_ll=-9741.1934 KL=9906.2549\n",
      "[VI iter 800/800] ELBO=-19593.4648 exp_ll=-9633.5635 KL=9959.9014\n",
      "Final test RMSE: 0.16171793804609866\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 86 | labelled size = 880 | pool size = 59120 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.117436, train_rmse=0.284791\n",
      "[Train epoch 5/50] loss=0.059097, train_rmse=0.230364\n",
      "[Train epoch 10/50] loss=0.041175, train_rmse=0.197350\n",
      "[Train epoch 15/50] loss=0.033177, train_rmse=0.176167\n",
      "[Train epoch 20/50] loss=0.025355, train_rmse=0.173017\n",
      "[Train epoch 25/50] loss=0.022426, train_rmse=0.171235\n",
      "[Train epoch 30/50] loss=0.020368, train_rmse=0.166934\n",
      "[Train epoch 35/50] loss=0.018131, train_rmse=0.165829\n",
      "[Train epoch 40/50] loss=0.016688, train_rmse=0.173342\n",
      "[Train epoch 45/50] loss=0.016719, train_rmse=0.161487\n",
      "[Train epoch 50/50] loss=0.016455, train_rmse=0.158877\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-206504.5781 exp_ll=-198951.4688 KL=7553.1074\n",
      "[VI iter 80/800] ELBO=-27025.8477 exp_ll=-18582.5508 KL=8443.2959\n",
      "[VI iter 160/800] ELBO=-23130.2930 exp_ll=-14303.9697 KL=8826.3223\n",
      "[VI iter 240/800] ELBO=-21678.3906 exp_ll=-12570.0879 KL=9108.3027\n",
      "[VI iter 320/800] ELBO=-20936.7852 exp_ll=-11608.5625 KL=9328.2227\n",
      "[VI iter 400/800] ELBO=-20505.9336 exp_ll=-11002.2520 KL=9503.6826\n",
      "[VI iter 480/800] ELBO=-20236.6172 exp_ll=-10591.3574 KL=9645.2607\n",
      "[VI iter 560/800] ELBO=-20059.7109 exp_ll=-10299.6016 KL=9760.1084\n",
      "[VI iter 640/800] ELBO=-19938.7539 exp_ll=-10085.3594 KL=9853.3955\n",
      "[VI iter 720/800] ELBO=-19853.4570 exp_ll=-9924.4297 KL=9929.0283\n",
      "[VI iter 800/800] ELBO=-19791.4766 exp_ll=-9801.4082 KL=9990.0674\n",
      "Final test RMSE: 0.1588774976421472\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 87 | labelled size = 890 | pool size = 59110 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.113663, train_rmse=0.281182\n",
      "[Train epoch 5/50] loss=0.058624, train_rmse=0.226015\n",
      "[Train epoch 10/50] loss=0.041214, train_rmse=0.193067\n",
      "[Train epoch 15/50] loss=0.031285, train_rmse=0.174702\n",
      "[Train epoch 20/50] loss=0.025810, train_rmse=0.168016\n",
      "[Train epoch 25/50] loss=0.022939, train_rmse=0.164275\n",
      "[Train epoch 30/50] loss=0.019591, train_rmse=0.163690\n",
      "[Train epoch 35/50] loss=0.016850, train_rmse=0.165473\n",
      "[Train epoch 40/50] loss=0.017323, train_rmse=0.162566\n",
      "[Train epoch 45/50] loss=0.015503, train_rmse=0.159821\n",
      "[Train epoch 50/50] loss=0.015826, train_rmse=0.157970\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-193459.4688 exp_ll=-185884.0938 KL=7575.3779\n",
      "[VI iter 80/800] ELBO=-26580.9961 exp_ll=-18125.1445 KL=8455.8525\n",
      "[VI iter 160/800] ELBO=-22813.4590 exp_ll=-13987.2070 KL=8826.2520\n",
      "[VI iter 240/800] ELBO=-21445.8496 exp_ll=-12349.9424 KL=9095.9072\n",
      "[VI iter 320/800] ELBO=-20766.0586 exp_ll=-11462.1699 KL=9303.8896\n",
      "[VI iter 400/800] ELBO=-20377.2266 exp_ll=-10909.3584 KL=9467.8691\n",
      "[VI iter 480/800] ELBO=-20135.5312 exp_ll=-10537.1875 KL=9598.3447\n",
      "[VI iter 560/800] ELBO=-19976.3555 exp_ll=-10273.9453 KL=9702.4102\n",
      "[VI iter 640/800] ELBO=-19866.7266 exp_ll=-10081.4824 KL=9785.2432\n",
      "[VI iter 720/800] ELBO=-19788.3555 exp_ll=-9937.5342 KL=9850.8213\n",
      "[VI iter 800/800] ELBO=-19730.4062 exp_ll=-9828.1152 KL=9902.2920\n",
      "Final test RMSE: 0.15797025415325106\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 88 | labelled size = 900 | pool size = 59100 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.113593, train_rmse=0.284015\n",
      "[Train epoch 5/50] loss=0.060195, train_rmse=0.233085\n",
      "[Train epoch 10/50] loss=0.043742, train_rmse=0.200347\n",
      "[Train epoch 15/50] loss=0.036553, train_rmse=0.183920\n",
      "[Train epoch 20/50] loss=0.029446, train_rmse=0.184194\n",
      "[Train epoch 25/50] loss=0.029145, train_rmse=0.173371\n",
      "[Train epoch 30/50] loss=0.024843, train_rmse=0.180702\n",
      "[Train epoch 35/50] loss=0.024994, train_rmse=0.174676\n",
      "[Train epoch 40/50] loss=0.021174, train_rmse=0.169501\n",
      "[Train epoch 45/50] loss=0.018984, train_rmse=0.161557\n",
      "[Train epoch 50/50] loss=0.019707, train_rmse=0.166911\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-201772.3750 exp_ll=-194213.7500 KL=7558.6255\n",
      "[VI iter 80/800] ELBO=-28545.9824 exp_ll=-20032.7402 KL=8513.2422\n",
      "[VI iter 160/800] ELBO=-24070.3281 exp_ll=-15137.1230 KL=8933.2041\n",
      "[VI iter 240/800] ELBO=-22397.3438 exp_ll=-13159.0781 KL=9238.2666\n",
      "[VI iter 320/800] ELBO=-21548.9844 exp_ll=-12074.8730 KL=9474.1104\n",
      "[VI iter 400/800] ELBO=-21058.0430 exp_ll=-11396.9082 KL=9661.1357\n",
      "[VI iter 480/800] ELBO=-20751.4453 exp_ll=-10940.0215 KL=9811.4238\n",
      "[VI iter 560/800] ELBO=-20549.7578 exp_ll=-10616.7090 KL=9933.0498\n",
      "[VI iter 640/800] ELBO=-20411.8301 exp_ll=-10380.0410 KL=10031.7891\n",
      "[VI iter 720/800] ELBO=-20314.4141 exp_ll=-10202.4463 KL=10111.9668\n",
      "[VI iter 800/800] ELBO=-20243.6719 exp_ll=-10066.7266 KL=10176.9463\n",
      "Final test RMSE: 0.16691109689068356\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 89 | labelled size = 910 | pool size = 59090 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.112352, train_rmse=0.284604\n",
      "[Train epoch 5/50] loss=0.059771, train_rmse=0.228588\n",
      "[Train epoch 10/50] loss=0.041123, train_rmse=0.192109\n",
      "[Train epoch 15/50] loss=0.032150, train_rmse=0.183417\n",
      "[Train epoch 20/50] loss=0.027504, train_rmse=0.175017\n",
      "[Train epoch 25/50] loss=0.022282, train_rmse=0.171129\n",
      "[Train epoch 30/50] loss=0.020998, train_rmse=0.166361\n",
      "[Train epoch 35/50] loss=0.020012, train_rmse=0.164070\n",
      "[Train epoch 40/50] loss=0.018059, train_rmse=0.162648\n",
      "[Train epoch 45/50] loss=0.015925, train_rmse=0.157020\n",
      "[Train epoch 50/50] loss=0.018213, train_rmse=0.166776\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-187293.2969 exp_ll=-179725.9375 KL=7567.3579\n",
      "[VI iter 80/800] ELBO=-26857.0742 exp_ll=-18376.5234 KL=8480.5518\n",
      "[VI iter 160/800] ELBO=-23106.0430 exp_ll=-14236.8633 KL=8869.1807\n",
      "[VI iter 240/800] ELBO=-21741.0684 exp_ll=-12591.0850 KL=9149.9834\n",
      "[VI iter 320/800] ELBO=-21055.9102 exp_ll=-11690.4629 KL=9365.4473\n",
      "[VI iter 400/800] ELBO=-20661.4180 exp_ll=-11126.9854 KL=9534.4326\n",
      "[VI iter 480/800] ELBO=-20415.4688 exp_ll=-10747.2402 KL=9668.2295\n",
      "[VI iter 560/800] ELBO=-20253.5410 exp_ll=-10479.0439 KL=9774.4971\n",
      "[VI iter 640/800] ELBO=-20142.3398 exp_ll=-10283.5312 KL=9858.8096\n",
      "[VI iter 720/800] ELBO=-20063.1914 exp_ll=-10137.7695 KL=9925.4229\n",
      "[VI iter 800/800] ELBO=-20005.0820 exp_ll=-10027.3906 KL=9977.6924\n",
      "Final test RMSE: 0.1667757850053234\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 90 | labelled size = 920 | pool size = 59080 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.111793, train_rmse=0.278619\n",
      "[Train epoch 5/50] loss=0.057174, train_rmse=0.225456\n",
      "[Train epoch 10/50] loss=0.040883, train_rmse=0.197104\n",
      "[Train epoch 15/50] loss=0.031645, train_rmse=0.178320\n",
      "[Train epoch 20/50] loss=0.025089, train_rmse=0.169852\n",
      "[Train epoch 25/50] loss=0.022601, train_rmse=0.169647\n",
      "[Train epoch 30/50] loss=0.020439, train_rmse=0.160878\n",
      "[Train epoch 35/50] loss=0.020646, train_rmse=0.176509\n",
      "[Train epoch 40/50] loss=0.017851, train_rmse=0.159664\n",
      "[Train epoch 45/50] loss=0.016009, train_rmse=0.159688\n",
      "[Train epoch 50/50] loss=0.016958, train_rmse=0.167385\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-199434.2656 exp_ll=-191868.8906 KL=7565.3691\n",
      "[VI iter 80/800] ELBO=-26967.4023 exp_ll=-18512.7617 KL=8454.6396\n",
      "[VI iter 160/800] ELBO=-23137.4023 exp_ll=-14314.0986 KL=8823.3027\n",
      "[VI iter 240/800] ELBO=-21761.1738 exp_ll=-12671.3008 KL=9089.8730\n",
      "[VI iter 320/800] ELBO=-21076.7734 exp_ll=-11781.2891 KL=9295.4844\n",
      "[VI iter 400/800] ELBO=-20682.7695 exp_ll=-11224.5684 KL=9458.2021\n",
      "[VI iter 480/800] ELBO=-20436.5156 exp_ll=-10848.0752 KL=9588.4404\n",
      "[VI iter 560/800] ELBO=-20273.9219 exp_ll=-10580.8320 KL=9693.0898\n",
      "[VI iter 640/800] ELBO=-20162.0098 exp_ll=-10384.8799 KL=9777.1299\n",
      "[VI iter 720/800] ELBO=-20082.1504 exp_ll=-10237.7861 KL=9844.3643\n",
      "[VI iter 800/800] ELBO=-20023.5703 exp_ll=-10125.7725 KL=9897.7988\n",
      "Final test RMSE: 0.16738526180794389\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 91 | labelled size = 930 | pool size = 59070 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.113713, train_rmse=0.284695\n",
      "[Train epoch 5/50] loss=0.060650, train_rmse=0.227946\n",
      "[Train epoch 10/50] loss=0.042310, train_rmse=0.192299\n",
      "[Train epoch 15/50] loss=0.032392, train_rmse=0.179484\n",
      "[Train epoch 20/50] loss=0.026091, train_rmse=0.172716\n",
      "[Train epoch 25/50] loss=0.022466, train_rmse=0.164211\n",
      "[Train epoch 30/50] loss=0.020883, train_rmse=0.162207\n",
      "[Train epoch 35/50] loss=0.018643, train_rmse=0.163466\n",
      "[Train epoch 40/50] loss=0.017628, train_rmse=0.158375\n",
      "[Train epoch 45/50] loss=0.017075, train_rmse=0.160332\n",
      "[Train epoch 50/50] loss=0.016219, train_rmse=0.160678\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-212121.8281 exp_ll=-204559.7344 KL=7562.0923\n",
      "[VI iter 80/800] ELBO=-27822.4727 exp_ll=-19356.0762 KL=8466.3955\n",
      "[VI iter 160/800] ELBO=-23736.1738 exp_ll=-14886.0742 KL=8850.0996\n",
      "[VI iter 240/800] ELBO=-22237.7305 exp_ll=-13107.1699 KL=9130.5596\n",
      "[VI iter 320/800] ELBO=-21476.6055 exp_ll=-12128.3164 KL=9348.2881\n",
      "[VI iter 400/800] ELBO=-21034.3359 exp_ll=-11513.0342 KL=9521.3027\n",
      "[VI iter 480/800] ELBO=-20756.4570 exp_ll=-11096.0703 KL=9660.3867\n",
      "[VI iter 560/800] ELBO=-20572.4102 exp_ll=-10799.6133 KL=9772.7979\n",
      "[VI iter 640/800] ELBO=-20445.5430 exp_ll=-10581.7734 KL=9863.7705\n",
      "[VI iter 720/800] ELBO=-20355.1348 exp_ll=-10417.8574 KL=9937.2773\n",
      "[VI iter 800/800] ELBO=-20288.7188 exp_ll=-10292.2754 KL=9996.4424\n",
      "Final test RMSE: 0.16067783973140726\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 92 | labelled size = 940 | pool size = 59060 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.115709, train_rmse=0.285504\n",
      "[Train epoch 5/50] loss=0.058827, train_rmse=0.225688\n",
      "[Train epoch 10/50] loss=0.041789, train_rmse=0.196099\n",
      "[Train epoch 15/50] loss=0.030627, train_rmse=0.174139\n",
      "[Train epoch 20/50] loss=0.025016, train_rmse=0.170109\n",
      "[Train epoch 25/50] loss=0.021983, train_rmse=0.171145\n",
      "[Train epoch 30/50] loss=0.021090, train_rmse=0.162549\n",
      "[Train epoch 35/50] loss=0.019726, train_rmse=0.160728\n",
      "[Train epoch 40/50] loss=0.016974, train_rmse=0.160833\n",
      "[Train epoch 45/50] loss=0.017181, train_rmse=0.166137\n",
      "[Train epoch 50/50] loss=0.015201, train_rmse=0.155190\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-200620.4219 exp_ll=-193059.2031 KL=7561.2192\n",
      "[VI iter 80/800] ELBO=-27136.4023 exp_ll=-18686.5781 KL=8449.8232\n",
      "[VI iter 160/800] ELBO=-23382.7754 exp_ll=-14563.5898 KL=8819.1855\n",
      "[VI iter 240/800] ELBO=-22010.8594 exp_ll=-12920.8525 KL=9090.0078\n",
      "[VI iter 320/800] ELBO=-21318.9961 exp_ll=-12018.1777 KL=9300.8193\n",
      "[VI iter 400/800] ELBO=-20918.3828 exp_ll=-11449.6865 KL=9468.6963\n",
      "[VI iter 480/800] ELBO=-20667.5098 exp_ll=-11063.7109 KL=9603.7988\n",
      "[VI iter 560/800] ELBO=-20502.0156 exp_ll=-10789.0449 KL=9712.9697\n",
      "[VI iter 640/800] ELBO=-20388.3965 exp_ll=-10587.2432 KL=9801.1533\n",
      "[VI iter 720/800] ELBO=-20307.7344 exp_ll=-10435.6182 KL=9872.1172\n",
      "[VI iter 800/800] ELBO=-20248.7207 exp_ll=-10319.8828 KL=9928.8379\n",
      "Final test RMSE: 0.1551903528649535\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 93 | labelled size = 950 | pool size = 59050 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.111633, train_rmse=0.282474\n",
      "[Train epoch 5/50] loss=0.057349, train_rmse=0.224109\n",
      "[Train epoch 10/50] loss=0.040520, train_rmse=0.190805\n",
      "[Train epoch 15/50] loss=0.031827, train_rmse=0.173701\n",
      "[Train epoch 20/50] loss=0.026769, train_rmse=0.175825\n",
      "[Train epoch 25/50] loss=0.020988, train_rmse=0.166721\n",
      "[Train epoch 30/50] loss=0.020822, train_rmse=0.164412\n",
      "[Train epoch 35/50] loss=0.018652, train_rmse=0.161647\n",
      "[Train epoch 40/50] loss=0.018432, train_rmse=0.159610\n",
      "[Train epoch 45/50] loss=0.016009, train_rmse=0.157669\n",
      "[Train epoch 50/50] loss=0.014739, train_rmse=0.158418\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-195451.0938 exp_ll=-187882.9375 KL=7568.1616\n",
      "[VI iter 80/800] ELBO=-26988.7344 exp_ll=-18529.5156 KL=8459.2178\n",
      "[VI iter 160/800] ELBO=-23342.5469 exp_ll=-14514.6250 KL=8827.9209\n",
      "[VI iter 240/800] ELBO=-21996.8867 exp_ll=-12899.8818 KL=9097.0039\n",
      "[VI iter 320/800] ELBO=-21321.9141 exp_ll=-12016.6562 KL=9305.2568\n",
      "[VI iter 400/800] ELBO=-20933.6055 exp_ll=-11463.5332 KL=9470.0713\n",
      "[VI iter 480/800] ELBO=-20691.5273 exp_ll=-11089.8037 KL=9601.7246\n",
      "[VI iter 560/800] ELBO=-20532.0625 exp_ll=-10824.9414 KL=9707.1201\n",
      "[VI iter 640/800] ELBO=-20422.4258 exp_ll=-10631.1367 KL=9791.2891\n",
      "[VI iter 720/800] ELBO=-20344.2266 exp_ll=-10486.1289 KL=9858.0986\n",
      "[VI iter 800/800] ELBO=-20286.5469 exp_ll=-10375.9033 KL=9910.6436\n",
      "Final test RMSE: 0.1584175341363494\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 94 | labelled size = 960 | pool size = 59040 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.112117, train_rmse=0.280936\n",
      "[Train epoch 5/50] loss=0.058521, train_rmse=0.230363\n",
      "[Train epoch 10/50] loss=0.040580, train_rmse=0.189592\n",
      "[Train epoch 15/50] loss=0.031542, train_rmse=0.176518\n",
      "[Train epoch 20/50] loss=0.025968, train_rmse=0.167446\n",
      "[Train epoch 25/50] loss=0.022661, train_rmse=0.168969\n",
      "[Train epoch 30/50] loss=0.020385, train_rmse=0.157360\n",
      "[Train epoch 35/50] loss=0.018061, train_rmse=0.154571\n",
      "[Train epoch 40/50] loss=0.016879, train_rmse=0.160703\n",
      "[Train epoch 45/50] loss=0.016416, train_rmse=0.157955\n",
      "[Train epoch 50/50] loss=0.016869, train_rmse=0.155970\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-207003.5781 exp_ll=-199429.4531 KL=7574.1201\n",
      "[VI iter 80/800] ELBO=-28305.2500 exp_ll=-19839.6660 KL=8465.5830\n",
      "[VI iter 160/800] ELBO=-24056.2734 exp_ll=-15208.8984 KL=8847.3750\n",
      "[VI iter 240/800] ELBO=-22525.9648 exp_ll=-13400.2920 KL=9125.6729\n",
      "[VI iter 320/800] ELBO=-21749.6445 exp_ll=-12408.2354 KL=9341.4102\n",
      "[VI iter 400/800] ELBO=-21297.0352 exp_ll=-11784.7529 KL=9512.2822\n",
      "[VI iter 480/800] ELBO=-21011.8457 exp_ll=-11362.9316 KL=9648.9141\n",
      "[VI iter 560/800] ELBO=-20822.3789 exp_ll=-11063.8252 KL=9758.5537\n",
      "[VI iter 640/800] ELBO=-20691.3066 exp_ll=-10844.8115 KL=9846.4951\n",
      "[VI iter 720/800] ELBO=-20597.2031 exp_ll=-10680.4141 KL=9916.7900\n",
      "[VI iter 800/800] ELBO=-20527.7441 exp_ll=-10555.1016 KL=9972.6426\n",
      "Final test RMSE: 0.1559701938795433\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 95 | labelled size = 970 | pool size = 59030 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.114554, train_rmse=0.286230\n",
      "[Train epoch 5/50] loss=0.059761, train_rmse=0.226252\n",
      "[Train epoch 10/50] loss=0.043389, train_rmse=0.193168\n",
      "[Train epoch 15/50] loss=0.032227, train_rmse=0.173148\n",
      "[Train epoch 20/50] loss=0.028011, train_rmse=0.166460\n",
      "[Train epoch 25/50] loss=0.025824, train_rmse=0.169540\n",
      "[Train epoch 30/50] loss=0.022179, train_rmse=0.164032\n",
      "[Train epoch 35/50] loss=0.020938, train_rmse=0.162387\n",
      "[Train epoch 40/50] loss=0.019130, train_rmse=0.160724\n",
      "[Train epoch 45/50] loss=0.017475, train_rmse=0.151798\n",
      "[Train epoch 50/50] loss=0.017467, train_rmse=0.167367\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-191839.4062 exp_ll=-184273.0625 KL=7566.3394\n",
      "[VI iter 80/800] ELBO=-28026.4316 exp_ll=-19543.5820 KL=8482.8496\n",
      "[VI iter 160/800] ELBO=-23988.5117 exp_ll=-15109.2021 KL=8879.3105\n",
      "[VI iter 240/800] ELBO=-22505.9316 exp_ll=-13339.6270 KL=9166.3047\n",
      "[VI iter 320/800] ELBO=-21760.7539 exp_ll=-12374.1211 KL=9386.6338\n",
      "[VI iter 400/800] ELBO=-21332.9473 exp_ll=-11773.2930 KL=9559.6543\n",
      "[VI iter 480/800] ELBO=-21067.4473 exp_ll=-11370.3896 KL=9697.0576\n",
      "[VI iter 560/800] ELBO=-20893.4160 exp_ll=-11086.6719 KL=9806.7441\n",
      "[VI iter 640/800] ELBO=-20774.3750 exp_ll=-10879.9902 KL=9894.3838\n",
      "[VI iter 720/800] ELBO=-20690.0273 exp_ll=-10725.7930 KL=9964.2344\n",
      "[VI iter 800/800] ELBO=-20628.2539 exp_ll=-10608.6523 KL=10019.6025\n",
      "Final test RMSE: 0.1673668736599694\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 96 | labelled size = 980 | pool size = 59020 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.110510, train_rmse=0.283645\n",
      "[Train epoch 5/50] loss=0.057290, train_rmse=0.221093\n",
      "[Train epoch 10/50] loss=0.040833, train_rmse=0.189564\n",
      "[Train epoch 15/50] loss=0.031819, train_rmse=0.180219\n",
      "[Train epoch 20/50] loss=0.027596, train_rmse=0.169718\n",
      "[Train epoch 25/50] loss=0.021674, train_rmse=0.169296\n",
      "[Train epoch 30/50] loss=0.021524, train_rmse=0.161617\n",
      "[Train epoch 35/50] loss=0.019576, train_rmse=0.160873\n",
      "[Train epoch 40/50] loss=0.018331, train_rmse=0.157772\n",
      "[Train epoch 45/50] loss=0.017284, train_rmse=0.158844\n",
      "[Train epoch 50/50] loss=0.015430, train_rmse=0.155716\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-209380.0000 exp_ll=-201825.4844 KL=7554.5093\n",
      "[VI iter 80/800] ELBO=-28220.3828 exp_ll=-19770.6543 KL=8449.7285\n",
      "[VI iter 160/800] ELBO=-24089.6797 exp_ll=-15270.1367 KL=8819.5439\n",
      "[VI iter 240/800] ELBO=-22606.2969 exp_ll=-13517.2676 KL=9089.0283\n",
      "[VI iter 320/800] ELBO=-21851.7910 exp_ll=-12552.7266 KL=9299.0645\n",
      "[VI iter 400/800] ELBO=-21411.3906 exp_ll=-11944.8389 KL=9466.5518\n",
      "[VI iter 480/800] ELBO=-21133.9004 exp_ll=-11532.4551 KL=9601.4453\n",
      "[VI iter 560/800] ELBO=-20949.6602 exp_ll=-11239.1523 KL=9710.5088\n",
      "[VI iter 640/800] ELBO=-20822.3203 exp_ll=-11023.6289 KL=9798.6914\n",
      "[VI iter 720/800] ELBO=-20731.2422 exp_ll=-10861.4727 KL=9869.7705\n",
      "[VI iter 800/800] ELBO=-20664.1152 exp_ll=-10737.3779 KL=9926.7373\n",
      "Final test RMSE: 0.15571569206945102\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 97 | labelled size = 990 | pool size = 59010 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.113021, train_rmse=0.283367\n",
      "[Train epoch 5/50] loss=0.057769, train_rmse=0.227334\n",
      "[Train epoch 10/50] loss=0.041547, train_rmse=0.191065\n",
      "[Train epoch 15/50] loss=0.031275, train_rmse=0.178403\n",
      "[Train epoch 20/50] loss=0.026173, train_rmse=0.170694\n",
      "[Train epoch 25/50] loss=0.023131, train_rmse=0.170440\n",
      "[Train epoch 30/50] loss=0.020898, train_rmse=0.156844\n",
      "[Train epoch 35/50] loss=0.019323, train_rmse=0.168078\n",
      "[Train epoch 40/50] loss=0.017995, train_rmse=0.164691\n",
      "[Train epoch 45/50] loss=0.016188, train_rmse=0.156171\n",
      "[Train epoch 50/50] loss=0.016093, train_rmse=0.157308\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-197733.9219 exp_ll=-190166.1719 KL=7567.7490\n",
      "[VI iter 80/800] ELBO=-27374.0156 exp_ll=-18924.4668 KL=8449.5479\n",
      "[VI iter 160/800] ELBO=-23696.5938 exp_ll=-14883.5322 KL=8813.0605\n",
      "[VI iter 240/800] ELBO=-22363.4492 exp_ll=-13283.7461 KL=9079.7031\n",
      "[VI iter 320/800] ELBO=-21691.3867 exp_ll=-12403.5020 KL=9287.8848\n",
      "[VI iter 400/800] ELBO=-21303.1406 exp_ll=-11849.2598 KL=9453.8818\n",
      "[VI iter 480/800] ELBO=-21060.6914 exp_ll=-11473.3594 KL=9587.3320\n",
      "[VI iter 560/800] ELBO=-20900.9785 exp_ll=-11206.1738 KL=9694.8047\n",
      "[VI iter 640/800] ELBO=-20791.1484 exp_ll=-11010.0127 KL=9781.1348\n",
      "[VI iter 720/800] ELBO=-20712.9961 exp_ll=-10862.9258 KL=9850.0693\n",
      "[VI iter 800/800] ELBO=-20655.5820 exp_ll=-10750.9785 KL=9904.6045\n",
      "Final test RMSE: 0.15730837516544982\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 98 | labelled size = 1000 | pool size = 59000 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.110853, train_rmse=0.280699\n",
      "[Train epoch 5/50] loss=0.057435, train_rmse=0.222718\n",
      "[Train epoch 10/50] loss=0.039415, train_rmse=0.186783\n",
      "[Train epoch 15/50] loss=0.031901, train_rmse=0.173292\n",
      "[Train epoch 20/50] loss=0.026888, train_rmse=0.180470\n",
      "[Train epoch 25/50] loss=0.021935, train_rmse=0.164578\n",
      "[Train epoch 30/50] loss=0.019820, train_rmse=0.164692\n",
      "[Train epoch 35/50] loss=0.018181, train_rmse=0.166442\n",
      "[Train epoch 40/50] loss=0.017778, train_rmse=0.155785\n",
      "[Train epoch 45/50] loss=0.015787, train_rmse=0.153270\n",
      "[Train epoch 50/50] loss=0.015534, train_rmse=0.157804\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-203470.4531 exp_ll=-195914.5781 KL=7555.8745\n",
      "[VI iter 80/800] ELBO=-27474.5312 exp_ll=-19037.5176 KL=8437.0127\n",
      "[VI iter 160/800] ELBO=-23851.6328 exp_ll=-15050.0078 KL=8801.6260\n",
      "[VI iter 240/800] ELBO=-22530.8750 exp_ll=-13459.7275 KL=9071.1475\n",
      "[VI iter 320/800] ELBO=-21852.0547 exp_ll=-12569.4434 KL=9282.6104\n",
      "[VI iter 400/800] ELBO=-21455.0215 exp_ll=-12003.3223 KL=9451.6992\n",
      "[VI iter 480/800] ELBO=-21205.4453 exp_ll=-11617.4570 KL=9587.9873\n",
      "[VI iter 560/800] ELBO=-21040.5801 exp_ll=-11342.4492 KL=9698.1309\n",
      "[VI iter 640/800] ELBO=-20927.2891 exp_ll=-11140.2285 KL=9787.0605\n",
      "[VI iter 720/800] ELBO=-20846.8203 exp_ll=-10988.2334 KL=9858.5879\n",
      "[VI iter 800/800] ELBO=-20787.8945 exp_ll=-10872.1523 KL=9915.7412\n",
      "Final test RMSE: 0.15780418762372614\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 99 | labelled size = 1010 | pool size = 58990 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.109754, train_rmse=0.282285\n",
      "[Train epoch 5/50] loss=0.058058, train_rmse=0.221333\n",
      "[Train epoch 10/50] loss=0.040266, train_rmse=0.186798\n",
      "[Train epoch 15/50] loss=0.031331, train_rmse=0.169837\n",
      "[Train epoch 20/50] loss=0.025537, train_rmse=0.172498\n",
      "[Train epoch 25/50] loss=0.021768, train_rmse=0.158980\n",
      "[Train epoch 30/50] loss=0.019850, train_rmse=0.154437\n",
      "[Train epoch 35/50] loss=0.017042, train_rmse=0.153678\n",
      "[Train epoch 40/50] loss=0.015966, train_rmse=0.162975\n",
      "[Train epoch 45/50] loss=0.016318, train_rmse=0.155723\n",
      "[Train epoch 50/50] loss=0.014869, train_rmse=0.158412\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-197562.2188 exp_ll=-190003.2500 KL=7558.9629\n",
      "[VI iter 80/800] ELBO=-27103.6055 exp_ll=-18676.1309 KL=8427.4756\n",
      "[VI iter 160/800] ELBO=-23594.1758 exp_ll=-14807.2139 KL=8786.9619\n",
      "[VI iter 240/800] ELBO=-22328.3711 exp_ll=-13279.7402 KL=9048.6318\n",
      "[VI iter 320/800] ELBO=-21697.6953 exp_ll=-12446.4072 KL=9251.2891\n",
      "[VI iter 400/800] ELBO=-21336.7207 exp_ll=-11924.8867 KL=9411.8340\n",
      "[VI iter 480/800] ELBO=-21112.6680 exp_ll=-11572.4443 KL=9540.2246\n",
      "[VI iter 560/800] ELBO=-20965.6191 exp_ll=-11322.4922 KL=9643.1270\n",
      "[VI iter 640/800] ELBO=-20864.7109 exp_ll=-11139.3408 KL=9725.3691\n",
      "[VI iter 720/800] ELBO=-20792.8867 exp_ll=-11002.2354 KL=9790.6504\n",
      "[VI iter 800/800] ELBO=-20740.0000 exp_ll=-10898.0791 KL=9841.9209\n",
      "Final test RMSE: 0.1584117019160631\n",
      "Computing acquisition scores on pool (subsample size: 2000)\n",
      "\n",
      "=== Acquisition iteration 100 | labelled size = 1020 | pool size = 58980 ===\n",
      "Initializing BNN MFVI MLPRegressor Simple...\n",
      "[Train epoch 1/50] loss=0.111782, train_rmse=0.281846\n",
      "[Train epoch 5/50] loss=0.057653, train_rmse=0.222710\n",
      "[Train epoch 10/50] loss=0.039932, train_rmse=0.192923\n",
      "[Train epoch 15/50] loss=0.031293, train_rmse=0.171832\n",
      "[Train epoch 20/50] loss=0.025009, train_rmse=0.167775\n",
      "[Train epoch 25/50] loss=0.021553, train_rmse=0.156802\n",
      "[Train epoch 30/50] loss=0.019398, train_rmse=0.159808\n",
      "[Train epoch 35/50] loss=0.018134, train_rmse=0.155944\n",
      "[Train epoch 40/50] loss=0.017259, train_rmse=0.155263\n",
      "[Train epoch 45/50] loss=0.016805, train_rmse=0.155091\n",
      "[Train epoch 50/50] loss=0.016388, train_rmse=0.159262\n",
      "Initialising Full Matrix Normal VI Model for Final Layer...\n",
      "[VI iter 1/800] ELBO=-196501.3906 exp_ll=-188942.1406 KL=7559.2476\n",
      "[VI iter 80/800] ELBO=-27640.0879 exp_ll=-19195.5938 KL=8444.4941\n",
      "[VI iter 160/800] ELBO=-24018.5820 exp_ll=-15204.7090 KL=8813.8740\n",
      "[VI iter 240/800] ELBO=-22676.2031 exp_ll=-13590.0273 KL=9086.1748\n",
      "[VI iter 320/800] ELBO=-21995.6797 exp_ll=-12697.1816 KL=9298.4990\n",
      "[VI iter 400/800] ELBO=-21602.8438 exp_ll=-12135.4424 KL=9467.4014\n",
      "[VI iter 480/800] ELBO=-21357.9922 exp_ll=-11755.1025 KL=9602.8887\n",
      "[VI iter 560/800] ELBO=-21197.0898 exp_ll=-11485.3135 KL=9711.7773\n",
      "[VI iter 640/800] ELBO=-21086.8496 exp_ll=-11287.7812 KL=9799.0684\n",
      "[VI iter 720/800] ELBO=-21008.5801 exp_ll=-11139.9570 KL=9868.6230\n",
      "[VI iter 800/800] ELBO=-20951.3457 exp_ll=-11027.8057 KL=9923.5400\n",
      "Final test RMSE: 0.15926230973346944\n",
      "Results saved to outputs/bnn_mfvi/history_BNN_MFVI_full_PredCovariance_Run4.json\n"
     ]
    }
   ],
   "source": [
    "#@title Run all acquisition functions\n",
    "for idx, acq_function in enumerate(acq_functions):\n",
    "    for seed in seeds:\n",
    "        acq_name = acq_names[idx]\n",
    "        print(f\"\\n\\n========== Running {acq_name} Seed {seed} ==========\")\n",
    "\n",
    "        init_idxs = sample_balanced_seed(train_dataset_to_use, n_per_class=2, seed=seed)\n",
    "\n",
    "        history = active_learning_loop(\n",
    "            model_ctor=make_model,\n",
    "            train_dataset=train_dataset_to_use,\n",
    "            test_dataset=test_dataset_to_use,\n",
    "            initial_labeled_idxs=init_idxs,\n",
    "            candidate_pool_size=candidate_pool_size, # subsample size\n",
    "            n_acq_per_iter=10,        # top k data from pool\n",
    "            n_iterations=n_iterations,# number of AL rounds\n",
    "            epochs_per_round=epochs_per_round,      \n",
    "            lr=1e-3,\n",
    "            weight_decay=1e-4,        \n",
    "            T_acq=T_acq,                 # MC samples for acquisition & test eval\n",
    "            vi_lr=vi_lr,\n",
    "            vi_epochs=vi_epochs,\n",
    "            use_VI=use_VI,\n",
    "            use_full_mn_VI=use_full_mn_VI,\n",
    "            batch_train=64,\n",
    "            batch_pool=256,\n",
    "            reset_model=True,        \n",
    "            device=device,\n",
    "            seed=seed,\n",
    "            acquisition_fn=acq_function,\n",
    "            acquisition_kwargs={'device': device, 'score_type': score_type}\n",
    "        )\n",
    "\n",
    "        # Save history to a json file\n",
    "        file_name = output_dir + f'history_{model_names[idx]}_{acq_name}_Run{seed}.json'\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(history, f)\n",
    "        print(f\"Results saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0AvY8UKBFFB"
   },
   "source": [
    "## 4.4 Visualising Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1592,
     "status": "ok",
     "timestamp": 1767403368125,
     "user": {
      "displayName": "Lukang Guo",
      "userId": "08731569048860429605"
     },
     "user_tz": -480
    },
    "id": "MJgMko1tBFFB",
    "outputId": "482f90bd-4991-416a-b827-760e1aaa9e8d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title plot_active_learning_curves()\n",
    "def plot_active_learning_curves(history_list, labels=None, ylim = None,\n",
    "                                title=\"Bayesian NN Active Learning (MNIST)\",\n",
    "                                xlabel=\"Number of labeled training examples\",\n",
    "                                ylabel=\"RMSE values\",\n",
    "                                xfield=\"labelled_set_sizes\",\n",
    "                                yfield=\"test_rmse\",\n",
    "                                marker=\"\",\n",
    "                                linestyle=\"-\"):\n",
    "    if labels is not None:\n",
    "        assert len(labels) == len(history_list), \"Labels must have same length as history_list.\"\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for idx, history in enumerate(history_list):\n",
    "        x = history[xfield]\n",
    "        y = history[yfield]\n",
    "        label = labels[idx] if labels is not None else None\n",
    "\n",
    "        assert len(x) == len(y), \"Label sizes and accuracies must have same length.\"\n",
    "        plt.plot(x, y, marker=marker, linestyle=linestyle, label=label)\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    if labels is not None:\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_active_learning_curves([history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns8Pz-TdGuhl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vvcLJGz1L-np",
    "MAt-p6nNp7-f",
    "NPW8LxMhqBIw",
    "ipv8n5U__XN0",
    "Vud0lKJLuYfm",
    "HKNcWoHBudCn",
    "zyBnpvgsBFFA",
    "wuqTGB2M2VpF"
   ],
   "provenance": [
    {
     "file_id": "1_Ywoood-Sm6sZJRCgJTGcc6OALNgOiUK",
     "timestamp": 1767330552888
    },
    {
     "file_id": "1IhJdG2w1pws7LZ7V_baeyHDCd33kz216",
     "timestamp": 1767278679249
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
